{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "folder = \"/Volumes/LACIE SHARE/seizure-prediction\"\n",
    "\n",
    "mat_data = loadmat(folder + \"/Dog_1/Dog_1/Dog_1_interictal_segment_0001.mat\")\n",
    "print(mat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3c187-0a38-4111-8bfa-182a3c1d1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "signals = np.array(mat_data['interictal_segment_1'][0, 0][0])\n",
    "print(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9a577-0f9e-400c-ba3e-b1cfc72362f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "Pxx, freqs, bins, im = plt.specgram(signals[0, :], Fs=400)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.show()\n",
    "\n",
    "t_axis = np.arange(0, signals.shape[1])*(1/400)\n",
    "plt.plot(t_axis, signals[0, :])\n",
    "plt.show()\n",
    "\n",
    "fft_0 = np.fft.fft(signals[0,:])\n",
    "plt.plot(fft_0)\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52dd562-5e73-4517-9b66-f23ae89b4edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "number_of_components = 16\n",
    "\n",
    "# Perform ICA on the EEG data\n",
    "ica = FastICA(n_components=number_of_components)  # Set the desired number of components\n",
    "ica_components = ica.fit_transform(signals)  # Transpose data for ICA\n",
    "\n",
    "# Plot original EEG data and ICA components for visualization\n",
    "num_plots = min(number_of_components, 10)  # Adjust the number of plots based on components\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot original EEG data (plotting the first channel as an example)\n",
    "plt.subplot(num_plots + 1, 1, 1)\n",
    "plt.plot(signals[0, :])  # Plotting the first channel as an example\n",
    "\n",
    "# Plot ICA components\n",
    "for i in range(num_plots):\n",
    "    plt.subplot(num_plots + 1, 1, i + 2)\n",
    "    plt.plot(ica_components[:, i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9fbe6-5658-4e23-b9ce-068e42644ba9",
   "metadata": {},
   "source": [
    "## Define custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f1063-ac49-4380-bbd4-e44e697054cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.feature_extraction.feature_calculators import abs_energy\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Fs = 399.6097561  # Hz\n",
    "\n",
    "\n",
    "def root_abs_energy(x):\n",
    "    return np.sqrt(abs_energy(x))\n",
    "\n",
    "\n",
    "def get_powers(x):\n",
    "    freq = np.fft.fftfreq(x.shape[0], d=1/Fs)\n",
    "    power_spectrum = np.abs(np.fft.fft(x))**2\n",
    "    results = {}\n",
    "    results['power_delta'] = np.mean(power_spectrum[(freq >= 1) & (freq < 4)])\n",
    "    results['power_theta'] = np.mean(power_spectrum[(freq >= 4) & (freq < 8)])\n",
    "    results['power_alpha'] = np.mean(power_spectrum[(freq >= 8) & (freq < 14)])\n",
    "    results['power_beta'] = np.mean(power_spectrum[(freq >= 14) & (freq < 30)])\n",
    "    results['power_gamma'] = np.mean(power_spectrum[(freq >= 30)])\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_custom_feat(x):\n",
    "    results = get_powers(x)\n",
    "    results['root_abs_energy'] = np.sqrt(abs_energy(x))\n",
    "    return results\n",
    "    \n",
    "\n",
    "fc_parameters = {\n",
    "    \"mean\": None,\n",
    "    \"standard_deviation\": None,\n",
    "    \"absolute_sum_of_changes\": None,\n",
    "    \"minimum\": None,\n",
    "    \"maximum\": None,\n",
    "    \"skewness\": None,\n",
    "    \"kurtosis\": None,\n",
    "    \"root_mean_square\": None\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame({'id': 0, 'signal': signals[0,:]})\n",
    "print(signals[0,:])\n",
    "print(test_df.head())\n",
    "\n",
    "ts_results = extract_features(test_df, default_fc_parameters=fc_parameters, column_id='id', n_jobs=5)\n",
    "cust_results = get_custom_feat(signals[0,:])\n",
    "print(cust_results)\n",
    "all_feat = pd.concat([ts_results, pd.DataFrame(cust_results, index=[0])], axis=1)\n",
    "print(all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b88931-b7a3-4055-8d54-56d22faac698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "upper_time = 1200  # s, (20 min)\n",
    "\n",
    "def segment_signal(signal, window_size, overlap, Fs):\n",
    "    window_id = 0\n",
    "    window_start_ind = 0\n",
    "    signal_length = signal.shape[0]\n",
    "    t_axis = np.arange(0, signal_length*Fs, 1/Fs)\n",
    "    result_df = pd.DataFrame(columns=[\"window_id\", \"time\", \"signal\"])\n",
    "    while window_start_ind < signal_length:\n",
    "        window_end_ind = np.min([signal_length, window_start_ind+window_size])\n",
    "        \n",
    "        this_time = upper_time * np.ones((window_size,))\n",
    "        this_signal = np.zeros((window_size,))\n",
    "        this_time[:window_end_ind-window_start_ind] = t_axis[window_start_ind:window_end_ind]\n",
    "        this_signal[:window_end_ind-window_start_ind] = signal[window_start_ind:window_end_ind]\n",
    "\n",
    "        this_df = pd.DataFrame({\"window_id\": window_id, \"time\": this_time, \"signal\": this_signal})\n",
    "        result_df = pd.concat([result_df, this_df])\n",
    "        \n",
    "        window_start_ind += window_size - overlap\n",
    "        window_id += 1\n",
    "    return result_df\n",
    "\n",
    "\n",
    "result_df = segment_signal(signals[0, 0:3600], 800, 200, Fs)\n",
    "print(result_df[result_df['window_id'] == 5])\n",
    "ts_fresh_feat = extract_features(result_df, default_fc_parameters=fc_parameters, column_id='window_id', column_sort='time', n_jobs=5)\n",
    "print(ts_fresh_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3fd87-cf28-4a8a-87e0-6fb048980cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feat_per_window(window_df, sample_col='window_id'):\n",
    "    ts_fresh_feat = extract_features(window_df, default_fc_parameters=fc_parameters, column_id='window_id', column_sort='time', n_jobs=5)\n",
    "    cust_results = []\n",
    "    for i in range(window_df[sample_col].max()+1):\n",
    "        this_sig = window_df[window_df[sample_col] == i]\n",
    "        this_sig = this_sig['signal'].to_numpy()\n",
    "        cust_results.append(get_custom_feat(this_sig))\n",
    "    all_feat = pd.concat([ts_fresh_feat, pd.DataFrame(cust_results)], axis=1)\n",
    "    return all_feat\n",
    "\n",
    "all_feat = extract_feat_per_window(result_df)\n",
    "print(all_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ccb64-5770-47d0-9bcb-cdcf0d5caa02",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792e26c-d603-4221-9b4e-789cf868e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_folder = \"/Volumes/LACIE SHARE/seizure-prediction\"\n",
    "sub_folders = [\"Dog_1/Dog_1\", \"Dog_2/Dog_2\", \"Dog_3/Dog_3\", \"Dog_4/Dog_4\", \"Dog_5/Dog_5\"]\n",
    "interictal_files = []\n",
    "preictal_files = []\n",
    "test_files = []\n",
    "for fol in sub_folders:\n",
    "    for file_name in os.listdir(os.path.join(root_folder, fol)):\n",
    "        if \"._\" in file_name:\n",
    "            continue\n",
    "        if 'interictal' in file_name:\n",
    "            interictal_files.append(os.path.join(fol, file_name))\n",
    "        elif 'preictal' in file_name:\n",
    "            preictal_files.append(os.path.join(fol, file_name))\n",
    "        elif 'test' in file_name:\n",
    "            test_files.append(os.path.join(fol, file_name))\n",
    "\n",
    "# save results\n",
    "with open('interictal.txt', 'w') as f:\n",
    "    for file_name in interictal_files:\n",
    "        f.write(file_name + \"\\n\")\n",
    "with open('preictal.txt', 'w') as f:\n",
    "    for file_name in preictal_files:\n",
    "        f.write(file_name + \"\\n\")\n",
    "with open('nolabel.txt', 'w') as f:\n",
    "    for file_name in test_files:\n",
    "        f.write(file_name + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b754edb-9c7e-4726-b282-9ffe93871f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "interictal_files = [file_name.strip() for file_name in open('interictal.txt').readlines()]\n",
    "preictal_files = [file_name.strip() for file_name in open('preictal.txt').readlines()]\n",
    "all_files = interictal_files + preictal_files\n",
    "classes = np.ones((len(all_files),))\n",
    "classes[:len(interictal_files)] = 0\n",
    "\n",
    "train_files, test_files = train_test_split(all_files, test_size=0.3, random_state=23, stratify=classes)\n",
    "\n",
    "# save results\n",
    "with open('train.txt', 'w') as f:\n",
    "    for file_name in train_files:\n",
    "        f.write(file_name + \"\\n\")\n",
    "with open('test.txt', 'w') as f:\n",
    "    for file_name in test_files:\n",
    "        f.write(file_name + \"\\n\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deb71d0-7712-477c-b1da-2fd97342e476",
   "metadata": {},
   "source": [
    "### Undersample training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626822a-d6a4-466f-b361-26698b536473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = open(\"./data/train.txt\").readlines()\n",
    "train_preictal = [filename for filename in train_files if \"preictal\" in filename]\n",
    "train_interictal = [filename for filename in train_files if \"interictal\" in filename]\n",
    "print(f\"Number of preictal training samples: {len(train_preictal)}\")\n",
    "print(f\"Number of interictal training samples: {len(train_interictal)}\")\n",
    "\n",
    "# should only run code below once and then used saved file list going forward\n",
    "\n",
    "# num_preictal = len(train_preictal)\n",
    "# train_undersamp_interictal = np.random.choice(train_interictal, num_preictal, replace=False)\n",
    "# train_files_sampled = train_preictal + train_undersamp_interictal.tolist()\n",
    "\n",
    "# # save results\n",
    "# with open('./data/train_undersampled.txt', 'w') as f:\n",
    "#     for file_name in train_files_sampled:\n",
    "#         f.write(file_name.strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd99163-e851-4258-9d5e-a10f3f486a0f",
   "metadata": {},
   "source": [
    "## Extract features for undersampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99444c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def segment_signal_multichannel(signals, window_size, overlap, Fs, window_id_start=0, window_start_ind=0):\n",
    "    \"\"\" expects signals to be number of channels x number of eeg samples\n",
    "    \"\"\"\n",
    "    window_id = window_id_start\n",
    "    window_start_ind = window_start_ind\n",
    "    num_channels = signals.shape[0]\n",
    "    signal_length = signals.shape[1]\n",
    "    t_axis = np.arange(0, signal_length*Fs, 1/Fs)\n",
    "    upper_time = 1200  # 20 min\n",
    "    signal_cols = [\"channel_\" + str(i) for i in range(num_channels)]\n",
    "    result_df = pd.DataFrame(columns=[\"window_id\", \"time\"] + signal_cols)\n",
    "    signals = np.transpose(signals)\n",
    "    while window_start_ind < signal_length:\n",
    "        window_end_ind = np.min([signal_length, window_start_ind+window_size])\n",
    "        \n",
    "        this_time = upper_time * np.ones((window_size,))\n",
    "        this_signal = np.zeros((window_size, num_channels))\n",
    "        this_time[:window_end_ind-window_start_ind] = t_axis[window_start_ind:window_end_ind]\n",
    "        this_signal[:window_end_ind-window_start_ind, :] = signals[window_start_ind:window_end_ind, :]\n",
    "\n",
    "        this_df = pd.DataFrame({\"window_id\": window_id, \"time\": this_time})\n",
    "        for i, channel_name in enumerate(signal_cols):\n",
    "            this_df[channel_name] = this_signal[:, i]\n",
    "        result_df = pd.concat([result_df, this_df])\n",
    "        \n",
    "        window_start_ind += window_size - overlap\n",
    "        window_id += 1\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58272ab8-c938-49cc-84de-2e97ea07ee5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting file 0/370: Dog_4_preictal_segment_0017.mat\n",
      "  window_id      time  channel_0  channel_1  channel_2  channel_3  channel_4  \\\n",
      "0         0  0.000000      -50.0       58.0       43.0      -28.0      -32.0   \n",
      "1         0  0.002502      -45.0       51.0       51.0       -5.0      -55.0   \n",
      "2         0  0.005005      -36.0       58.0       66.0       12.0      -75.0   \n",
      "3         0  0.007507      -14.0       71.0       75.0       30.0      -71.0   \n",
      "4         0  0.010010        2.0       83.0       78.0       44.0      -67.0   \n",
      "\n",
      "   channel_5  channel_6  channel_7  channel_8  channel_9  channel_10  \\\n",
      "0        6.0       17.0       -2.0       35.0      -40.0       -73.0   \n",
      "1      -11.0       -4.0        4.0       43.0      -12.0       -61.0   \n",
      "2      -30.0      -33.0        9.0       51.0        1.0       -56.0   \n",
      "3      -35.0      -34.0        2.0       43.0        0.0       -62.0   \n",
      "4      -37.0      -23.0        4.0       32.0       -1.0       -67.0   \n",
      "\n",
      "   channel_11  channel_12  channel_13  channel_14  channel_15  \n",
      "0       -93.0        15.0        83.0        30.0        22.0  \n",
      "1       -97.0         6.0        79.0        39.0        15.0  \n",
      "2       -97.0         7.0        73.0        41.0         4.0  \n",
      "3       -94.0         2.0        65.0        26.0        -8.0  \n",
      "4       -89.0       -13.0        52.0        14.0       -18.0  \n",
      "4000\n",
      "8400\n",
      "  window_id       time  channel_0  channel_1  channel_2  channel_3  channel_4  \\\n",
      "0         5  10.009766      157.0      -26.0      -63.0      -55.0       49.0   \n",
      "1         5  10.012268      143.0      -32.0      -66.0      -58.0       55.0   \n",
      "2         5  10.014771      140.0      -31.0      -72.0      -60.0       52.0   \n",
      "3         5  10.017273      145.0      -32.0      -77.0      -58.0       48.0   \n",
      "4         5  10.019775      150.0      -37.0      -81.0      -59.0       43.0   \n",
      "\n",
      "   channel_5  channel_6  channel_7  channel_8  channel_9  channel_10  \\\n",
      "0      -50.0      -24.0      -75.0       68.0       14.0        19.0   \n",
      "1      -42.0      -35.0      -78.0       73.0       19.0        14.0   \n",
      "2      -34.0      -52.0      -86.0       77.0       23.0        15.0   \n",
      "3      -32.0      -41.0      -87.0       77.0       20.0        14.0   \n",
      "4      -31.0      -19.0      -84.0       70.0       17.0        12.0   \n",
      "\n",
      "   channel_11  channel_12  channel_13  channel_14  channel_15  \n",
      "0       -17.0       -21.0        17.0        28.0       -17.0  \n",
      "1       -18.0        -4.0        21.0        35.0       -20.0  \n",
      "2       -15.0         9.0        22.0        31.0       -28.0  \n",
      "3       -16.0        10.0        17.0        37.0       -29.0  \n",
      "4       -14.0         4.0        16.0        42.0       -28.0  \n",
      "8000\n",
      "12400\n",
      "Empty DataFrame\n",
      "Columns: [window_id, time, channel_0, channel_1, channel_2, channel_3, channel_4, channel_5, channel_6, channel_7, channel_8, channel_9, channel_10, channel_11, channel_12, channel_13, channel_14, channel_15]\n",
      "Index: []\n",
      "12000\n",
      "16400\n",
      "Empty DataFrame\n",
      "Columns: [window_id, time, channel_0, channel_1, channel_2, channel_3, channel_4, channel_5, channel_6, channel_7, channel_8, channel_9, channel_10, channel_11, channel_12, channel_13, channel_14, channel_15]\n",
      "Index: []\n",
      "16000\n",
      "20400\n",
      "Empty DataFrame\n",
      "Columns: [window_id, time, channel_0, channel_1, channel_2, channel_3, channel_4, channel_5, channel_6, channel_7, channel_8, channel_9, channel_10, channel_11, channel_12, channel_13, channel_14, channel_15]\n",
      "Index: []\n",
      "20000\n",
      "24400\n",
      "Empty DataFrame\n",
      "Columns: [window_id, time, channel_0, channel_1, channel_2, channel_3, channel_4, channel_5, channel_6, channel_7, channel_8, channel_9, channel_10, channel_11, channel_12, channel_13, channel_14, channel_15]\n",
      "Index: []\n",
      "24000\n",
      "28400\n",
      "Empty DataFrame\n",
      "Columns: [window_id, time, channel_0, channel_1, channel_2, channel_3, channel_4, channel_5, channel_6, channel_7, channel_8, channel_9, channel_10, channel_11, channel_12, channel_13, channel_14, channel_15]\n",
      "Index: []\n",
      "28000\n",
      "32400\n",
      "Empty DataFrame\n",
      "Columns: [window_id, time, channel_0, channel_1, channel_2, channel_3, channel_4, channel_5, channel_6, channel_7, channel_8, channel_9, channel_10, channel_11, channel_12, channel_13, channel_14, channel_15]\n",
      "Index: []\n",
      "32000\n",
      "36400\n",
      "Empty DataFrame\n",
      "Columns: [window_id, time, channel_0, channel_1, channel_2, channel_3, channel_4, channel_5, channel_6, channel_7, channel_8, channel_9, channel_10, channel_11, channel_12, channel_13, channel_14, channel_15]\n",
      "Index: []\n",
      "36000\n",
      "40400\n",
      "Empty DataFrame\n",
      "Columns: [window_id, time, channel_0, channel_1, channel_2, channel_3, channel_4, channel_5, channel_6, channel_7, channel_8, channel_9, channel_10, channel_11, channel_12, channel_13, channel_14, channel_15]\n",
      "Index: []\n",
      "40000\n",
      "44400\n",
      "Empty DataFrame\n",
      "Columns: [window_id, time, channel_0, channel_1, channel_2, channel_3, channel_4, channel_5, channel_6, channel_7, channel_8, channel_9, channel_10, channel_11, channel_12, channel_13, channel_14, channel_15]\n",
      "Index: []\n",
      "44000\n",
      "48400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m window_id_start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m window_start_ind \u001b[38;5;241m<\u001b[39m signals\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 36\u001b[0m     chunk_df \u001b[38;5;241m=\u001b[39m segment_signal_multichannel(signals[:,window_start_ind:window_end_ind], window_size, window_overlap, \n\u001b[1;32m     37\u001b[0m                                            Fs, window_id_start, window_start_ind)\n\u001b[1;32m     38\u001b[0m     chunk_df\u001b[38;5;241m.\u001b[39mto_csv(outpath, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m, in \u001b[0;36msegment_signal_multichannel\u001b[0;34m(signals, window_size, overlap, Fs, window_id_start, window_start_ind)\u001b[0m\n\u001b[1;32m      8\u001b[0m num_channels \u001b[38;5;241m=\u001b[39m signals\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m signal_length \u001b[38;5;241m=\u001b[39m signals\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m t_axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, signal_length\u001b[38;5;241m*\u001b[39mFs, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mFs)\n\u001b[1;32m     11\u001b[0m upper_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1200\u001b[39m  \u001b[38;5;66;03m# 20 min\u001b[39;00m\n\u001b[1;32m     12\u001b[0m signal_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_channels)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Fs = 399.6097561\n",
    "window_size = 1200  # 3s\n",
    "window_overlap = 400  # 1s\n",
    "processing_chunk_num_windows = 5\n",
    "\n",
    "def get_data_key_from_filename(filename):\n",
    "    filename = filename.split(\"/\")\n",
    "    filename = filename[-1].split(\".\")\n",
    "    filename = filename[0].split(\"_\")\n",
    "    filename = filename[2:]\n",
    "    filename[-1] = filename[-1].lstrip(\"0\")\n",
    "    return \"_\".join(filename)\n",
    "\n",
    "\n",
    "root_folder = \"/Volumes/LACIE SHARE/seizure-prediction\"\n",
    "output_folder = \"/Volumes/LACIE SHARE/seizure-prediction-outputs/windows_3sduration_1soverlap\"\n",
    "train_files_undersamp = [f.strip() for f in open(\"./data/train_undersampled.txt\").readlines()]\n",
    "for i, filename in enumerate(train_files_undersamp):\n",
    "    print(f\"Segmenting file {i}/{len(train_files_undersamp)}: {filename.split('/')[-1]}\")\n",
    "    filepath = os.path.join(root_folder, filename)\n",
    "    mat_data = loadmat(filepath)\n",
    "    signals = np.array(mat_data[get_data_key_from_filename(filename)][0, 0][0])\n",
    "    outfilename = filename.split(\"/\")[-1]\n",
    "    outfilename = outfilename.split(\".\")[0] + \".csv\"\n",
    "    outpath = os.path.join(output_folder, outfilename)\n",
    "    \n",
    "    window_start_ind = 0\n",
    "    window_end_ind = window_size + (window_size - window_overlap)*(processing_chunk_num_windows-1)\n",
    "    window_id_start = 0\n",
    "    while window_start_ind < signals.shape[1]:\n",
    "        chunk_df = segment_signal_multichannel(signals[:,window_start_ind:window_end_ind], window_size, window_overlap, \n",
    "                                               Fs, window_id_start, window_start_ind)\n",
    "        chunk_df.to_csv(outpath, index=False, mode='a')\n",
    "        print(chunk_df.head())\n",
    "        window_start_ind = window_end_ind-window_overlap\n",
    "        print(window_start_ind)\n",
    "        window_end_ind = window_start_ind + window_size + (window_size - window_overlap)*(processing_chunk_num_windows-1)\n",
    "        print(window_end_ind)\n",
    "        window_id_start += processing_chunk_num_windows\n",
    "    \n",
    "    break\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afcd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036b259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
