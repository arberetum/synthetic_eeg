{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 4000\n",
    "NUM_CHANNELS = 16\n",
    "X_int = np.load(\"interictal_gan_train.npy\")\n",
    "X_int = X_int.reshape(-1, WINDOW_SIZE, NUM_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9499, 4000, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_int = np.zeros((X_int.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9499,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int_normalized = (X_int - X_int.min()) / (X_int.max() - X_int.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min X for interictal = -2153 \n",
      "Max X for interictal= 1925\n"
     ]
    }
   ],
   "source": [
    "print(\"Min X for interictal =\", X_int.min(), \"\\nMax X for interictal=\", X_int.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_int_train, X_int_val, y_int_train, y_int_val = train_test_split(X_int_normalized, y_int, test_size = 0.1, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8549, 4000, 16) (950, 4000, 16) (8549,) (950,)\n"
     ]
    }
   ],
   "source": [
    "print(X_int_train.shape, X_int_val.shape, y_int_train.shape, y_int_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ucsiTKJDW-y"
   },
   "source": [
    "# Define DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the Denoising Diffusion Probabilistic Model (DDPM)\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, input_channels, num_filters):\n",
    "        super(DDPM, self).__init__()\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, num_filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(num_filters, num_filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(num_filters, num_filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(num_filters, input_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()  # Output range between 0 and 1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #encoded = self.encoder(x)\n",
    "        encoded = self.encoder(x.permute(0, 2, 1))  # Permute to match Conv1d input format\n",
    "        decoded = self.decoder(encoded)\n",
    "        #return decoded\n",
    "        return decoded.permute(0, 2, 1)  # Permute back to original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_channels = 16  # NUM_CHANNELS\n",
    "num_filters = 32\n",
    "batch_size = 64  # Batch size increased\n",
    "learning_rate = 0.001 #learning rate increased\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_int_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_int_train, dtype=torch.float32)\n",
    "\n",
    "# Convert validation data to PyTorch tensors\n",
    "X_val_tensor = torch.tensor(X_int_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_int_val, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader for training set\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create DataLoader for validation set\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # No need to shuffle validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.0010402239859104156, Validation Loss: 0.0008762090272891025\n",
      "Epoch [1/25], Train Loss: 0.0007955128094181418, Validation Loss: 0.0007484551014689107\n",
      "Epoch [1/25], Train Loss: 0.0008230623207055032, Validation Loss: 0.0006404953155045708\n",
      "Epoch [1/25], Train Loss: 0.0006154373404569924, Validation Loss: 0.0005563614366110414\n",
      "Epoch [1/25], Train Loss: 0.0005577924894168973, Validation Loss: 0.0004904925590381026\n",
      "Epoch [1/25], Train Loss: 0.0004940288490615785, Validation Loss: 0.00043554057095510264\n",
      "Epoch [1/25], Train Loss: 0.0004351685638539493, Validation Loss: 0.0003915241570211947\n",
      "Epoch [1/25], Train Loss: 0.00043147013639099896, Validation Loss: 0.0003570062709817042\n",
      "Epoch [1/25], Train Loss: 0.0003349939361214638, Validation Loss: 0.0003297903672015915\n",
      "Epoch [1/25], Train Loss: 0.0003357651294209063, Validation Loss: 0.00030767111165914686\n",
      "Epoch [1/25], Train Loss: 0.0002750115527305752, Validation Loss: 0.00028866416153808434\n",
      "Epoch [1/25], Train Loss: 0.00039862317498773336, Validation Loss: 0.00027191613044124096\n",
      "Epoch [1/25], Train Loss: 0.00027873911312781274, Validation Loss: 0.0002571428136434406\n",
      "Epoch [1/25], Train Loss: 0.00021946414199192077, Validation Loss: 0.00024544051460300884\n",
      "Epoch [1/25], Train Loss: 0.0002103331935359165, Validation Loss: 0.00023790774575900288\n",
      "Epoch [1/25], Train Loss: 0.00023295081336982548, Validation Loss: 0.00023267361684702336\n",
      "Epoch [1/25], Train Loss: 0.00022313384397421032, Validation Loss: 0.00022921100608073175\n",
      "Epoch [1/25], Train Loss: 0.0003102976770605892, Validation Loss: 0.00022664624363339197\n",
      "Epoch [1/25], Train Loss: 0.0002845540002454072, Validation Loss: 0.00022493466870704044\n",
      "Epoch [1/25], Train Loss: 0.0002987945917993784, Validation Loss: 0.00022416783031076193\n",
      "Epoch [1/25], Train Loss: 0.00022933089348953217, Validation Loss: 0.00022434200121400257\n",
      "Epoch [1/25], Train Loss: 0.00023967029119376093, Validation Loss: 0.00022562558976157258\n",
      "Epoch [1/25], Train Loss: 0.0003011654189322144, Validation Loss: 0.0002265076948485027\n",
      "Epoch [1/25], Train Loss: 0.0001965924457181245, Validation Loss: 0.00022733291358842205\n",
      "Epoch [1/25], Train Loss: 0.000290076422970742, Validation Loss: 0.0002274359450287496\n",
      "Epoch [1/25], Train Loss: 0.00022050892584957182, Validation Loss: 0.00022678152987888703\n",
      "Epoch [1/25], Train Loss: 0.00023918772058095783, Validation Loss: 0.00022572265782703956\n",
      "Epoch [1/25], Train Loss: 0.0002732448047026992, Validation Loss: 0.0002246677487467726\n",
      "Epoch [1/25], Train Loss: 0.00020479473460000008, Validation Loss: 0.00022387576076046873\n",
      "Epoch [1/25], Train Loss: 0.00023699639132246375, Validation Loss: 0.00022333182375101993\n",
      "Epoch [1/25], Train Loss: 0.00022306019673123956, Validation Loss: 0.0002228759665740654\n",
      "Epoch [1/25], Train Loss: 0.0002655804855749011, Validation Loss: 0.0002223462205923473\n",
      "Epoch [1/25], Train Loss: 0.0002282035129610449, Validation Loss: 0.0002216881141066551\n",
      "Epoch [1/25], Train Loss: 0.00013497537293005735, Validation Loss: 0.0002209590486017987\n",
      "Epoch [1/25], Train Loss: 0.0002516000240575522, Validation Loss: 0.0002202518633566797\n",
      "Epoch [1/25], Train Loss: 0.0002106473402818665, Validation Loss: 0.00021961608532971392\n",
      "Epoch [1/25], Train Loss: 0.00022394570987671614, Validation Loss: 0.0002190393580046172\n",
      "Epoch [1/25], Train Loss: 0.0003193176817148924, Validation Loss: 0.0002184854083073636\n",
      "Epoch [1/25], Train Loss: 0.00015768843877594918, Validation Loss: 0.00021794831069807212\n",
      "Epoch [1/25], Train Loss: 0.00022932939464226365, Validation Loss: 0.00021748700140354534\n",
      "Epoch [1/25], Train Loss: 0.00027891117497347295, Validation Loss: 0.0002171631621119256\n",
      "Epoch [1/25], Train Loss: 0.00023052989854477346, Validation Loss: 0.00021699650678783656\n",
      "Epoch [1/25], Train Loss: 0.0002882432017941028, Validation Loss: 0.00021697649887452523\n",
      "Epoch [1/25], Train Loss: 0.0002728722174651921, Validation Loss: 0.0002170005871448666\n",
      "Epoch [1/25], Train Loss: 0.0002054927172139287, Validation Loss: 0.00021701465011574327\n",
      "Epoch [1/25], Train Loss: 0.0001968150318134576, Validation Loss: 0.0002170109898239995\n",
      "Epoch [1/25], Train Loss: 0.0002568710769992322, Validation Loss: 0.00021700947060404968\n",
      "Epoch [1/25], Train Loss: 0.00020235580450389534, Validation Loss: 0.0002170295842612783\n",
      "Epoch [1/25], Train Loss: 0.00015551141405012459, Validation Loss: 0.00021708112520476183\n",
      "Epoch [1/25], Train Loss: 0.0002070948394248262, Validation Loss: 0.00021713323949370533\n",
      "Epoch [1/25], Train Loss: 0.00019244443683419377, Validation Loss: 0.000217142054073823\n",
      "Epoch [1/25], Train Loss: 0.0002473880012985319, Validation Loss: 0.00021709620001881074\n",
      "Epoch [1/25], Train Loss: 0.00031225860584527254, Validation Loss: 0.00021701201524895926\n",
      "Epoch [1/25], Train Loss: 0.00020204726024530828, Validation Loss: 0.00021691000729333608\n",
      "Epoch [1/25], Train Loss: 0.0001864404184743762, Validation Loss: 0.0002168008921823154\n",
      "Epoch [1/25], Train Loss: 0.00030544993933290243, Validation Loss: 0.0002166964948022117\n",
      "Epoch [1/25], Train Loss: 0.00016880726616363972, Validation Loss: 0.00021659808213977765\n",
      "Epoch [1/25], Train Loss: 0.00018032312800642103, Validation Loss: 0.00021649123615740488\n",
      "Epoch [1/25], Train Loss: 0.00020199250138830394, Validation Loss: 0.00021639047287559757\n",
      "Epoch [1/25], Train Loss: 0.00022455463476944715, Validation Loss: 0.00021631111934160193\n",
      "Epoch [1/25], Train Loss: 0.00023606080503668636, Validation Loss: 0.00021624737128149717\n",
      "Epoch [1/25], Train Loss: 0.00023734921705909073, Validation Loss: 0.00021618293152035525\n",
      "Epoch [1/25], Train Loss: 0.0002478255773894489, Validation Loss: 0.00021611938912731907\n",
      "Epoch [1/25], Train Loss: 0.00025184868718497455, Validation Loss: 0.00021606263374754537\n",
      "Epoch [1/25], Train Loss: 0.00020809643319807947, Validation Loss: 0.00021599319685871403\n",
      "Epoch [1/25], Train Loss: 0.00015319323574658483, Validation Loss: 0.00021594274536861728\n",
      "Epoch [1/25], Train Loss: 0.00020164732995908707, Validation Loss: 0.00021590967371594162\n",
      "Epoch [1/25], Train Loss: 0.00021740354713983834, Validation Loss: 0.0002158721365655462\n",
      "Epoch [1/25], Train Loss: 0.00020078479428775609, Validation Loss: 0.00021584287751466035\n",
      "Epoch [1/25], Train Loss: 0.00027697448967956007, Validation Loss: 0.00021580573617635917\n",
      "Epoch [1/25], Train Loss: 0.00018093179096467793, Validation Loss: 0.0002157398887599508\n",
      "Epoch [1/25], Train Loss: 0.0002207854704465717, Validation Loss: 0.00021568378724623471\n",
      "Epoch [1/25], Train Loss: 0.00028762719011865556, Validation Loss: 0.0002156293213677903\n",
      "Epoch [1/25], Train Loss: 0.00025545357493683696, Validation Loss: 0.0002155635360395536\n",
      "Epoch [1/25], Train Loss: 0.000200611466425471, Validation Loss: 0.0002155139489332214\n",
      "Epoch [1/25], Train Loss: 0.00019024807261303067, Validation Loss: 0.00021545006117473046\n",
      "Epoch [1/25], Train Loss: 0.00022259543766267598, Validation Loss: 0.00021538175739503154\n",
      "Epoch [1/25], Train Loss: 0.00018110638484358788, Validation Loss: 0.00021531590706824015\n",
      "Epoch [1/25], Train Loss: 0.00020258089352864772, Validation Loss: 0.00021524674763592582\n",
      "Epoch [1/25], Train Loss: 0.00026744743809103966, Validation Loss: 0.00021516872996774812\n",
      "Epoch [1/25], Train Loss: 0.00020462732936721295, Validation Loss: 0.00021507115937614192\n",
      "Epoch [1/25], Train Loss: 0.0002506307791918516, Validation Loss: 0.00021497878866891067\n",
      "Epoch [1/25], Train Loss: 0.0002682320191524923, Validation Loss: 0.00021487928364270678\n",
      "Epoch [1/25], Train Loss: 0.0002503546711523086, Validation Loss: 0.00021477144327946006\n",
      "Epoch [1/25], Train Loss: 0.0002011095202760771, Validation Loss: 0.00021465600778659185\n",
      "Epoch [1/25], Train Loss: 0.0002111644862452522, Validation Loss: 0.00021453782392200083\n",
      "Epoch [1/25], Train Loss: 0.00027774827321991324, Validation Loss: 0.00021441977490515757\n",
      "Epoch [1/25], Train Loss: 0.00023977048113010824, Validation Loss: 0.00021428530162665994\n",
      "Epoch [1/25], Train Loss: 0.0002585460606496781, Validation Loss: 0.0002141439792467281\n",
      "Epoch [1/25], Train Loss: 0.00022897291637491435, Validation Loss: 0.0002139833552064374\n",
      "Epoch [1/25], Train Loss: 0.00020151349599473178, Validation Loss: 0.00021382557849089305\n",
      "Epoch [1/25], Train Loss: 0.0001850165572250262, Validation Loss: 0.00021364815765991806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Loss: 0.0002499783877283335, Validation Loss: 0.00021346160404694576\n",
      "Epoch [1/25], Train Loss: 0.0002660565951373428, Validation Loss: 0.00021325892012100667\n",
      "Epoch [1/25], Train Loss: 0.00024923330056481063, Validation Loss: 0.00021303065004758538\n",
      "Epoch [1/25], Train Loss: 0.00022081428323872387, Validation Loss: 0.00021279630212423702\n",
      "Epoch [1/25], Train Loss: 0.00029712211107835174, Validation Loss: 0.00021254085198355217\n",
      "Epoch [1/25], Train Loss: 0.0001807851658668369, Validation Loss: 0.00021226494767082234\n",
      "Epoch [1/25], Train Loss: 0.00022951811843086034, Validation Loss: 0.0002119819720974192\n",
      "Epoch [1/25], Train Loss: 0.00018803634156938642, Validation Loss: 0.00021168635382006566\n",
      "Epoch [1/25], Train Loss: 0.00019735416572075337, Validation Loss: 0.00021136629026538383\n",
      "Epoch [1/25], Train Loss: 0.0002638969453983009, Validation Loss: 0.00021105888202631226\n",
      "Epoch [1/25], Train Loss: 0.00020691685494966805, Validation Loss: 0.00021072920450630286\n",
      "Epoch [1/25], Train Loss: 0.0001822411286411807, Validation Loss: 0.00021028085708773385\n",
      "Epoch [1/25], Train Loss: 0.00020755440345965326, Validation Loss: 0.00021000654087401926\n",
      "Epoch [1/25], Train Loss: 0.0001880853233160451, Validation Loss: 0.00020980795476740848\n",
      "Epoch [1/25], Train Loss: 0.00019504012016113847, Validation Loss: 0.00020933335472363978\n",
      "Epoch [1/25], Train Loss: 0.00012939286534674466, Validation Loss: 0.00020889578736387192\n",
      "Epoch [1/25], Train Loss: 0.00023936640354804695, Validation Loss: 0.00020859362654543172\n",
      "Epoch [1/25], Train Loss: 0.00015222994261421263, Validation Loss: 0.00020841429941356182\n",
      "Epoch [1/25], Train Loss: 0.00021931416995357722, Validation Loss: 0.00020812246366403998\n",
      "Epoch [1/25], Train Loss: 0.00027209552354179323, Validation Loss: 0.0002075218993316715\n",
      "Epoch [1/25], Train Loss: 0.00024713316815905273, Validation Loss: 0.00020697028085123748\n",
      "Epoch [1/25], Train Loss: 0.00015464912576135248, Validation Loss: 0.00020657911663874985\n",
      "Epoch [1/25], Train Loss: 0.00026495696511119604, Validation Loss: 0.00020633307673657934\n",
      "Epoch [1/25], Train Loss: 0.00023267879441846162, Validation Loss: 0.00020624090005488444\n",
      "Epoch [1/25], Train Loss: 0.00029326562071219087, Validation Loss: 0.00020632280114417275\n",
      "Epoch [1/25], Train Loss: 0.000210810627322644, Validation Loss: 0.00020588415306216728\n",
      "Epoch [1/25], Train Loss: 0.0001531401794636622, Validation Loss: 0.00020464410966572661\n",
      "Epoch [1/25], Train Loss: 0.00023143844737205654, Validation Loss: 0.00020374640638086324\n",
      "Epoch [1/25], Train Loss: 0.0002158049028366804, Validation Loss: 0.00020387588301673532\n",
      "Epoch [1/25], Train Loss: 0.0001994950871448964, Validation Loss: 0.00020391918272556116\n",
      "Epoch [1/25], Train Loss: 0.00023914618941489607, Validation Loss: 0.00020288514497224241\n",
      "Epoch [1/25], Train Loss: 0.0002301432250533253, Validation Loss: 0.00020179320805861303\n",
      "Epoch [1/25], Train Loss: 0.00019892631098628044, Validation Loss: 0.00020158082576623808\n",
      "Epoch [1/25], Train Loss: 0.0002411401947028935, Validation Loss: 0.0002016633006860502\n",
      "Epoch [1/25], Train Loss: 0.0002458786475472152, Validation Loss: 0.00020133655780227855\n",
      "Epoch [1/25], Train Loss: 0.00021195688168518245, Validation Loss: 0.00020034390036016703\n",
      "Epoch [1/25], Train Loss: 0.0002170089865103364, Validation Loss: 0.00019919207989005372\n",
      "Epoch [1/25], Train Loss: 0.00018438756524119526, Validation Loss: 0.00019834925333270804\n",
      "Epoch [1/25], Train Loss: 0.00023181235883384943, Validation Loss: 0.00019791189891596634\n",
      "Epoch [1/25], Train Loss: 0.0002196659188484773, Validation Loss: 0.00019792431024446462\n",
      "Epoch [1/25], Train Loss: 0.00024669282720424235, Validation Loss: 0.00019855090940836816\n",
      "Epoch [1/25], Train Loss: 0.00012740277452394366, Validation Loss: 0.00019979200442321599\n",
      "Epoch [2/25], Train Loss: 0.0001610235485713929, Validation Loss: 0.00019947231436769167\n",
      "Epoch [2/25], Train Loss: 0.00018383619317319244, Validation Loss: 0.0001957929596149673\n",
      "Epoch [2/25], Train Loss: 0.00026997775421477854, Validation Loss: 0.00019415530647772054\n",
      "Epoch [2/25], Train Loss: 0.00024513850803487003, Validation Loss: 0.00019595820776885375\n",
      "Epoch [2/25], Train Loss: 0.00019709473417606205, Validation Loss: 0.00019653106137411668\n",
      "Epoch [2/25], Train Loss: 0.00024506900808773935, Validation Loss: 0.00019344456037894512\n",
      "Epoch [2/25], Train Loss: 0.00010404382919659838, Validation Loss: 0.00019150499768632773\n",
      "Epoch [2/25], Train Loss: 0.00020213070092722774, Validation Loss: 0.00019308194023324177\n",
      "Epoch [2/25], Train Loss: 0.00021089740039315075, Validation Loss: 0.00019369836954865604\n",
      "Epoch [2/25], Train Loss: 0.00020923258853144944, Validation Loss: 0.00019091350065233807\n",
      "Epoch [2/25], Train Loss: 0.0001853661087807268, Validation Loss: 0.0001888777357332098\n",
      "Epoch [2/25], Train Loss: 0.00014609444770030677, Validation Loss: 0.00018949877267004922\n",
      "Epoch [2/25], Train Loss: 0.00015260287909768522, Validation Loss: 0.00019047812966164202\n",
      "Epoch [2/25], Train Loss: 0.00016596248315181583, Validation Loss: 0.00018945657648146154\n",
      "Epoch [2/25], Train Loss: 0.0002106825413648039, Validation Loss: 0.00018699862703215332\n",
      "Epoch [2/25], Train Loss: 0.00015657756011933088, Validation Loss: 0.00018576840035772573\n",
      "Epoch [2/25], Train Loss: 0.00021885563910473138, Validation Loss: 0.00018610316668249045\n",
      "Epoch [2/25], Train Loss: 0.00022959774651098996, Validation Loss: 0.00018687160675957178\n",
      "Epoch [2/25], Train Loss: 0.00022870827524457127, Validation Loss: 0.00018704910665595282\n",
      "Epoch [2/25], Train Loss: 0.00018210679991170764, Validation Loss: 0.00018631580993921186\n",
      "Epoch [2/25], Train Loss: 0.0002627884387038648, Validation Loss: 0.00018425408634357155\n",
      "Epoch [2/25], Train Loss: 0.00017299491446465254, Validation Loss: 0.0001822615153893518\n",
      "Epoch [2/25], Train Loss: 0.00017495432985015213, Validation Loss: 0.00018098926617919156\n",
      "Epoch [2/25], Train Loss: 0.0001811144029488787, Validation Loss: 0.00018041959071221452\n",
      "Epoch [2/25], Train Loss: 0.00023244482872541994, Validation Loss: 0.0001805180707985225\n",
      "Epoch [2/25], Train Loss: 0.0001623133139219135, Validation Loss: 0.00018214979063486681\n",
      "Epoch [2/25], Train Loss: 0.00017319661856163293, Validation Loss: 0.0001873838448470148\n",
      "Epoch [2/25], Train Loss: 0.00020843284437432885, Validation Loss: 0.00019571531447581947\n",
      "Epoch [2/25], Train Loss: 0.00022833357797935605, Validation Loss: 0.00019318212386375914\n",
      "Epoch [2/25], Train Loss: 0.0001990539749385789, Validation Loss: 0.0001778000082898264\n",
      "Epoch [2/25], Train Loss: 0.0002755825698841363, Validation Loss: 0.00018129132319396983\n",
      "Epoch [2/25], Train Loss: 0.00016615301137790084, Validation Loss: 0.0001879322032133738\n",
      "Epoch [2/25], Train Loss: 0.00016506077372469008, Validation Loss: 0.0001770518463066158\n",
      "Epoch [2/25], Train Loss: 0.0001791725226212293, Validation Loss: 0.0001775316966813989\n",
      "Epoch [2/25], Train Loss: 0.0001897600741358474, Validation Loss: 0.0001836529064651889\n",
      "Epoch [2/25], Train Loss: 0.00019491586135700345, Validation Loss: 0.00017528379248687997\n",
      "Epoch [2/25], Train Loss: 0.00018816876399796456, Validation Loss: 0.00017540360374065738\n",
      "Epoch [2/25], Train Loss: 0.0001930505968630314, Validation Loss: 0.0001796695297040666\n",
      "Epoch [2/25], Train Loss: 0.00014556427777279168, Validation Loss: 0.00017307203185434143\n",
      "Epoch [2/25], Train Loss: 0.00019275931117590517, Validation Loss: 0.00017362478780948246\n",
      "Epoch [2/25], Train Loss: 0.00020228301582392305, Validation Loss: 0.0001769483201011705\n",
      "Epoch [2/25], Train Loss: 0.00019179258379153907, Validation Loss: 0.0001715736934177888\n",
      "Epoch [2/25], Train Loss: 0.00018333176558371633, Validation Loss: 0.00017138324668242906\n",
      "Epoch [2/25], Train Loss: 0.00014965653826948255, Validation Loss: 0.0001740308643396323\n",
      "Epoch [2/25], Train Loss: 0.0001443692744942382, Validation Loss: 0.0001705088434391655\n",
      "Epoch [2/25], Train Loss: 0.00021781274699606001, Validation Loss: 0.00016904992565590268\n",
      "Epoch [2/25], Train Loss: 0.00014509166067000479, Validation Loss: 0.0001713071794559558\n",
      "Epoch [2/25], Train Loss: 0.00017280082101933658, Validation Loss: 0.0001698262722735914\n",
      "Epoch [2/25], Train Loss: 0.0001984558766707778, Validation Loss: 0.00016730788678008442\n",
      "Epoch [2/25], Train Loss: 0.0001239478588104248, Validation Loss: 0.0001684879796812311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Train Loss: 0.00018490299407858402, Validation Loss: 0.00016917341369359444\n",
      "Epoch [2/25], Train Loss: 0.00021040529827587306, Validation Loss: 0.00016699241192933792\n",
      "Epoch [2/25], Train Loss: 0.0001636797096580267, Validation Loss: 0.00016553376869220908\n",
      "Epoch [2/25], Train Loss: 0.00020422303350642323, Validation Loss: 0.00016622823168290778\n",
      "Epoch [2/25], Train Loss: 0.00017752779240254313, Validation Loss: 0.00016657264398721358\n",
      "Epoch [2/25], Train Loss: 0.00020763278007507324, Validation Loss: 0.0001656444796632665\n",
      "Epoch [2/25], Train Loss: 0.00014934205682948232, Validation Loss: 0.0001640212756077138\n",
      "Epoch [2/25], Train Loss: 0.00017022161046043038, Validation Loss: 0.00016271110022595772\n",
      "Epoch [2/25], Train Loss: 0.00018257266492582858, Validation Loss: 0.0001622915447417957\n",
      "Epoch [2/25], Train Loss: 0.00018186375382356346, Validation Loss: 0.00016263034873797248\n",
      "Epoch [2/25], Train Loss: 0.00012909815995953977, Validation Loss: 0.00016352577028252806\n",
      "Epoch [2/25], Train Loss: 0.0002775843895506114, Validation Loss: 0.00016492330226659154\n",
      "Epoch [2/25], Train Loss: 0.00014894707419443876, Validation Loss: 0.00016686757880961521\n",
      "Epoch [2/25], Train Loss: 0.0001778262812877074, Validation Loss: 0.00016918303299462423\n",
      "Epoch [2/25], Train Loss: 0.00019301427528262138, Validation Loss: 0.00016957042729094003\n",
      "Epoch [2/25], Train Loss: 0.0002059649705188349, Validation Loss: 0.0001658608452999033\n",
      "Epoch [2/25], Train Loss: 0.00019150057050865144, Validation Loss: 0.00016025592049118131\n",
      "Epoch [2/25], Train Loss: 0.00015674985479563475, Validation Loss: 0.00015771645800365756\n",
      "Epoch [2/25], Train Loss: 0.00014192686649039388, Validation Loss: 0.0001591372230905108\n",
      "Epoch [2/25], Train Loss: 0.0001519270008429885, Validation Loss: 0.00016219449995939308\n",
      "Epoch [2/25], Train Loss: 0.00018574984278529882, Validation Loss: 0.00016367486241506413\n",
      "Epoch [2/25], Train Loss: 0.0001812564005376771, Validation Loss: 0.0001618430954598201\n",
      "Epoch [2/25], Train Loss: 0.00013027785462327302, Validation Loss: 0.00015777335356688128\n",
      "Epoch [2/25], Train Loss: 0.0001495414471719414, Validation Loss: 0.0001551222395695125\n",
      "Epoch [2/25], Train Loss: 0.00014524832658935338, Validation Loss: 0.00015552972569518413\n",
      "Epoch [2/25], Train Loss: 0.0001432267890777439, Validation Loss: 0.00015752674031925076\n",
      "Epoch [2/25], Train Loss: 0.00019510084530338645, Validation Loss: 0.00015874995297053828\n",
      "Epoch [2/25], Train Loss: 0.0001687072217464447, Validation Loss: 0.00015761618075581889\n",
      "Epoch [2/25], Train Loss: 0.00018489804642740637, Validation Loss: 0.0001548228664129662\n",
      "Epoch [2/25], Train Loss: 0.0001209671245305799, Validation Loss: 0.00015260933190196132\n",
      "Epoch [2/25], Train Loss: 0.0001312482636421919, Validation Loss: 0.00015196931005145113\n",
      "Epoch [2/25], Train Loss: 0.00018458235717844218, Validation Loss: 0.0001526285467358927\n",
      "Epoch [2/25], Train Loss: 0.0001317618734901771, Validation Loss: 0.00015351843903772534\n",
      "Epoch [2/25], Train Loss: 0.00012973754201084375, Validation Loss: 0.0001539156015496701\n",
      "Epoch [2/25], Train Loss: 0.00011894110502908006, Validation Loss: 0.00015334392422422145\n",
      "Epoch [2/25], Train Loss: 0.0001750824594637379, Validation Loss: 0.00015156675945036114\n",
      "Epoch [2/25], Train Loss: 0.00011242139589739963, Validation Loss: 0.00014976550398084024\n",
      "Epoch [2/25], Train Loss: 0.00013339069846551865, Validation Loss: 0.00014845418772893026\n",
      "Epoch [2/25], Train Loss: 0.00018481889856047928, Validation Loss: 0.00014782242360524833\n",
      "Epoch [2/25], Train Loss: 0.00016203585255425423, Validation Loss: 0.00014798939179551477\n",
      "Epoch [2/25], Train Loss: 0.00021318584913387895, Validation Loss: 0.0001501550762138019\n",
      "Epoch [2/25], Train Loss: 0.00013378674339037389, Validation Loss: 0.00015919095021672548\n",
      "Epoch [2/25], Train Loss: 0.00018666696269065142, Validation Loss: 0.00017912160546984524\n",
      "Epoch [2/25], Train Loss: 0.0001854243892012164, Validation Loss: 0.0001903855746301512\n",
      "Epoch [2/25], Train Loss: 0.0001972646568901837, Validation Loss: 0.00016227347950916737\n",
      "Epoch [2/25], Train Loss: 0.0001488316775066778, Validation Loss: 0.00014491788897430524\n",
      "Epoch [2/25], Train Loss: 0.00018112832913175225, Validation Loss: 0.0001681225112406537\n",
      "Epoch [2/25], Train Loss: 0.0001645575393922627, Validation Loss: 0.00016001304514550913\n",
      "Epoch [2/25], Train Loss: 0.00018761011597234756, Validation Loss: 0.00014305328077170997\n",
      "Epoch [2/25], Train Loss: 0.00011088037717854604, Validation Loss: 0.000158091901782124\n",
      "Epoch [2/25], Train Loss: 0.00017669434600975364, Validation Loss: 0.0001500106028591593\n",
      "Epoch [2/25], Train Loss: 0.00015221342619042844, Validation Loss: 0.00014276037885186573\n",
      "Epoch [2/25], Train Loss: 0.00018237477343063802, Validation Loss: 0.00015343897102866323\n",
      "Epoch [2/25], Train Loss: 0.0001411308767274022, Validation Loss: 0.00014182606246322395\n",
      "Epoch [2/25], Train Loss: 0.00011718286987161264, Validation Loss: 0.0001443270792757782\n",
      "Epoch [2/25], Train Loss: 0.00016354420222342014, Validation Loss: 0.00014663291367469355\n",
      "Epoch [2/25], Train Loss: 0.00019175256602466106, Validation Loss: 0.00013821457493274163\n",
      "Epoch [2/25], Train Loss: 0.00013450680125970393, Validation Loss: 0.00014469121088040994\n",
      "Epoch [2/25], Train Loss: 0.0001501927908975631, Validation Loss: 0.00013964375927268217\n",
      "Epoch [2/25], Train Loss: 0.0001392025442328304, Validation Loss: 0.0001380548511709397\n",
      "Epoch [2/25], Train Loss: 0.00015726027777418494, Validation Loss: 0.00014111962324629226\n",
      "Epoch [2/25], Train Loss: 0.00018952363461721689, Validation Loss: 0.00013618103742677097\n",
      "Epoch [2/25], Train Loss: 0.00011348987754900008, Validation Loss: 0.00013697587079756582\n",
      "Epoch [2/25], Train Loss: 0.00016505927487742156, Validation Loss: 0.00013749206215531254\n",
      "Epoch [2/25], Train Loss: 0.00015833615907467902, Validation Loss: 0.00013363130565267057\n",
      "Epoch [2/25], Train Loss: 0.00013160172966308892, Validation Loss: 0.00013496325118467212\n",
      "Epoch [2/25], Train Loss: 0.00010503108205739409, Validation Loss: 0.0001348051645133334\n",
      "Epoch [2/25], Train Loss: 0.00011628433276200667, Validation Loss: 0.00013133753624667104\n",
      "Epoch [2/25], Train Loss: 0.00010973270400427282, Validation Loss: 0.00013339611711368586\n",
      "Epoch [2/25], Train Loss: 0.00011493187048472464, Validation Loss: 0.00013237768095374728\n",
      "Epoch [2/25], Train Loss: 0.00015993382839951664, Validation Loss: 0.00012985999637749046\n",
      "Epoch [2/25], Train Loss: 0.00013271771604195237, Validation Loss: 0.00013067552111654853\n",
      "Epoch [2/25], Train Loss: 0.0001378076703986153, Validation Loss: 0.0001305638671813843\n",
      "Epoch [2/25], Train Loss: 0.00010540695075178519, Validation Loss: 0.00012841528077842668\n",
      "Epoch [2/25], Train Loss: 0.00016473345749545842, Validation Loss: 0.00012815074878744782\n",
      "Epoch [2/25], Train Loss: 0.0001219781770487316, Validation Loss: 0.0001292979417485185\n",
      "Epoch [2/25], Train Loss: 0.00010300981375621632, Validation Loss: 0.0001274891057012913\n",
      "Epoch [2/25], Train Loss: 0.00015959794109221548, Validation Loss: 0.00012589323062760135\n",
      "Epoch [2/25], Train Loss: 0.00012261929805390537, Validation Loss: 0.0001261821947991848\n",
      "Epoch [2/25], Train Loss: 0.00015443708980455995, Validation Loss: 0.00012669755378738045\n",
      "Epoch [2/25], Train Loss: 0.0001490586146246642, Validation Loss: 0.0001251522922151101\n",
      "Epoch [2/25], Train Loss: 0.00012209823762532324, Validation Loss: 0.0001242735384342571\n",
      "Epoch [2/25], Train Loss: 0.00010837212175829336, Validation Loss: 0.00012475371040636672\n",
      "Epoch [2/25], Train Loss: 0.0001291099179070443, Validation Loss: 0.00012718208017759025\n",
      "Epoch [3/25], Train Loss: 0.0001746606722008437, Validation Loss: 0.00013240679254522547\n",
      "Epoch [3/25], Train Loss: 0.0001299471186939627, Validation Loss: 0.00013701057323487476\n",
      "Epoch [3/25], Train Loss: 0.00012749695451930165, Validation Loss: 0.00013306676604164143\n",
      "Epoch [3/25], Train Loss: 0.0001251186477020383, Validation Loss: 0.00012319373927311973\n",
      "Epoch [3/25], Train Loss: 0.00011054961214540526, Validation Loss: 0.00012190636771265417\n",
      "Epoch [3/25], Train Loss: 0.00013754780229646713, Validation Loss: 0.00012793989832668255\n",
      "Epoch [3/25], Train Loss: 0.00014221880701370537, Validation Loss: 0.000129208380531054\n",
      "Epoch [3/25], Train Loss: 9.172505815513432e-05, Validation Loss: 0.0001226962689543143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Train Loss: 0.00014417745114769787, Validation Loss: 0.00011950384262794008\n",
      "Epoch [3/25], Train Loss: 0.0001315661211265251, Validation Loss: 0.00012455677788238972\n",
      "Epoch [3/25], Train Loss: 0.00010506081889616325, Validation Loss: 0.00013519212176712851\n",
      "Epoch [3/25], Train Loss: 0.00012263674580026418, Validation Loss: 0.0001308826923680802\n",
      "Epoch [3/25], Train Loss: 0.0001100286899600178, Validation Loss: 0.0001191534169871981\n",
      "Epoch [3/25], Train Loss: 0.00010774108523037285, Validation Loss: 0.0001227621299525102\n",
      "Epoch [3/25], Train Loss: 0.00017005107656586915, Validation Loss: 0.00012784363304187233\n",
      "Epoch [3/25], Train Loss: 0.00012181913916720077, Validation Loss: 0.00012296659260755405\n",
      "Epoch [3/25], Train Loss: 0.00012565968791022897, Validation Loss: 0.00011842311408448344\n",
      "Epoch [3/25], Train Loss: 0.00011046593863284215, Validation Loss: 0.00012214138841954992\n",
      "Epoch [3/25], Train Loss: 0.00010508347622817382, Validation Loss: 0.000124270589731168\n",
      "Epoch [3/25], Train Loss: 0.00014680727326776832, Validation Loss: 0.00011852114888218541\n",
      "Epoch [3/25], Train Loss: 0.00013478018809109926, Validation Loss: 0.00011798708437709138\n",
      "Epoch [3/25], Train Loss: 0.0001216173914144747, Validation Loss: 0.00012136274405444662\n",
      "Epoch [3/25], Train Loss: 0.00010516781912883744, Validation Loss: 0.00011986413252695153\n",
      "Epoch [3/25], Train Loss: 0.00012449869245756418, Validation Loss: 0.00011713359660158555\n",
      "Epoch [3/25], Train Loss: 0.0001407699310220778, Validation Loss: 0.00011736061666548873\n",
      "Epoch [3/25], Train Loss: 0.00011878010991495103, Validation Loss: 0.00011931162492449706\n",
      "Epoch [3/25], Train Loss: 0.00014895939966663718, Validation Loss: 0.0001187497361873587\n",
      "Epoch [3/25], Train Loss: 0.00012930673256050795, Validation Loss: 0.00011601663815478484\n",
      "Epoch [3/25], Train Loss: 0.00010823606862686574, Validation Loss: 0.00011611096754980584\n",
      "Epoch [3/25], Train Loss: 0.00013169397425372154, Validation Loss: 0.00011771130181538562\n",
      "Epoch [3/25], Train Loss: 0.00013614782074000686, Validation Loss: 0.0001174805389988857\n",
      "Epoch [3/25], Train Loss: 0.00012443844752851874, Validation Loss: 0.00011583488958422095\n",
      "Epoch [3/25], Train Loss: 0.00011752267164411023, Validation Loss: 0.00011496468456850077\n",
      "Epoch [3/25], Train Loss: 0.000119543015898671, Validation Loss: 0.00011571778450161218\n",
      "Epoch [3/25], Train Loss: 0.00013224325084593147, Validation Loss: 0.0001167755481825831\n",
      "Epoch [3/25], Train Loss: 0.00010376919817645103, Validation Loss: 0.00011660233625055601\n",
      "Epoch [3/25], Train Loss: 0.00012217329640407115, Validation Loss: 0.00011550632916623726\n",
      "Epoch [3/25], Train Loss: 0.00010749335342552513, Validation Loss: 0.00011449332281093424\n",
      "Epoch [3/25], Train Loss: 0.0001434766745660454, Validation Loss: 0.00011420227480509008\n",
      "Epoch [3/25], Train Loss: 9.969862003345042e-05, Validation Loss: 0.00011441345365407567\n",
      "Epoch [3/25], Train Loss: 0.00017455285706091672, Validation Loss: 0.00011662433438080674\n",
      "Epoch [3/25], Train Loss: 9.56990770646371e-05, Validation Loss: 0.0001225288583858249\n",
      "Epoch [3/25], Train Loss: 0.00013687514001503587, Validation Loss: 0.000137892802983212\n",
      "Epoch [3/25], Train Loss: 0.00015295125194825232, Validation Loss: 0.000148148370499257\n",
      "Epoch [3/25], Train Loss: 0.00014142140571493655, Validation Loss: 0.00013211679906817154\n",
      "Epoch [3/25], Train Loss: 0.00015452936349902302, Validation Loss: 0.00011429380683694034\n",
      "Epoch [3/25], Train Loss: 0.0001280241849599406, Validation Loss: 0.00012335932745675867\n",
      "Epoch [3/25], Train Loss: 0.000126458631712012, Validation Loss: 0.0001322277452951918\n",
      "Epoch [3/25], Train Loss: 0.00014451156312134117, Validation Loss: 0.0001208318441058509\n",
      "Epoch [3/25], Train Loss: 0.00011723095667548478, Validation Loss: 0.00011483296887793888\n",
      "Epoch [3/25], Train Loss: 0.00014133949298411608, Validation Loss: 0.00012345666812810425\n",
      "Epoch [3/25], Train Loss: 0.00013150396989658475, Validation Loss: 0.00012306503631407396\n",
      "Epoch [3/25], Train Loss: 0.00012340812827460468, Validation Loss: 0.00011402844975236804\n",
      "Epoch [3/25], Train Loss: 0.0001380891480948776, Validation Loss: 0.000117645321006421\n",
      "Epoch [3/25], Train Loss: 0.00011392031592549756, Validation Loss: 0.00012188688027284419\n",
      "Epoch [3/25], Train Loss: 9.852712537394837e-05, Validation Loss: 0.00011468404166710873\n",
      "Epoch [3/25], Train Loss: 0.00010488976840861142, Validation Loss: 0.00011461367830634117\n",
      "Epoch [3/25], Train Loss: 0.00011745833762688562, Validation Loss: 0.00011912603707363208\n",
      "Epoch [3/25], Train Loss: 8.290006371680647e-05, Validation Loss: 0.0001149213538155891\n",
      "Epoch [3/25], Train Loss: 0.00011228067887714133, Validation Loss: 0.00011335363087709993\n",
      "Epoch [3/25], Train Loss: 0.00012148306996095926, Validation Loss: 0.00011686446280994763\n",
      "Epoch [3/25], Train Loss: 0.00011258266749791801, Validation Loss: 0.00011494840243055174\n",
      "Epoch [3/25], Train Loss: 8.971798524726182e-05, Validation Loss: 0.00011296056909486652\n",
      "Epoch [3/25], Train Loss: 0.00010866373486351222, Validation Loss: 0.00011484838226654877\n",
      "Epoch [3/25], Train Loss: 0.00013958843192085624, Validation Loss: 0.00011462700980094573\n",
      "Epoch [3/25], Train Loss: 0.0001364888303214684, Validation Loss: 0.00011287461335693175\n",
      "Epoch [3/25], Train Loss: 0.00011208692012587562, Validation Loss: 0.00011331579056180392\n",
      "Epoch [3/25], Train Loss: 0.00011796401668107137, Validation Loss: 0.00011427113058743998\n",
      "Epoch [3/25], Train Loss: 0.0001415165897924453, Validation Loss: 0.00011283557784433166\n",
      "Epoch [3/25], Train Loss: 9.813806536840275e-05, Validation Loss: 0.00011234239500481635\n",
      "Epoch [3/25], Train Loss: 0.00013512266741599888, Validation Loss: 0.00011365876610701283\n",
      "Epoch [3/25], Train Loss: 0.00010347572242608294, Validation Loss: 0.00011291314925377567\n",
      "Epoch [3/25], Train Loss: 0.00011977808026131243, Validation Loss: 0.00011187224493672451\n",
      "Epoch [3/25], Train Loss: 0.00012930082448292524, Validation Loss: 0.0001129043298230196\n",
      "Epoch [3/25], Train Loss: 0.00011727250239346176, Validation Loss: 0.0001128765366350611\n",
      "Epoch [3/25], Train Loss: 0.00012082024477422237, Validation Loss: 0.00011180814569039891\n",
      "Epoch [3/25], Train Loss: 0.00011003445251844823, Validation Loss: 0.0001119622325253052\n",
      "Epoch [3/25], Train Loss: 0.00011935218935832381, Validation Loss: 0.00011249151818143825\n",
      "Epoch [3/25], Train Loss: 0.00012245358084328473, Validation Loss: 0.00011202932413046559\n",
      "Epoch [3/25], Train Loss: 0.00010929736163234338, Validation Loss: 0.00011145695025334134\n",
      "Epoch [3/25], Train Loss: 8.454449562123045e-05, Validation Loss: 0.00011177591950399801\n",
      "Epoch [3/25], Train Loss: 0.0001259868877241388, Validation Loss: 0.00011194735464717573\n",
      "Epoch [3/25], Train Loss: 9.729735756991431e-05, Validation Loss: 0.00011144479261323188\n",
      "Epoch [3/25], Train Loss: 0.00010413808195153251, Validation Loss: 0.00011115938978036865\n",
      "Epoch [3/25], Train Loss: 0.00016903565847314894, Validation Loss: 0.00011144380405312405\n",
      "Epoch [3/25], Train Loss: 0.0001359957386739552, Validation Loss: 0.00011149242636747659\n",
      "Epoch [3/25], Train Loss: 0.00011597825505305082, Validation Loss: 0.00011107773122300083\n",
      "Epoch [3/25], Train Loss: 0.00012123958003940061, Validation Loss: 0.0001109332360404854\n",
      "Epoch [3/25], Train Loss: 0.00010832131374627352, Validation Loss: 0.00011109927581856027\n",
      "Epoch [3/25], Train Loss: 0.000140465926961042, Validation Loss: 0.00011110017949249596\n",
      "Epoch [3/25], Train Loss: 0.0001024338707793504, Validation Loss: 0.0001108301769515189\n",
      "Epoch [3/25], Train Loss: 0.0001294567045988515, Validation Loss: 0.00011064233161353817\n",
      "Epoch [3/25], Train Loss: 0.00013814335397910327, Validation Loss: 0.00011067584127886221\n",
      "Epoch [3/25], Train Loss: 9.936739661497995e-05, Validation Loss: 0.00011069969962894296\n",
      "Epoch [3/25], Train Loss: 0.00011734954750863835, Validation Loss: 0.00011058010180325558\n",
      "Epoch [3/25], Train Loss: 0.00013254955410957336, Validation Loss: 0.00011039946111850441\n",
      "Epoch [3/25], Train Loss: 0.00010537933849263936, Validation Loss: 0.00011033418268198147\n",
      "Epoch [3/25], Train Loss: 0.00012228086416143924, Validation Loss: 0.00011038920104814073\n",
      "Epoch [3/25], Train Loss: 0.00013640991528518498, Validation Loss: 0.00011035864057096963\n",
      "Epoch [3/25], Train Loss: 7.937011832837015e-05, Validation Loss: 0.00011022150041147445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Train Loss: 0.0001137402214226313, Validation Loss: 0.00011009518008601542\n",
      "Epoch [3/25], Train Loss: 0.0001058712659869343, Validation Loss: 0.00011004196324696144\n",
      "Epoch [3/25], Train Loss: 0.00011359116615494713, Validation Loss: 0.000110021778770412\n",
      "Epoch [3/25], Train Loss: 0.00010808186198119074, Validation Loss: 0.00011004476255038753\n",
      "Epoch [3/25], Train Loss: 0.00010523015225771815, Validation Loss: 0.00010999166794742146\n",
      "Epoch [3/25], Train Loss: 0.00010861183545785025, Validation Loss: 0.00010985797950221846\n",
      "Epoch [3/25], Train Loss: 0.00013755427789874375, Validation Loss: 0.00010972186816312993\n",
      "Epoch [3/25], Train Loss: 0.00011116177483927459, Validation Loss: 0.00010970235113442565\n",
      "Epoch [3/25], Train Loss: 8.53046658448875e-05, Validation Loss: 0.00010966652383406958\n",
      "Epoch [3/25], Train Loss: 9.395927918376401e-05, Validation Loss: 0.00010965577772973727\n",
      "Epoch [3/25], Train Loss: 0.00012523031909950078, Validation Loss: 0.00010964851680910215\n",
      "Epoch [3/25], Train Loss: 0.00011842241656268016, Validation Loss: 0.00010951795799580092\n",
      "Epoch [3/25], Train Loss: 0.00011375392932677642, Validation Loss: 0.00010939356143353507\n",
      "Epoch [3/25], Train Loss: 0.00011749276745831594, Validation Loss: 0.00010933134326478467\n",
      "Epoch [3/25], Train Loss: 9.229659190168604e-05, Validation Loss: 0.00010926792747341096\n",
      "Epoch [3/25], Train Loss: 0.00011029531015083194, Validation Loss: 0.00010923410930748408\n",
      "Epoch [3/25], Train Loss: 0.00010032605496235192, Validation Loss: 0.00010919870692305267\n",
      "Epoch [3/25], Train Loss: 0.00014162853767629713, Validation Loss: 0.0001091529678281707\n",
      "Epoch [3/25], Train Loss: 8.07324904599227e-05, Validation Loss: 0.00010908032563747839\n",
      "Epoch [3/25], Train Loss: 0.00012101645552320406, Validation Loss: 0.00010896974563365803\n",
      "Epoch [3/25], Train Loss: 9.477751882513985e-05, Validation Loss: 0.00010888096294365823\n",
      "Epoch [3/25], Train Loss: 9.65499275480397e-05, Validation Loss: 0.0001088285556761548\n",
      "Epoch [3/25], Train Loss: 8.877095388015732e-05, Validation Loss: 0.00010876665376902868\n",
      "Epoch [3/25], Train Loss: 0.00010308399214409292, Validation Loss: 0.00010869832961664845\n",
      "Epoch [3/25], Train Loss: 0.00011889301094925031, Validation Loss: 0.0001086559195149069\n",
      "Epoch [3/25], Train Loss: 0.00011127559992019087, Validation Loss: 0.00010863099256918455\n",
      "Epoch [3/25], Train Loss: 0.0001379021123284474, Validation Loss: 0.00010858281408824648\n",
      "Epoch [3/25], Train Loss: 0.00012243057426530868, Validation Loss: 0.00010846445026497046\n",
      "Epoch [3/25], Train Loss: 9.034745744429529e-05, Validation Loss: 0.00010845250362763181\n",
      "Epoch [3/25], Train Loss: 0.00013748685887549073, Validation Loss: 0.00010846534229737396\n",
      "Epoch [3/25], Train Loss: 8.829412399791181e-05, Validation Loss: 0.00010835263237822801\n",
      "Epoch [3/25], Train Loss: 0.00011139439448015764, Validation Loss: 0.00010829805687535554\n",
      "Epoch [3/25], Train Loss: 0.00011121973511762917, Validation Loss: 0.00010831746767507866\n",
      "Epoch [3/25], Train Loss: 7.884451770223677e-05, Validation Loss: 0.00010830378596438095\n",
      "Epoch [4/25], Train Loss: 8.616614650236443e-05, Validation Loss: 0.00010837042112446701\n",
      "Epoch [4/25], Train Loss: 7.912652654340491e-05, Validation Loss: 0.00010858090778735156\n",
      "Epoch [4/25], Train Loss: 0.000111442590423394, Validation Loss: 0.0001089108894423892\n",
      "Epoch [4/25], Train Loss: 9.470171789871529e-05, Validation Loss: 0.00010939876859386763\n",
      "Epoch [4/25], Train Loss: 9.327829320682213e-05, Validation Loss: 0.00011025950370822102\n",
      "Epoch [4/25], Train Loss: 0.00011440775415394455, Validation Loss: 0.00011173662690756221\n",
      "Epoch [4/25], Train Loss: 0.00012027237244183198, Validation Loss: 0.00011408339875439803\n",
      "Epoch [4/25], Train Loss: 0.00011363431985955685, Validation Loss: 0.00011737319485594829\n",
      "Epoch [4/25], Train Loss: 0.00010492021101526916, Validation Loss: 0.00012106045760447159\n",
      "Epoch [4/25], Train Loss: 0.00011332335998304188, Validation Loss: 0.0001233485934790224\n",
      "Epoch [4/25], Train Loss: 0.00016414483252447098, Validation Loss: 0.00012151065214614695\n",
      "Epoch [4/25], Train Loss: 0.00012591811537276953, Validation Loss: 0.00011544290609890595\n",
      "Epoch [4/25], Train Loss: 0.00015602361236233264, Validation Loss: 0.0001092476086341776\n",
      "Epoch [4/25], Train Loss: 0.0001153222328866832, Validation Loss: 0.00010729970526881515\n",
      "Epoch [4/25], Train Loss: 0.0001376829168293625, Validation Loss: 0.00010993452694189425\n",
      "Epoch [4/25], Train Loss: 0.00010157602082472295, Validation Loss: 0.00011323113722028211\n",
      "Epoch [4/25], Train Loss: 0.0001064181124093011, Validation Loss: 0.00011314457709280154\n",
      "Epoch [4/25], Train Loss: 9.284000407205895e-05, Validation Loss: 0.00010953413147944957\n",
      "Epoch [4/25], Train Loss: 0.00012109950330341235, Validation Loss: 0.00010687710164347664\n",
      "Epoch [4/25], Train Loss: 0.00010730053327279165, Validation Loss: 0.00010778876167023554\n",
      "Epoch [4/25], Train Loss: 0.00015225647075567394, Validation Loss: 0.00010991983338802432\n",
      "Epoch [4/25], Train Loss: 9.628211410017684e-05, Validation Loss: 0.00010996582035052901\n",
      "Epoch [4/25], Train Loss: 9.616361057851464e-05, Validation Loss: 0.00010793141215496387\n",
      "Epoch [4/25], Train Loss: 0.00011462668771855533, Validation Loss: 0.00010652585527471577\n",
      "Epoch [4/25], Train Loss: 7.960789662320167e-05, Validation Loss: 0.0001071960519766435\n",
      "Epoch [4/25], Train Loss: 9.429535566596314e-05, Validation Loss: 0.0001084515368953968\n",
      "Epoch [4/25], Train Loss: 0.00010893157741520554, Validation Loss: 0.00010806448117364197\n",
      "Epoch [4/25], Train Loss: 0.0001171324256574735, Validation Loss: 0.00010660068219294771\n",
      "Epoch [4/25], Train Loss: 0.0001264062593691051, Validation Loss: 0.00010608346541024124\n",
      "Epoch [4/25], Train Loss: 0.0001187293091788888, Validation Loss: 0.00010666332285230359\n",
      "Epoch [4/25], Train Loss: 0.00010255342931486666, Validation Loss: 0.00010719423444243148\n",
      "Epoch [4/25], Train Loss: 0.00011819592327810824, Validation Loss: 0.00010673223878256976\n",
      "Epoch [4/25], Train Loss: 0.00011235402780584991, Validation Loss: 0.00010586450953269378\n",
      "Epoch [4/25], Train Loss: 0.00012591444829013199, Validation Loss: 0.0001057100758771412\n",
      "Epoch [4/25], Train Loss: 0.00010899564222199842, Validation Loss: 0.0001061012774395446\n",
      "Epoch [4/25], Train Loss: 0.00011236867430852726, Validation Loss: 0.00010620024938058729\n",
      "Epoch [4/25], Train Loss: 8.151773363351822e-05, Validation Loss: 0.00010575820488156751\n",
      "Epoch [4/25], Train Loss: 9.561511978972703e-05, Validation Loss: 0.00010528458418169369\n",
      "Epoch [4/25], Train Loss: 0.00010962170927086845, Validation Loss: 0.00010523544624447822\n",
      "Epoch [4/25], Train Loss: 8.967588655650616e-05, Validation Loss: 0.0001055454573361203\n",
      "Epoch [4/25], Train Loss: 0.00011651597742456943, Validation Loss: 0.00010682957896885152\n",
      "Epoch [4/25], Train Loss: 0.00010211380867986009, Validation Loss: 0.00010822086624102667\n",
      "Epoch [4/25], Train Loss: 0.00010041447239927948, Validation Loss: 0.00010812250305510436\n",
      "Epoch [4/25], Train Loss: 0.00010087584814755246, Validation Loss: 0.00010590495658107102\n",
      "Epoch [4/25], Train Loss: 0.00012513407273218036, Validation Loss: 0.00010481259814696387\n",
      "Epoch [4/25], Train Loss: 0.0001059778660419397, Validation Loss: 0.00010629006186112141\n",
      "Epoch [4/25], Train Loss: 0.00011721557530108839, Validation Loss: 0.00010708971773662293\n",
      "Epoch [4/25], Train Loss: 9.013687667902559e-05, Validation Loss: 0.00010580403613857925\n",
      "Epoch [4/25], Train Loss: 0.0001061329894582741, Validation Loss: 0.00010449731974707296\n",
      "Epoch [4/25], Train Loss: 7.679019472561777e-05, Validation Loss: 0.00010496607040598368\n",
      "Epoch [4/25], Train Loss: 0.00011558453843463212, Validation Loss: 0.00010590887007613977\n",
      "Epoch [4/25], Train Loss: 8.733979484532028e-05, Validation Loss: 0.00010538962572657814\n",
      "Epoch [4/25], Train Loss: 8.713638817425817e-05, Validation Loss: 0.00010446381881289805\n",
      "Epoch [4/25], Train Loss: 0.0001178467136924155, Validation Loss: 0.0001047482054370145\n",
      "Epoch [4/25], Train Loss: 0.0001246430038008839, Validation Loss: 0.00010510837407006572\n",
      "Epoch [4/25], Train Loss: 0.0001494167954660952, Validation Loss: 0.00010450410627527162\n",
      "Epoch [4/25], Train Loss: 0.00012548807717394084, Validation Loss: 0.00010375723844238868\n",
      "Epoch [4/25], Train Loss: 9.486909402767196e-05, Validation Loss: 0.00010408624560416986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Train Loss: 0.00011394247121643275, Validation Loss: 0.00010475924257965137\n",
      "Epoch [4/25], Train Loss: 0.00012633579899556935, Validation Loss: 0.0001043075739289634\n",
      "Epoch [4/25], Train Loss: 9.195754682878032e-05, Validation Loss: 0.00010337517305742949\n",
      "Epoch [4/25], Train Loss: 0.0001017934555420652, Validation Loss: 0.00010329400975024327\n",
      "Epoch [4/25], Train Loss: 0.0001383957569487393, Validation Loss: 0.00010378691270792235\n",
      "Epoch [4/25], Train Loss: 0.00011704017379088327, Validation Loss: 0.00010375018852452438\n",
      "Epoch [4/25], Train Loss: 9.039417636813596e-05, Validation Loss: 0.00010315661153678471\n",
      "Epoch [4/25], Train Loss: 9.434693492949009e-05, Validation Loss: 0.00010282416333211586\n",
      "Epoch [4/25], Train Loss: 0.00011978577822446823, Validation Loss: 0.00010301312383186693\n",
      "Epoch [4/25], Train Loss: 8.260364847956225e-05, Validation Loss: 0.00010304467238408203\n",
      "Epoch [4/25], Train Loss: 0.00012631977733690292, Validation Loss: 0.00010279729855634893\n",
      "Epoch [4/25], Train Loss: 9.938945004250854e-05, Validation Loss: 0.0001024506845472691\n",
      "Epoch [4/25], Train Loss: 0.00012409940245561302, Validation Loss: 0.00010226319330589226\n",
      "Epoch [4/25], Train Loss: 0.00012080601300112903, Validation Loss: 0.00010224695142824203\n",
      "Epoch [4/25], Train Loss: 0.00011179244029335678, Validation Loss: 0.00010225358370613928\n",
      "Epoch [4/25], Train Loss: 0.00013117601338308305, Validation Loss: 0.00010218887618975713\n",
      "Epoch [4/25], Train Loss: 9.23339175642468e-05, Validation Loss: 0.00010209329872547338\n",
      "Epoch [4/25], Train Loss: 0.00010802134056575596, Validation Loss: 0.00010209421307081357\n",
      "Epoch [4/25], Train Loss: 8.734150469535962e-05, Validation Loss: 0.0001020671785227023\n",
      "Epoch [4/25], Train Loss: 0.00013395451242104173, Validation Loss: 0.0001020454825872245\n",
      "Epoch [4/25], Train Loss: 8.155737305060029e-05, Validation Loss: 0.00010196194537760069\n",
      "Epoch [4/25], Train Loss: 0.00010060388740384951, Validation Loss: 0.00010215478784327084\n",
      "Epoch [4/25], Train Loss: 0.00010770818335004151, Validation Loss: 0.00010242370141592498\n",
      "Epoch [4/25], Train Loss: 9.497333667241037e-05, Validation Loss: 0.00010269274644088\n",
      "Epoch [4/25], Train Loss: 0.00013180098903831095, Validation Loss: 0.00010317691339878365\n",
      "Epoch [4/25], Train Loss: 0.00011050344619434327, Validation Loss: 0.00010390165698481724\n",
      "Epoch [4/25], Train Loss: 0.00010629336611600593, Validation Loss: 0.00010479655708574379\n",
      "Epoch [4/25], Train Loss: 0.00012460553261917084, Validation Loss: 0.00010594650763475025\n",
      "Epoch [4/25], Train Loss: 9.7442272817716e-05, Validation Loss: 0.00010618401962953309\n",
      "Epoch [4/25], Train Loss: 0.00010839792230399325, Validation Loss: 0.0001052749697313023\n",
      "Epoch [4/25], Train Loss: 0.00010959790233755484, Validation Loss: 0.00010350238298997282\n",
      "Epoch [4/25], Train Loss: 9.928791405400261e-05, Validation Loss: 0.00010175023732396463\n",
      "Epoch [4/25], Train Loss: 0.00012248929124325514, Validation Loss: 0.00010070257994811981\n",
      "Epoch [4/25], Train Loss: 8.24516755528748e-05, Validation Loss: 0.00010062799362155298\n",
      "Epoch [4/25], Train Loss: 0.00011542531865416095, Validation Loss: 0.0001012708079845955\n",
      "Epoch [4/25], Train Loss: 0.00014509227185044438, Validation Loss: 0.0001019219669008938\n",
      "Epoch [4/25], Train Loss: 9.154192957794294e-05, Validation Loss: 0.00010222835844615474\n",
      "Epoch [4/25], Train Loss: 8.092389907687902e-05, Validation Loss: 0.0001018521977433314\n",
      "Epoch [4/25], Train Loss: 0.0001107677526306361, Validation Loss: 0.00010116787598235533\n",
      "Epoch [4/25], Train Loss: 9.061290620593354e-05, Validation Loss: 0.00010031921459206691\n",
      "Epoch [4/25], Train Loss: 0.00010032742284238338, Validation Loss: 9.974471953076621e-05\n",
      "Epoch [4/25], Train Loss: 7.828681555110961e-05, Validation Loss: 9.967595542548224e-05\n",
      "Epoch [4/25], Train Loss: 0.00011471424659248441, Validation Loss: 0.00010001433499079818\n",
      "Epoch [4/25], Train Loss: 0.00012410360795911402, Validation Loss: 0.00010063767986139283\n",
      "Epoch [4/25], Train Loss: 8.888464071787894e-05, Validation Loss: 0.00010145234118681401\n",
      "Epoch [4/25], Train Loss: 8.349707786692306e-05, Validation Loss: 0.00010200321703450755\n",
      "Epoch [4/25], Train Loss: 0.00010610181925585493, Validation Loss: 0.00010190850880462677\n",
      "Epoch [4/25], Train Loss: 0.00011391982843633741, Validation Loss: 0.0001020709372824058\n",
      "Epoch [4/25], Train Loss: 9.219254570780322e-05, Validation Loss: 0.00010245196220542615\n",
      "Epoch [4/25], Train Loss: 0.00012345134746283293, Validation Loss: 0.00010279200117414196\n",
      "Epoch [4/25], Train Loss: 0.00010762547753984109, Validation Loss: 0.00010329869692213834\n",
      "Epoch [4/25], Train Loss: 0.000108815060229972, Validation Loss: 0.0001041325352465113\n",
      "Epoch [4/25], Train Loss: 0.00010202397970715538, Validation Loss: 0.00010496266622794792\n",
      "Epoch [4/25], Train Loss: 0.00011795801401603967, Validation Loss: 0.00010533204573827485\n",
      "Epoch [4/25], Train Loss: 0.00010205946455243975, Validation Loss: 0.00010482222472395127\n",
      "Epoch [4/25], Train Loss: 0.00010531723091844469, Validation Loss: 0.00010348097324216117\n",
      "Epoch [4/25], Train Loss: 0.00011535647354321554, Validation Loss: 0.00010157710979304586\n",
      "Epoch [4/25], Train Loss: 9.651676373323426e-05, Validation Loss: 9.975992143154144e-05\n",
      "Epoch [4/25], Train Loss: 0.00011788782285293564, Validation Loss: 9.885772014968097e-05\n",
      "Epoch [4/25], Train Loss: 8.746223466005176e-05, Validation Loss: 9.912577903984736e-05\n",
      "Epoch [4/25], Train Loss: 0.00010634030331857502, Validation Loss: 0.00010030656703747809\n",
      "Epoch [4/25], Train Loss: 0.00010125947301276028, Validation Loss: 0.00010159737624538441\n",
      "Epoch [4/25], Train Loss: 7.824449130566791e-05, Validation Loss: 0.00010251138301100581\n",
      "Epoch [4/25], Train Loss: 0.0001175840079667978, Validation Loss: 0.00010255218852156152\n",
      "Epoch [4/25], Train Loss: 9.987058729166165e-05, Validation Loss: 0.00010252293383625025\n",
      "Epoch [4/25], Train Loss: 9.926963684847578e-05, Validation Loss: 0.00010235242176956186\n",
      "Epoch [4/25], Train Loss: 0.00012024821626255289, Validation Loss: 0.00010284534607004995\n",
      "Epoch [4/25], Train Loss: 9.366086305817589e-05, Validation Loss: 0.00010451837636840841\n",
      "Epoch [4/25], Train Loss: 9.012542432174087e-05, Validation Loss: 0.00010601157943407694\n",
      "Epoch [4/25], Train Loss: 0.00010192443733103573, Validation Loss: 0.0001061016257153824\n",
      "Epoch [4/25], Train Loss: 0.00012125018110964447, Validation Loss: 0.00010394150885986164\n",
      "Epoch [4/25], Train Loss: 0.00011179520515725017, Validation Loss: 0.00010051631155268599\n",
      "Epoch [4/25], Train Loss: 9.846672764979303e-05, Validation Loss: 9.789276615871738e-05\n",
      "Epoch [4/25], Train Loss: 0.00010201759869232774, Validation Loss: 9.752449550433084e-05\n",
      "Epoch [4/25], Train Loss: 0.00011617002019193023, Validation Loss: 9.880458577147996e-05\n",
      "Epoch [4/25], Train Loss: 0.00011951003398280591, Validation Loss: 0.00010000083032840242\n",
      "Epoch [5/25], Train Loss: 7.327000639634207e-05, Validation Loss: 0.0001000189518284363\n",
      "Epoch [5/25], Train Loss: 8.809183054836467e-05, Validation Loss: 9.888206695904956e-05\n",
      "Epoch [5/25], Train Loss: 0.00010468139953445643, Validation Loss: 9.763370762811973e-05\n",
      "Epoch [5/25], Train Loss: 0.00015123582852538675, Validation Loss: 9.70698277039143e-05\n",
      "Epoch [5/25], Train Loss: 0.00010321119043510407, Validation Loss: 9.742096008267254e-05\n",
      "Epoch [5/25], Train Loss: 6.87293941155076e-05, Validation Loss: 9.804783088232702e-05\n",
      "Epoch [5/25], Train Loss: 9.668491111369804e-05, Validation Loss: 9.827239894851421e-05\n",
      "Epoch [5/25], Train Loss: 9.670626604929566e-05, Validation Loss: 9.805658094895383e-05\n",
      "Epoch [5/25], Train Loss: 0.00010800502059282735, Validation Loss: 9.788894967641682e-05\n",
      "Epoch [5/25], Train Loss: 9.384280565427616e-05, Validation Loss: 9.816830230799193e-05\n",
      "Epoch [5/25], Train Loss: 6.040909647708759e-05, Validation Loss: 9.921749297063798e-05\n",
      "Epoch [5/25], Train Loss: 0.00011702249321388081, Validation Loss: 0.00010119961710491528\n",
      "Epoch [5/25], Train Loss: 0.00012203157530166209, Validation Loss: 0.00010426365382348498\n",
      "Epoch [5/25], Train Loss: 0.00013161827519070357, Validation Loss: 0.00010748606776663412\n",
      "Epoch [5/25], Train Loss: 0.00010009279503719881, Validation Loss: 0.00011116166327459116\n",
      "Epoch [5/25], Train Loss: 0.00011902662663487718, Validation Loss: 0.00011122401483589783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Train Loss: 0.00010772898531286046, Validation Loss: 0.00010656752177358915\n",
      "Epoch [5/25], Train Loss: 0.00013581549865193665, Validation Loss: 0.0001000615307323945\n",
      "Epoch [5/25], Train Loss: 8.928009629016742e-05, Validation Loss: 9.76964157113495e-05\n",
      "Epoch [5/25], Train Loss: 8.996260294225067e-05, Validation Loss: 0.0001006078760838136\n",
      "Epoch [5/25], Train Loss: 9.113961277762428e-05, Validation Loss: 0.00010319474725595986\n",
      "Epoch [5/25], Train Loss: 7.000500045251101e-05, Validation Loss: 0.00010186200767445067\n",
      "Epoch [5/25], Train Loss: 0.00010311535879736766, Validation Loss: 9.83098681899719e-05\n",
      "Epoch [5/25], Train Loss: 0.00010453691356815398, Validation Loss: 9.795309403367961e-05\n",
      "Epoch [5/25], Train Loss: 0.00012834055814892054, Validation Loss: 0.00010010964469984174\n",
      "Epoch [5/25], Train Loss: 7.4487914389465e-05, Validation Loss: 0.00010034361766884104\n",
      "Epoch [5/25], Train Loss: 0.0001197162491735071, Validation Loss: 9.831467759795487e-05\n",
      "Epoch [5/25], Train Loss: 0.00011039272794732824, Validation Loss: 9.709075917877878e-05\n",
      "Epoch [5/25], Train Loss: 9.630493150325492e-05, Validation Loss: 9.837041870923713e-05\n",
      "Epoch [5/25], Train Loss: 0.0001104963812394999, Validation Loss: 9.885857871267944e-05\n",
      "Epoch [5/25], Train Loss: 9.74266222328879e-05, Validation Loss: 9.73834675581505e-05\n",
      "Epoch [5/25], Train Loss: 0.00010576873319223523, Validation Loss: 9.610849325933183e-05\n",
      "Epoch [5/25], Train Loss: 0.00011071917833760381, Validation Loss: 9.661841759225353e-05\n",
      "Epoch [5/25], Train Loss: 0.00012232262815814465, Validation Loss: 9.777038455164681e-05\n",
      "Epoch [5/25], Train Loss: 9.175723243970424e-05, Validation Loss: 9.755143206954623e-05\n",
      "Epoch [5/25], Train Loss: 8.851286838762462e-05, Validation Loss: 9.618771000532433e-05\n",
      "Epoch [5/25], Train Loss: 8.519881521351635e-05, Validation Loss: 9.554112766636535e-05\n",
      "Epoch [5/25], Train Loss: 9.571776899974793e-05, Validation Loss: 9.622089031230038e-05\n",
      "Epoch [5/25], Train Loss: 9.232258889824152e-05, Validation Loss: 9.68468850866581e-05\n",
      "Epoch [5/25], Train Loss: 0.0001010312043945305, Validation Loss: 9.648000899081429e-05\n",
      "Epoch [5/25], Train Loss: 0.00011159050336573273, Validation Loss: 9.562825531853984e-05\n",
      "Epoch [5/25], Train Loss: 0.000118195079267025, Validation Loss: 9.535715362289921e-05\n",
      "Epoch [5/25], Train Loss: 8.003984112292528e-05, Validation Loss: 9.573937713867054e-05\n",
      "Epoch [5/25], Train Loss: 0.00010125881090061739, Validation Loss: 9.595303223856415e-05\n",
      "Epoch [5/25], Train Loss: 0.00010962469968944788, Validation Loss: 9.569825391129901e-05\n",
      "Epoch [5/25], Train Loss: 8.174250979209319e-05, Validation Loss: 9.517434276252364e-05\n",
      "Epoch [5/25], Train Loss: 7.865555380703881e-05, Validation Loss: 9.502463362878188e-05\n",
      "Epoch [5/25], Train Loss: 8.966873429017141e-05, Validation Loss: 9.534227137919515e-05\n",
      "Epoch [5/25], Train Loss: 0.00011773865116992965, Validation Loss: 9.565406993109113e-05\n",
      "Epoch [5/25], Train Loss: 0.00010093438322655857, Validation Loss: 9.571106250708302e-05\n",
      "Epoch [5/25], Train Loss: 0.00010542802920099348, Validation Loss: 9.565846218417088e-05\n",
      "Epoch [5/25], Train Loss: 7.506710971938446e-05, Validation Loss: 9.592234709998593e-05\n",
      "Epoch [5/25], Train Loss: 9.605308150639758e-05, Validation Loss: 9.654534029929588e-05\n",
      "Epoch [5/25], Train Loss: 9.429257625015453e-05, Validation Loss: 9.766580527260278e-05\n",
      "Epoch [5/25], Train Loss: 9.711174789117649e-05, Validation Loss: 9.916019917000085e-05\n",
      "Epoch [5/25], Train Loss: 9.212411532644182e-05, Validation Loss: 0.00010117129713762551\n",
      "Epoch [5/25], Train Loss: 9.725401469040662e-05, Validation Loss: 0.00010397127528752511\n",
      "Epoch [5/25], Train Loss: 0.00014875280612614006, Validation Loss: 0.00010794508852995932\n",
      "Epoch [5/25], Train Loss: 0.000123478879686445, Validation Loss: 0.00011240821913816035\n",
      "Epoch [5/25], Train Loss: 0.0001307570346398279, Validation Loss: 0.00011405331266966338\n",
      "Epoch [5/25], Train Loss: 0.00011767074465751648, Validation Loss: 0.00010927275434369221\n",
      "Epoch [5/25], Train Loss: 9.790326294023544e-05, Validation Loss: 0.00010040562386469295\n",
      "Epoch [5/25], Train Loss: 0.00011952599015785381, Validation Loss: 9.46113975563397e-05\n",
      "Epoch [5/25], Train Loss: 7.472328434232622e-05, Validation Loss: 9.683413760891805e-05\n",
      "Epoch [5/25], Train Loss: 0.00010791226668516174, Validation Loss: 0.00010196247603744268\n",
      "Epoch [5/25], Train Loss: 8.939724648371339e-05, Validation Loss: 0.00010282493797906985\n",
      "Epoch [5/25], Train Loss: 0.00010543943790253252, Validation Loss: 9.825778882562493e-05\n",
      "Epoch [5/25], Train Loss: 0.00011207738862140104, Validation Loss: 9.469531990665321e-05\n",
      "Epoch [5/25], Train Loss: 9.559515456203371e-05, Validation Loss: 9.624305530451239e-05\n",
      "Epoch [5/25], Train Loss: 0.00010990565351676196, Validation Loss: 9.913363658900684e-05\n",
      "Epoch [5/25], Train Loss: 7.859883044147864e-05, Validation Loss: 9.839453026264286e-05\n",
      "Epoch [5/25], Train Loss: 0.0001131317694671452, Validation Loss: 9.56211137236096e-05\n",
      "Epoch [5/25], Train Loss: 0.00010967850539600477, Validation Loss: 9.46185575836959e-05\n",
      "Epoch [5/25], Train Loss: 9.9797201983165e-05, Validation Loss: 9.618766440932329e-05\n",
      "Epoch [5/25], Train Loss: 0.00011037878721253946, Validation Loss: 9.720722688750053e-05\n",
      "Epoch [5/25], Train Loss: 7.588802691316232e-05, Validation Loss: 9.584828706768652e-05\n",
      "Epoch [5/25], Train Loss: 8.891198376659304e-05, Validation Loss: 9.434183642345792e-05\n",
      "Epoch [5/25], Train Loss: 8.798192720860243e-05, Validation Loss: 9.459640035250535e-05\n",
      "Epoch [5/25], Train Loss: 8.628501382190734e-05, Validation Loss: 9.564183225544791e-05\n",
      "Epoch [5/25], Train Loss: 8.94569675438106e-05, Validation Loss: 9.578573808539659e-05\n",
      "Epoch [5/25], Train Loss: 6.875845429021865e-05, Validation Loss: 9.462184292109062e-05\n",
      "Epoch [5/25], Train Loss: 8.641813474241644e-05, Validation Loss: 9.389899496454745e-05\n",
      "Epoch [5/25], Train Loss: 9.789279283722863e-05, Validation Loss: 9.450708215202515e-05\n",
      "Epoch [5/25], Train Loss: 0.0001006262973533012, Validation Loss: 9.525510055633883e-05\n",
      "Epoch [5/25], Train Loss: 7.791370444465429e-05, Validation Loss: 9.523635138369476e-05\n",
      "Epoch [5/25], Train Loss: 0.00010248784383293241, Validation Loss: 9.439211086525272e-05\n",
      "Epoch [5/25], Train Loss: 0.00012500182492658496, Validation Loss: 9.374099366444473e-05\n",
      "Epoch [5/25], Train Loss: 0.00010886709787882864, Validation Loss: 9.392248660636446e-05\n",
      "Epoch [5/25], Train Loss: 9.092438995139673e-05, Validation Loss: 9.457360041172554e-05\n",
      "Epoch [5/25], Train Loss: 0.0001044478703988716, Validation Loss: 9.483355048966284e-05\n",
      "Epoch [5/25], Train Loss: 8.163054008036852e-05, Validation Loss: 9.430602998084699e-05\n",
      "Epoch [5/25], Train Loss: 8.974105003289878e-05, Validation Loss: 9.38017435449486e-05\n",
      "Epoch [5/25], Train Loss: 0.00011123982403660193, Validation Loss: 9.351654395383472e-05\n",
      "Epoch [5/25], Train Loss: 8.95630510058254e-05, Validation Loss: 9.354534947002928e-05\n",
      "Epoch [5/25], Train Loss: 8.082919521257281e-05, Validation Loss: 9.379846305819228e-05\n",
      "Epoch [5/25], Train Loss: 0.00010907953401328996, Validation Loss: 9.398363375415405e-05\n",
      "Epoch [5/25], Train Loss: 0.00010325996117899194, Validation Loss: 9.390762522040555e-05\n",
      "Epoch [5/25], Train Loss: 7.427617674693465e-05, Validation Loss: 9.359488127908359e-05\n",
      "Epoch [5/25], Train Loss: 0.0001183324129669927, Validation Loss: 9.333535272162407e-05\n",
      "Epoch [5/25], Train Loss: 0.00011163385352119803, Validation Loss: 9.324175577300291e-05\n",
      "Epoch [5/25], Train Loss: 9.107157529797405e-05, Validation Loss: 9.338382660644129e-05\n",
      "Epoch [5/25], Train Loss: 0.00010726723121479154, Validation Loss: 9.366696661648651e-05\n",
      "Epoch [5/25], Train Loss: 9.15398049983196e-05, Validation Loss: 9.394488588441164e-05\n",
      "Epoch [5/25], Train Loss: 0.00011101751442765817, Validation Loss: 9.429874674727519e-05\n",
      "Epoch [5/25], Train Loss: 7.26063663023524e-05, Validation Loss: 9.469054493820295e-05\n",
      "Epoch [5/25], Train Loss: 9.557794692227617e-05, Validation Loss: 9.5029738440644e-05\n",
      "Epoch [5/25], Train Loss: 0.00010838460002560169, Validation Loss: 9.559947163021813e-05\n",
      "Epoch [5/25], Train Loss: 0.00012152922863606364, Validation Loss: 9.612074500182643e-05\n",
      "Epoch [5/25], Train Loss: 0.00010490671411389485, Validation Loss: 9.650989522924647e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Train Loss: 8.165485633071512e-05, Validation Loss: 9.686481304621945e-05\n",
      "Epoch [5/25], Train Loss: 9.224276436725631e-05, Validation Loss: 9.725284908199683e-05\n",
      "Epoch [5/25], Train Loss: 9.17275610845536e-05, Validation Loss: 9.740762276730189e-05\n",
      "Epoch [5/25], Train Loss: 0.00010514683526707813, Validation Loss: 9.7519737513115e-05\n",
      "Epoch [5/25], Train Loss: 8.509976760251448e-05, Validation Loss: 9.745120963392159e-05\n",
      "Epoch [5/25], Train Loss: 0.00011609342618612573, Validation Loss: 9.690147465638196e-05\n",
      "Epoch [5/25], Train Loss: 0.00010765586921479553, Validation Loss: 9.611818677512929e-05\n",
      "Epoch [5/25], Train Loss: 7.921930955490097e-05, Validation Loss: 9.520906896796078e-05\n",
      "Epoch [5/25], Train Loss: 8.929146861191839e-05, Validation Loss: 9.423546531858543e-05\n",
      "Epoch [5/25], Train Loss: 8.80847655935213e-05, Validation Loss: 9.33739667137464e-05\n",
      "Epoch [5/25], Train Loss: 0.00010540733637753874, Validation Loss: 9.285781513123463e-05\n",
      "Epoch [5/25], Train Loss: 9.58027012529783e-05, Validation Loss: 9.255940531147644e-05\n",
      "Epoch [5/25], Train Loss: 9.674882312538102e-05, Validation Loss: 9.252932456244404e-05\n",
      "Epoch [5/25], Train Loss: 9.418682748218998e-05, Validation Loss: 9.268220649876942e-05\n",
      "Epoch [5/25], Train Loss: 0.00011451211321400478, Validation Loss: 9.296954958699643e-05\n",
      "Epoch [5/25], Train Loss: 8.688115485711023e-05, Validation Loss: 9.328822440390165e-05\n",
      "Epoch [5/25], Train Loss: 9.247493289876729e-05, Validation Loss: 9.380455497497072e-05\n",
      "Epoch [5/25], Train Loss: 0.00010415484575787559, Validation Loss: 9.463389190689971e-05\n",
      "Epoch [5/25], Train Loss: 0.00012320798123255372, Validation Loss: 9.579664377573257e-05\n",
      "Epoch [5/25], Train Loss: 8.502612035954371e-05, Validation Loss: 9.753643438064804e-05\n",
      "Epoch [5/25], Train Loss: 0.0001169087117887102, Validation Loss: 9.957508882507682e-05\n",
      "Epoch [5/25], Train Loss: 0.00010541927622398362, Validation Loss: 0.00010237590710554893\n",
      "Epoch [5/25], Train Loss: 8.526959572918713e-05, Validation Loss: 0.00010508181536958242\n",
      "Epoch [5/25], Train Loss: 0.00012380116095300764, Validation Loss: 0.00010728899748452629\n",
      "Epoch [5/25], Train Loss: 8.378200436709449e-05, Validation Loss: 0.000106809760715502\n",
      "Epoch [6/25], Train Loss: 0.0001178634338430129, Validation Loss: 0.00010282481525791809\n",
      "Epoch [6/25], Train Loss: 0.00011733764404198155, Validation Loss: 9.685078888045003e-05\n",
      "Epoch [6/25], Train Loss: 0.0001021974312607199, Validation Loss: 9.292718314100057e-05\n",
      "Epoch [6/25], Train Loss: 9.01439125300385e-05, Validation Loss: 9.300727833760902e-05\n",
      "Epoch [6/25], Train Loss: 0.0001225742744281888, Validation Loss: 9.593674427984903e-05\n",
      "Epoch [6/25], Train Loss: 9.021782170748338e-05, Validation Loss: 9.852842874048898e-05\n",
      "Epoch [6/25], Train Loss: 8.388209971599281e-05, Validation Loss: 9.821315034059807e-05\n",
      "Epoch [6/25], Train Loss: 0.00012833435903303325, Validation Loss: 9.558378127015507e-05\n",
      "Epoch [6/25], Train Loss: 0.00010382953769294545, Validation Loss: 9.3070882333753e-05\n",
      "Epoch [6/25], Train Loss: 9.0723333414644e-05, Validation Loss: 9.285399816387023e-05\n",
      "Epoch [6/25], Train Loss: 0.00012736640928778797, Validation Loss: 9.44458598193402e-05\n",
      "Epoch [6/25], Train Loss: 0.00012231076834723353, Validation Loss: 9.564540426557263e-05\n",
      "Epoch [6/25], Train Loss: 9.294894698541611e-05, Validation Loss: 9.51462279772386e-05\n",
      "Epoch [6/25], Train Loss: 7.989078585524112e-05, Validation Loss: 9.339767469403644e-05\n",
      "Epoch [6/25], Train Loss: 7.35053836251609e-05, Validation Loss: 9.237404447048903e-05\n",
      "Epoch [6/25], Train Loss: 0.00011186047049704939, Validation Loss: 9.2739380003574e-05\n",
      "Epoch [6/25], Train Loss: 7.041298522381112e-05, Validation Loss: 9.384951311706876e-05\n",
      "Epoch [6/25], Train Loss: 7.227566675283015e-05, Validation Loss: 9.447688644286245e-05\n",
      "Epoch [6/25], Train Loss: 0.00010166589345317334, Validation Loss: 9.38586910100033e-05\n",
      "Epoch [6/25], Train Loss: 9.234879689756781e-05, Validation Loss: 9.267660789191723e-05\n",
      "Epoch [6/25], Train Loss: 0.00010562060924712569, Validation Loss: 9.201508413146561e-05\n",
      "Epoch [6/25], Train Loss: 9.935388516169041e-05, Validation Loss: 9.242638722450162e-05\n",
      "Epoch [6/25], Train Loss: 0.00010911684512393549, Validation Loss: 9.312739178615933e-05\n",
      "Epoch [6/25], Train Loss: 7.988781726453453e-05, Validation Loss: 9.334967617178336e-05\n",
      "Epoch [6/25], Train Loss: 9.292727190768346e-05, Validation Loss: 9.29395027924329e-05\n",
      "Epoch [6/25], Train Loss: 9.729011071613058e-05, Validation Loss: 9.213223481007541e-05\n",
      "Epoch [6/25], Train Loss: 0.00010020577610703185, Validation Loss: 9.17517696507275e-05\n",
      "Epoch [6/25], Train Loss: 8.273211278719828e-05, Validation Loss: 9.202073391255302e-05\n",
      "Epoch [6/25], Train Loss: 9.560625039739534e-05, Validation Loss: 9.256813646061346e-05\n",
      "Epoch [6/25], Train Loss: 8.221428288379684e-05, Validation Loss: 9.29514309973456e-05\n",
      "Epoch [6/25], Train Loss: 0.00010128096619155258, Validation Loss: 9.281453142951553e-05\n",
      "Epoch [6/25], Train Loss: 0.00010866946104215458, Validation Loss: 9.243991274464255e-05\n",
      "Epoch [6/25], Train Loss: 7.013188587734476e-05, Validation Loss: 9.202933651977218e-05\n",
      "Epoch [6/25], Train Loss: 7.751740486128256e-05, Validation Loss: 9.181121810494611e-05\n",
      "Epoch [6/25], Train Loss: 9.886907355394214e-05, Validation Loss: 9.186695606331342e-05\n",
      "Epoch [6/25], Train Loss: 9.112288535106927e-05, Validation Loss: 9.20959190504315e-05\n",
      "Epoch [6/25], Train Loss: 0.0001213484865729697, Validation Loss: 9.225429578994712e-05\n",
      "Epoch [6/25], Train Loss: 0.00010097997437696904, Validation Loss: 9.222943335771561e-05\n",
      "Epoch [6/25], Train Loss: 0.00010442271741339937, Validation Loss: 9.218879470912119e-05\n",
      "Epoch [6/25], Train Loss: 0.000125849517644383, Validation Loss: 9.218246996169909e-05\n",
      "Epoch [6/25], Train Loss: 0.00011107243335573003, Validation Loss: 9.230350406141952e-05\n",
      "Epoch [6/25], Train Loss: 9.392389620188624e-05, Validation Loss: 9.250155174716686e-05\n",
      "Epoch [6/25], Train Loss: 0.00011220206943107769, Validation Loss: 9.307480310477937e-05\n",
      "Epoch [6/25], Train Loss: 0.00010915048187598586, Validation Loss: 9.380354555711771e-05\n",
      "Epoch [6/25], Train Loss: 9.35397983994335e-05, Validation Loss: 9.472708334214985e-05\n",
      "Epoch [6/25], Train Loss: 9.077178401639685e-05, Validation Loss: 9.603653500865524e-05\n",
      "Epoch [6/25], Train Loss: 0.00010365488560637459, Validation Loss: 9.765307768248022e-05\n",
      "Epoch [6/25], Train Loss: 8.728423563297838e-05, Validation Loss: 9.954836180744071e-05\n",
      "Epoch [6/25], Train Loss: 9.68715685303323e-05, Validation Loss: 0.0001020804537499013\n",
      "Epoch [6/25], Train Loss: 0.000112647918285802, Validation Loss: 0.000104554162438338\n",
      "Epoch [6/25], Train Loss: 9.704898548079655e-05, Validation Loss: 0.00010596797510515898\n",
      "Epoch [6/25], Train Loss: 0.00011737325257854536, Validation Loss: 0.00010545262630330398\n",
      "Epoch [6/25], Train Loss: 0.00010619841486914083, Validation Loss: 0.0001030382098785291\n",
      "Epoch [6/25], Train Loss: 0.00011960003757849336, Validation Loss: 9.815300581976772e-05\n",
      "Epoch [6/25], Train Loss: 0.00010207742161583155, Validation Loss: 9.352345708369588e-05\n",
      "Epoch [6/25], Train Loss: 9.498105646343902e-05, Validation Loss: 9.157840565118628e-05\n",
      "Epoch [6/25], Train Loss: 8.879755478119478e-05, Validation Loss: 9.281704309008395e-05\n",
      "Epoch [6/25], Train Loss: 8.624328620499e-05, Validation Loss: 9.534171452590575e-05\n",
      "Epoch [6/25], Train Loss: 0.00011332691792631522, Validation Loss: 9.649808537991097e-05\n",
      "Epoch [6/25], Train Loss: 9.69057873589918e-05, Validation Loss: 9.533134289085865e-05\n",
      "Epoch [6/25], Train Loss: 9.894172399071977e-05, Validation Loss: 9.296588444461426e-05\n",
      "Epoch [6/25], Train Loss: 9.16945282369852e-05, Validation Loss: 9.138322517780277e-05\n",
      "Epoch [6/25], Train Loss: 9.90226399153471e-05, Validation Loss: 9.165780235586378e-05\n",
      "Epoch [6/25], Train Loss: 0.00010207537707174197, Validation Loss: 9.328391218635565e-05\n",
      "Epoch [6/25], Train Loss: 8.944908040575683e-05, Validation Loss: 9.448205382796004e-05\n",
      "Epoch [6/25], Train Loss: 9.94449874269776e-05, Validation Loss: 9.408392991948252e-05\n",
      "Epoch [6/25], Train Loss: 6.697351636830717e-05, Validation Loss: 9.254610243563851e-05\n",
      "Epoch [6/25], Train Loss: 0.00012026057811453938, Validation Loss: 9.122870833380147e-05\n",
      "Epoch [6/25], Train Loss: 8.158083073794842e-05, Validation Loss: 9.131524833113265e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Train Loss: 9.022976155392826e-05, Validation Loss: 9.232081453471134e-05\n",
      "Epoch [6/25], Train Loss: 9.333354682894424e-05, Validation Loss: 9.316006811180463e-05\n",
      "Epoch [6/25], Train Loss: 0.00012011902435915545, Validation Loss: 9.325389692094177e-05\n",
      "Epoch [6/25], Train Loss: 7.249040208989754e-05, Validation Loss: 9.248293693720673e-05\n",
      "Epoch [6/25], Train Loss: 8.070795593084767e-05, Validation Loss: 9.14384116185829e-05\n",
      "Epoch [6/25], Train Loss: 9.740758105181158e-05, Validation Loss: 9.093209422038248e-05\n",
      "Epoch [6/25], Train Loss: 0.00011737801105482504, Validation Loss: 9.128430950416563e-05\n",
      "Epoch [6/25], Train Loss: 0.00010084071254823357, Validation Loss: 9.206500447665652e-05\n",
      "Epoch [6/25], Train Loss: 8.484474528813735e-05, Validation Loss: 9.250952425645664e-05\n",
      "Epoch [6/25], Train Loss: 8.567638724343851e-05, Validation Loss: 9.237849056565513e-05\n",
      "Epoch [6/25], Train Loss: 8.32526056910865e-05, Validation Loss: 9.17165923359183e-05\n",
      "Epoch [6/25], Train Loss: 9.269826114177704e-05, Validation Loss: 9.106934109392266e-05\n",
      "Epoch [6/25], Train Loss: 9.215977479470894e-05, Validation Loss: 9.07272202312015e-05\n",
      "Epoch [6/25], Train Loss: 9.336444782093167e-05, Validation Loss: 9.0828293953867e-05\n",
      "Epoch [6/25], Train Loss: 9.03516192920506e-05, Validation Loss: 9.108418016694486e-05\n",
      "Epoch [6/25], Train Loss: 0.00010539273353060707, Validation Loss: 9.123232448473572e-05\n",
      "Epoch [6/25], Train Loss: 8.649923256598413e-05, Validation Loss: 9.119306972327952e-05\n",
      "Epoch [6/25], Train Loss: 8.53264209581539e-05, Validation Loss: 9.103714110096917e-05\n",
      "Epoch [6/25], Train Loss: 9.264086111215875e-05, Validation Loss: 9.079533871651317e-05\n",
      "Epoch [6/25], Train Loss: 8.096140663838014e-05, Validation Loss: 9.055603489590187e-05\n",
      "Epoch [6/25], Train Loss: 9.01561725186184e-05, Validation Loss: 9.050567241501995e-05\n",
      "Epoch [6/25], Train Loss: 7.738977728877217e-05, Validation Loss: 9.05685415394449e-05\n",
      "Epoch [6/25], Train Loss: 0.00010050491255242378, Validation Loss: 9.063452622892025e-05\n",
      "Epoch [6/25], Train Loss: 0.00010819530871231109, Validation Loss: 9.069826313255666e-05\n",
      "Epoch [6/25], Train Loss: 7.490885036531836e-05, Validation Loss: 9.070727901416831e-05\n",
      "Epoch [6/25], Train Loss: 8.808759594103321e-05, Validation Loss: 9.070080801999817e-05\n",
      "Epoch [6/25], Train Loss: 9.720610978547484e-05, Validation Loss: 9.069060324691236e-05\n",
      "Epoch [6/25], Train Loss: 0.00010320117871742696, Validation Loss: 9.071671059549166e-05\n",
      "Epoch [6/25], Train Loss: 9.366762969875708e-05, Validation Loss: 9.070659216376953e-05\n",
      "Epoch [6/25], Train Loss: 9.341585246147588e-05, Validation Loss: 9.076618007384241e-05\n",
      "Epoch [6/25], Train Loss: 7.071470463415608e-05, Validation Loss: 9.09865673747845e-05\n",
      "Epoch [6/25], Train Loss: 8.263160270871595e-05, Validation Loss: 9.12938077817671e-05\n",
      "Epoch [6/25], Train Loss: 9.338613745057955e-05, Validation Loss: 9.16343808057718e-05\n",
      "Epoch [6/25], Train Loss: 8.026300929486752e-05, Validation Loss: 9.201269034141054e-05\n",
      "Epoch [6/25], Train Loss: 0.00010759337601484731, Validation Loss: 9.251017084655662e-05\n",
      "Epoch [6/25], Train Loss: 0.00010737209959188476, Validation Loss: 9.342451279129213e-05\n",
      "Epoch [6/25], Train Loss: 8.442989928880706e-05, Validation Loss: 9.47664322059912e-05\n",
      "Epoch [6/25], Train Loss: 9.812346252147108e-05, Validation Loss: 9.704919745369504e-05\n",
      "Epoch [6/25], Train Loss: 0.0001167869777418673, Validation Loss: 9.987270314013586e-05\n",
      "Epoch [6/25], Train Loss: 8.900011016521603e-05, Validation Loss: 0.00010316487508437907\n",
      "Epoch [6/25], Train Loss: 9.396360110258684e-05, Validation Loss: 0.00010657437184515098\n",
      "Epoch [6/25], Train Loss: 0.0001266912731807679, Validation Loss: 0.00010823201737366616\n",
      "Epoch [6/25], Train Loss: 9.857502300292253e-05, Validation Loss: 0.00010652915758934493\n",
      "Epoch [6/25], Train Loss: 0.00011043583072023466, Validation Loss: 0.0001017954054987058\n",
      "Epoch [6/25], Train Loss: 9.877912816591561e-05, Validation Loss: 9.579179507757847e-05\n",
      "Epoch [6/25], Train Loss: 0.00010164696141146123, Validation Loss: 9.255315962946043e-05\n",
      "Epoch [6/25], Train Loss: 0.00010235870286123827, Validation Loss: 9.322303570418929e-05\n",
      "Epoch [6/25], Train Loss: 9.891162335406989e-05, Validation Loss: 9.548089340872442e-05\n",
      "Epoch [6/25], Train Loss: 9.229641000274569e-05, Validation Loss: 9.638418656929085e-05\n",
      "Epoch [6/25], Train Loss: 8.239328599302098e-05, Validation Loss: 9.43107792409137e-05\n",
      "Epoch [6/25], Train Loss: 0.0001104951516026631, Validation Loss: 9.170044747103626e-05\n",
      "Epoch [6/25], Train Loss: 8.285333024105057e-05, Validation Loss: 9.130142352660186e-05\n",
      "Epoch [6/25], Train Loss: 9.808180038817227e-05, Validation Loss: 9.333021201503773e-05\n",
      "Epoch [6/25], Train Loss: 9.066125494427979e-05, Validation Loss: 9.49489757961904e-05\n",
      "Epoch [6/25], Train Loss: 8.45088143250905e-05, Validation Loss: 9.399849319985757e-05\n",
      "Epoch [6/25], Train Loss: 9.029922512127087e-05, Validation Loss: 9.141496848315e-05\n",
      "Epoch [6/25], Train Loss: 8.696505392435938e-05, Validation Loss: 9.000585462975626e-05\n",
      "Epoch [6/25], Train Loss: 7.477890176232904e-05, Validation Loss: 9.098168035658697e-05\n",
      "Epoch [6/25], Train Loss: 0.0001014091249089688, Validation Loss: 9.257728427958985e-05\n",
      "Epoch [6/25], Train Loss: 9.197637700708583e-05, Validation Loss: 9.263174530739585e-05\n",
      "Epoch [6/25], Train Loss: 9.1231195256114e-05, Validation Loss: 9.125235180060068e-05\n",
      "Epoch [6/25], Train Loss: 7.905731035862118e-05, Validation Loss: 9.02594673486116e-05\n",
      "Epoch [6/25], Train Loss: 8.39617132442072e-05, Validation Loss: 9.074382881711548e-05\n",
      "Epoch [6/25], Train Loss: 9.616278839530423e-05, Validation Loss: 9.18645984105145e-05\n",
      "Epoch [6/25], Train Loss: 8.143184095388278e-05, Validation Loss: 9.211157982160026e-05\n",
      "Epoch [7/25], Train Loss: 0.00010583801486063749, Validation Loss: 9.108296023138488e-05\n",
      "Epoch [7/25], Train Loss: 0.00011099139373982325, Validation Loss: 8.999292064496937e-05\n",
      "Epoch [7/25], Train Loss: 0.00011589567293412983, Validation Loss: 9.008108875908268e-05\n",
      "Epoch [7/25], Train Loss: 9.023102029459551e-05, Validation Loss: 9.093055850826204e-05\n",
      "Epoch [7/25], Train Loss: 0.00010526886762818322, Validation Loss: 9.12444680579938e-05\n",
      "Epoch [7/25], Train Loss: 9.75099828792736e-05, Validation Loss: 9.066329099975216e-05\n",
      "Epoch [7/25], Train Loss: 7.651123451068997e-05, Validation Loss: 9.006525506265462e-05\n",
      "Epoch [7/25], Train Loss: 0.00010122113599209115, Validation Loss: 8.99832933403862e-05\n",
      "Epoch [7/25], Train Loss: 0.00013380956079345196, Validation Loss: 9.027996323614691e-05\n",
      "Epoch [7/25], Train Loss: 0.00010638405365170911, Validation Loss: 9.047685477222936e-05\n",
      "Epoch [7/25], Train Loss: 7.408704550471157e-05, Validation Loss: 9.030199071276001e-05\n",
      "Epoch [7/25], Train Loss: 8.721170161152259e-05, Validation Loss: 8.991699796752073e-05\n",
      "Epoch [7/25], Train Loss: 8.590446668677032e-05, Validation Loss: 8.970349614780085e-05\n",
      "Epoch [7/25], Train Loss: 0.00010782942990772426, Validation Loss: 8.978124096756802e-05\n",
      "Epoch [7/25], Train Loss: 0.00010420659964438528, Validation Loss: 8.999301498988644e-05\n",
      "Epoch [7/25], Train Loss: 0.00010618569649523124, Validation Loss: 9.004624759351524e-05\n",
      "Epoch [7/25], Train Loss: 8.336798055097461e-05, Validation Loss: 8.987154263498573e-05\n",
      "Epoch [7/25], Train Loss: 8.725461520953104e-05, Validation Loss: 8.968129986897111e-05\n",
      "Epoch [7/25], Train Loss: 8.845653792377561e-05, Validation Loss: 8.960523288502979e-05\n",
      "Epoch [7/25], Train Loss: 0.00010292600200045854, Validation Loss: 8.962879680135908e-05\n",
      "Epoch [7/25], Train Loss: 8.718408207641914e-05, Validation Loss: 8.970616424145798e-05\n",
      "Epoch [7/25], Train Loss: 8.28669362817891e-05, Validation Loss: 8.97584681903633e-05\n",
      "Epoch [7/25], Train Loss: 8.771288412390277e-05, Validation Loss: 8.973354269983246e-05\n",
      "Epoch [7/25], Train Loss: 8.927981980377808e-05, Validation Loss: 8.9627177658258e-05\n",
      "Epoch [7/25], Train Loss: 8.985873137135059e-05, Validation Loss: 8.951655472628772e-05\n",
      "Epoch [7/25], Train Loss: 6.615265738219023e-05, Validation Loss: 8.946988333870346e-05\n",
      "Epoch [7/25], Train Loss: 9.114790009334683e-05, Validation Loss: 8.949013620925446e-05\n",
      "Epoch [7/25], Train Loss: 8.538189285900444e-05, Validation Loss: 8.955239415323983e-05\n",
      "Epoch [7/25], Train Loss: 9.645654063206166e-05, Validation Loss: 8.959694071866883e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Train Loss: 8.644233457744122e-05, Validation Loss: 8.96642287746848e-05\n",
      "Epoch [7/25], Train Loss: 8.645861089462414e-05, Validation Loss: 8.975848541012966e-05\n",
      "Epoch [7/25], Train Loss: 0.00010146745626116171, Validation Loss: 8.98791348542242e-05\n",
      "Epoch [7/25], Train Loss: 0.0001036413450492546, Validation Loss: 9.021874454144078e-05\n",
      "Epoch [7/25], Train Loss: 8.535705273970962e-05, Validation Loss: 9.082190590561367e-05\n",
      "Epoch [7/25], Train Loss: 9.71619738265872e-05, Validation Loss: 9.201157760495941e-05\n",
      "Epoch [7/25], Train Loss: 9.244155808119103e-05, Validation Loss: 9.408855791358898e-05\n",
      "Epoch [7/25], Train Loss: 0.00011588284542085603, Validation Loss: 9.790997185821955e-05\n",
      "Epoch [7/25], Train Loss: 9.15727941901423e-05, Validation Loss: 0.00010435773923139398\n",
      "Epoch [7/25], Train Loss: 9.56346484599635e-05, Validation Loss: 0.0001136127679880398\n",
      "Epoch [7/25], Train Loss: 0.00013102144293952733, Validation Loss: 0.0001244986274590095\n",
      "Epoch [7/25], Train Loss: 0.00012301639071665704, Validation Loss: 0.00013124380153991904\n",
      "Epoch [7/25], Train Loss: 0.00013752620725426823, Validation Loss: 0.00012424592908549432\n",
      "Epoch [7/25], Train Loss: 0.0001337872090516612, Validation Loss: 0.00010423417067310463\n",
      "Epoch [7/25], Train Loss: 0.00011330568668199703, Validation Loss: 8.995320774071539e-05\n",
      "Epoch [7/25], Train Loss: 8.206661004805937e-05, Validation Loss: 9.434968572653209e-05\n",
      "Epoch [7/25], Train Loss: 0.00011089958570664749, Validation Loss: 0.00010570386220933869\n",
      "Epoch [7/25], Train Loss: 0.00012226245598867536, Validation Loss: 0.00010442967710938925\n",
      "Epoch [7/25], Train Loss: 0.00010838025627890602, Validation Loss: 9.302637239064401e-05\n",
      "Epoch [7/25], Train Loss: 9.870043868431821e-05, Validation Loss: 9.017393022077158e-05\n",
      "Epoch [7/25], Train Loss: 8.534474909538403e-05, Validation Loss: 9.730890014907345e-05\n",
      "Epoch [7/25], Train Loss: 9.07938156160526e-05, Validation Loss: 9.862311659768845e-05\n",
      "Epoch [7/25], Train Loss: 9.582126222085208e-05, Validation Loss: 9.164496732410044e-05\n",
      "Epoch [7/25], Train Loss: 9.016593685373664e-05, Validation Loss: 8.982873672114995e-05\n",
      "Epoch [7/25], Train Loss: 8.158114360412583e-05, Validation Loss: 9.480656056742494e-05\n",
      "Epoch [7/25], Train Loss: 0.00011017036013072357, Validation Loss: 9.484585267879689e-05\n",
      "Epoch [7/25], Train Loss: 9.44102939683944e-05, Validation Loss: 9.00803449136826e-05\n",
      "Epoch [7/25], Train Loss: 9.476818377152085e-05, Validation Loss: 9.029823850141838e-05\n",
      "Epoch [7/25], Train Loss: 7.834051211830229e-05, Validation Loss: 9.339293950082114e-05\n",
      "Epoch [7/25], Train Loss: 9.524483175482601e-05, Validation Loss: 9.179523767670617e-05\n",
      "Epoch [7/25], Train Loss: 9.153737482847646e-05, Validation Loss: 8.929577597882599e-05\n",
      "Epoch [7/25], Train Loss: 8.608322241343558e-05, Validation Loss: 9.081374591914936e-05\n",
      "Epoch [7/25], Train Loss: 9.957016300177202e-05, Validation Loss: 9.200635880309467e-05\n",
      "Epoch [7/25], Train Loss: 0.0001004749137791805, Validation Loss: 9.000965486241816e-05\n",
      "Epoch [7/25], Train Loss: 8.144184539560229e-05, Validation Loss: 8.939393640806277e-05\n",
      "Epoch [7/25], Train Loss: 8.930079638957977e-05, Validation Loss: 9.093868890583204e-05\n",
      "Epoch [7/25], Train Loss: 7.840009493520483e-05, Validation Loss: 9.072845787159168e-05\n",
      "Epoch [7/25], Train Loss: 8.248027734225616e-05, Validation Loss: 8.93119206011761e-05\n",
      "Epoch [7/25], Train Loss: 0.00011412282765377313, Validation Loss: 8.983421939774416e-05\n",
      "Epoch [7/25], Train Loss: 9.281834354624152e-05, Validation Loss: 9.0665813574257e-05\n",
      "Epoch [7/25], Train Loss: 7.314634422073141e-05, Validation Loss: 8.971314406759726e-05\n",
      "Epoch [7/25], Train Loss: 7.441806519636884e-05, Validation Loss: 8.915334474295378e-05\n",
      "Epoch [7/25], Train Loss: 7.660566916456446e-05, Validation Loss: 8.989780302120683e-05\n",
      "Epoch [7/25], Train Loss: 8.519378752680495e-05, Validation Loss: 9.001186117529869e-05\n",
      "Epoch [7/25], Train Loss: 8.808622078504413e-05, Validation Loss: 8.925980315931762e-05\n",
      "Epoch [7/25], Train Loss: 9.051748929778114e-05, Validation Loss: 8.921233068880005e-05\n",
      "Epoch [7/25], Train Loss: 8.384202374145389e-05, Validation Loss: 8.963876534835435e-05\n",
      "Epoch [7/25], Train Loss: 8.779863856034353e-05, Validation Loss: 8.940481541988751e-05\n",
      "Epoch [7/25], Train Loss: 7.86528253229335e-05, Validation Loss: 8.906288179180896e-05\n",
      "Epoch [7/25], Train Loss: 8.756202441873029e-05, Validation Loss: 8.926868443571341e-05\n",
      "Epoch [7/25], Train Loss: 8.730604167794809e-05, Validation Loss: 8.942212637824317e-05\n",
      "Epoch [7/25], Train Loss: 9.861231956165284e-05, Validation Loss: 8.917192559844503e-05\n",
      "Epoch [7/25], Train Loss: 8.636308484710753e-05, Validation Loss: 8.900109532987699e-05\n",
      "Epoch [7/25], Train Loss: 7.723743328824639e-05, Validation Loss: 8.916086371755228e-05\n",
      "Epoch [7/25], Train Loss: 8.481841359753162e-05, Validation Loss: 8.922023747193937e-05\n",
      "Epoch [7/25], Train Loss: 7.98109540482983e-05, Validation Loss: 8.901654024763653e-05\n",
      "Epoch [7/25], Train Loss: 9.089738159673288e-05, Validation Loss: 8.896464108450648e-05\n",
      "Epoch [7/25], Train Loss: 9.397667599841952e-05, Validation Loss: 8.908076051739044e-05\n",
      "Epoch [7/25], Train Loss: 0.00010041129280580208, Validation Loss: 8.900918401195667e-05\n",
      "Epoch [7/25], Train Loss: 0.00010243847646052018, Validation Loss: 8.888716499010722e-05\n",
      "Epoch [7/25], Train Loss: 7.0531117671635e-05, Validation Loss: 8.887827134458348e-05\n",
      "Epoch [7/25], Train Loss: 8.835323387756944e-05, Validation Loss: 8.890330039624435e-05\n",
      "Epoch [7/25], Train Loss: 0.00011699373135343194, Validation Loss: 8.889012218181355e-05\n",
      "Epoch [7/25], Train Loss: 9.465810580877587e-05, Validation Loss: 8.883542783830004e-05\n",
      "Epoch [7/25], Train Loss: 7.257200195454061e-05, Validation Loss: 8.88264856863922e-05\n",
      "Epoch [7/25], Train Loss: 9.364212746731937e-05, Validation Loss: 8.88637512010367e-05\n",
      "Epoch [7/25], Train Loss: 7.719515269855037e-05, Validation Loss: 8.888839753732707e-05\n",
      "Epoch [7/25], Train Loss: 0.00010139986989088356, Validation Loss: 8.885856635364083e-05\n",
      "Epoch [7/25], Train Loss: 9.918672003550455e-05, Validation Loss: 8.883481544520085e-05\n",
      "Epoch [7/25], Train Loss: 0.00010437350283609703, Validation Loss: 8.886074162243555e-05\n",
      "Epoch [7/25], Train Loss: 9.55642681219615e-05, Validation Loss: 8.889119950860428e-05\n",
      "Epoch [7/25], Train Loss: 7.944977551233023e-05, Validation Loss: 8.888135368276076e-05\n",
      "Epoch [7/25], Train Loss: 9.145028161583468e-05, Validation Loss: 8.890672421936566e-05\n",
      "Epoch [7/25], Train Loss: 8.357728802366182e-05, Validation Loss: 8.893706350742529e-05\n",
      "Epoch [7/25], Train Loss: 8.408522990066558e-05, Validation Loss: 8.901512313362522e-05\n",
      "Epoch [7/25], Train Loss: 8.211372187361121e-05, Validation Loss: 8.904592832550406e-05\n",
      "Epoch [7/25], Train Loss: 9.217234764946625e-05, Validation Loss: 8.908505915314891e-05\n",
      "Epoch [7/25], Train Loss: 8.112816431093961e-05, Validation Loss: 8.917613789283981e-05\n",
      "Epoch [7/25], Train Loss: 8.887339936336502e-05, Validation Loss: 8.932008786359802e-05\n",
      "Epoch [7/25], Train Loss: 6.401099381037056e-05, Validation Loss: 8.949168162265171e-05\n",
      "Epoch [7/25], Train Loss: 0.00012512484681792557, Validation Loss: 8.968229400731312e-05\n",
      "Epoch [7/25], Train Loss: 8.593059465056285e-05, Validation Loss: 8.988477178111983e-05\n",
      "Epoch [7/25], Train Loss: 8.826134580885991e-05, Validation Loss: 9.036199990077875e-05\n",
      "Epoch [7/25], Train Loss: 7.042131619527936e-05, Validation Loss: 9.106809205453223e-05\n",
      "Epoch [7/25], Train Loss: 0.0001247539184987545, Validation Loss: 9.196347770436356e-05\n",
      "Epoch [7/25], Train Loss: 8.379273640457541e-05, Validation Loss: 9.29622823605314e-05\n",
      "Epoch [7/25], Train Loss: 9.946006321115419e-05, Validation Loss: 9.422924874039988e-05\n",
      "Epoch [7/25], Train Loss: 9.510589734418318e-05, Validation Loss: 9.569627630601947e-05\n",
      "Epoch [7/25], Train Loss: 0.00010675167868612334, Validation Loss: 9.715906635392458e-05\n",
      "Epoch [7/25], Train Loss: 0.0001371987018501386, Validation Loss: 9.797256934689358e-05\n",
      "Epoch [7/25], Train Loss: 8.06518510216847e-05, Validation Loss: 9.805564817118768e-05\n",
      "Epoch [7/25], Train Loss: 0.00010570200538495556, Validation Loss: 9.677980027239149e-05\n",
      "Epoch [7/25], Train Loss: 0.0001258483825949952, Validation Loss: 9.426708711544052e-05\n",
      "Epoch [7/25], Train Loss: 0.00011757761240005493, Validation Loss: 9.126096701947973e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Train Loss: 0.00010364556510467082, Validation Loss: 8.916615285367394e-05\n",
      "Epoch [7/25], Train Loss: 0.00010161101090488955, Validation Loss: 8.840932544747677e-05\n",
      "Epoch [7/25], Train Loss: 6.838151603005826e-05, Validation Loss: 8.905422291718423e-05\n",
      "Epoch [7/25], Train Loss: 8.739272743696347e-05, Validation Loss: 9.05623409683661e-05\n",
      "Epoch [7/25], Train Loss: 8.800188516033813e-05, Validation Loss: 9.163008556546022e-05\n",
      "Epoch [7/25], Train Loss: 9.309823508374393e-05, Validation Loss: 9.163605233576769e-05\n",
      "Epoch [7/25], Train Loss: 9.903318277793005e-05, Validation Loss: 9.065761623787694e-05\n",
      "Epoch [7/25], Train Loss: 8.792376320343465e-05, Validation Loss: 8.934928409871645e-05\n",
      "Epoch [7/25], Train Loss: 6.684855907224119e-05, Validation Loss: 8.843624139747893e-05\n",
      "Epoch [7/25], Train Loss: 7.919593917904422e-05, Validation Loss: 8.843083002526933e-05\n",
      "Epoch [7/25], Train Loss: 8.280220936285332e-05, Validation Loss: 8.897553270799108e-05\n",
      "Epoch [8/25], Train Loss: 9.474249964114279e-05, Validation Loss: 8.946537248751459e-05\n",
      "Epoch [8/25], Train Loss: 9.518944716546685e-05, Validation Loss: 8.955264565884136e-05\n",
      "Epoch [8/25], Train Loss: 0.00010806421778397635, Validation Loss: 8.906488122496133e-05\n",
      "Epoch [8/25], Train Loss: 7.864156214054674e-05, Validation Loss: 8.853010779906375e-05\n",
      "Epoch [8/25], Train Loss: 6.352140917442739e-05, Validation Loss: 8.826091458710531e-05\n",
      "Epoch [8/25], Train Loss: 8.82864769664593e-05, Validation Loss: 8.832600142341107e-05\n",
      "Epoch [8/25], Train Loss: 8.114699448924512e-05, Validation Loss: 8.857777841816035e-05\n",
      "Epoch [8/25], Train Loss: 6.742922414559871e-05, Validation Loss: 8.876524443621748e-05\n",
      "Epoch [8/25], Train Loss: 6.820104317739606e-05, Validation Loss: 8.875275307218544e-05\n",
      "Epoch [8/25], Train Loss: 0.00010087964619742706, Validation Loss: 8.857851401747515e-05\n",
      "Epoch [8/25], Train Loss: 0.00011226172500755638, Validation Loss: 8.839805620179202e-05\n",
      "Epoch [8/25], Train Loss: 8.743791113374755e-05, Validation Loss: 8.824092171077306e-05\n",
      "Epoch [8/25], Train Loss: 7.875940355006605e-05, Validation Loss: 8.81834236982589e-05\n",
      "Epoch [8/25], Train Loss: 6.489686347777024e-05, Validation Loss: 8.821656883810647e-05\n",
      "Epoch [8/25], Train Loss: 8.068631723290309e-05, Validation Loss: 8.829641204404955e-05\n",
      "Epoch [8/25], Train Loss: 9.392351057613268e-05, Validation Loss: 8.837150113928752e-05\n",
      "Epoch [8/25], Train Loss: 0.00010845706128748134, Validation Loss: 8.836367075370314e-05\n",
      "Epoch [8/25], Train Loss: 7.844092033337802e-05, Validation Loss: 8.8275322195841e-05\n",
      "Epoch [8/25], Train Loss: 0.0001082226590369828, Validation Loss: 8.813601549870023e-05\n",
      "Epoch [8/25], Train Loss: 7.605238351970911e-05, Validation Loss: 8.80701469820148e-05\n",
      "Epoch [8/25], Train Loss: 7.270110654644668e-05, Validation Loss: 8.807106302507842e-05\n",
      "Epoch [8/25], Train Loss: 9.137428423855454e-05, Validation Loss: 8.814313502322571e-05\n",
      "Epoch [8/25], Train Loss: 0.00010131188173545524, Validation Loss: 8.824237738735974e-05\n",
      "Epoch [8/25], Train Loss: 0.00011005342821590602, Validation Loss: 8.830198009187976e-05\n",
      "Epoch [8/25], Train Loss: 9.035788389155641e-05, Validation Loss: 8.837232186730641e-05\n",
      "Epoch [8/25], Train Loss: 9.129856334766373e-05, Validation Loss: 8.837709077245867e-05\n",
      "Epoch [8/25], Train Loss: 0.0001086373085854575, Validation Loss: 8.837133912796465e-05\n",
      "Epoch [8/25], Train Loss: 8.831826562527567e-05, Validation Loss: 8.83260574482847e-05\n",
      "Epoch [8/25], Train Loss: 7.41387702873908e-05, Validation Loss: 8.828446904468971e-05\n",
      "Epoch [8/25], Train Loss: 9.394457447342575e-05, Validation Loss: 8.816209010547027e-05\n",
      "Epoch [8/25], Train Loss: 9.698975918581709e-05, Validation Loss: 8.808535106557732e-05\n",
      "Epoch [8/25], Train Loss: 8.051899931160733e-05, Validation Loss: 8.80110586876981e-05\n",
      "Epoch [8/25], Train Loss: 6.446578481700271e-05, Validation Loss: 8.79516648031616e-05\n",
      "Epoch [8/25], Train Loss: 0.00010307004413334653, Validation Loss: 8.79098428413272e-05\n",
      "Epoch [8/25], Train Loss: 7.949243445182219e-05, Validation Loss: 8.788394504032719e-05\n",
      "Epoch [8/25], Train Loss: 8.402518869843334e-05, Validation Loss: 8.7881697982084e-05\n",
      "Epoch [8/25], Train Loss: 0.00010049499542219564, Validation Loss: 8.786871136787036e-05\n",
      "Epoch [8/25], Train Loss: 0.00010256405221298337, Validation Loss: 8.784180827206e-05\n",
      "Epoch [8/25], Train Loss: 9.534160199109465e-05, Validation Loss: 8.782478932213659e-05\n",
      "Epoch [8/25], Train Loss: 7.909119449323043e-05, Validation Loss: 8.780910914841418e-05\n",
      "Epoch [8/25], Train Loss: 8.688071102369577e-05, Validation Loss: 8.781565799533079e-05\n",
      "Epoch [8/25], Train Loss: 9.702867100713775e-05, Validation Loss: 8.783584222934829e-05\n",
      "Epoch [8/25], Train Loss: 0.00010944748646579683, Validation Loss: 8.78507036153072e-05\n",
      "Epoch [8/25], Train Loss: 0.00011356223694747314, Validation Loss: 8.785002695124907e-05\n",
      "Epoch [8/25], Train Loss: 9.877872798824683e-05, Validation Loss: 8.78424490413939e-05\n",
      "Epoch [8/25], Train Loss: 7.693214865867049e-05, Validation Loss: 8.789113344391808e-05\n",
      "Epoch [8/25], Train Loss: 0.00010322384332539514, Validation Loss: 8.80219978474391e-05\n",
      "Epoch [8/25], Train Loss: 8.965825691120699e-05, Validation Loss: 8.828027008955057e-05\n",
      "Epoch [8/25], Train Loss: 8.539709961041808e-05, Validation Loss: 8.861131015388915e-05\n",
      "Epoch [8/25], Train Loss: 7.696554530411959e-05, Validation Loss: 8.930032612018598e-05\n",
      "Epoch [8/25], Train Loss: 0.00010027673852164298, Validation Loss: 9.044718487227025e-05\n",
      "Epoch [8/25], Train Loss: 7.773857214488089e-05, Validation Loss: 9.274726908188313e-05\n",
      "Epoch [8/25], Train Loss: 5.6931930885184556e-05, Validation Loss: 9.700184600660577e-05\n",
      "Epoch [8/25], Train Loss: 0.00010545228724367917, Validation Loss: 0.00010440916375955566\n",
      "Epoch [8/25], Train Loss: 0.0001100948647945188, Validation Loss: 0.00011520644523746645\n",
      "Epoch [8/25], Train Loss: 0.00014637969434261322, Validation Loss: 0.00012769984459737316\n",
      "Epoch [8/25], Train Loss: 0.00013633751950692385, Validation Loss: 0.00013528607038703437\n",
      "Epoch [8/25], Train Loss: 0.00012645413517020643, Validation Loss: 0.00012708296368752297\n",
      "Epoch [8/25], Train Loss: 0.00012579307076521218, Validation Loss: 0.00010405321760723989\n",
      "Epoch [8/25], Train Loss: 0.0001135839702328667, Validation Loss: 8.855949417920783e-05\n",
      "Epoch [8/25], Train Loss: 8.867540600476786e-05, Validation Loss: 9.550910084120309e-05\n",
      "Epoch [8/25], Train Loss: 0.0001027431499096565, Validation Loss: 0.00010822031423837567\n",
      "Epoch [8/25], Train Loss: 9.787410090211779e-05, Validation Loss: 0.00010398050459722677\n",
      "Epoch [8/25], Train Loss: 7.594822818646207e-05, Validation Loss: 9.041721738564471e-05\n",
      "Epoch [8/25], Train Loss: 9.353864152217284e-05, Validation Loss: 9.029419040113377e-05\n",
      "Epoch [8/25], Train Loss: 9.036417031893507e-05, Validation Loss: 9.939383016899228e-05\n",
      "Epoch [8/25], Train Loss: 0.00012605638767126948, Validation Loss: 9.690085231947402e-05\n",
      "Epoch [8/25], Train Loss: 0.0001262843725271523, Validation Loss: 8.828686841297895e-05\n",
      "Epoch [8/25], Train Loss: 0.00010453514551045373, Validation Loss: 9.089743349856386e-05\n",
      "Epoch [8/25], Train Loss: 8.3045510109514e-05, Validation Loss: 9.614962182240561e-05\n",
      "Epoch [8/25], Train Loss: 8.474837522953749e-05, Validation Loss: 9.130146063398569e-05\n",
      "Epoch [8/25], Train Loss: 8.519687980879098e-05, Validation Loss: 8.802089359960519e-05\n",
      "Epoch [8/25], Train Loss: 9.302967373514548e-05, Validation Loss: 9.252467862097546e-05\n",
      "Epoch [8/25], Train Loss: 9.976944420486689e-05, Validation Loss: 9.23820038830551e-05\n",
      "Epoch [8/25], Train Loss: 0.00010763002501334995, Validation Loss: 8.796752129759018e-05\n",
      "Epoch [8/25], Train Loss: 8.962092397268862e-05, Validation Loss: 8.949952049685332e-05\n",
      "Epoch [8/25], Train Loss: 7.523695239797235e-05, Validation Loss: 9.16263927744391e-05\n",
      "Epoch [8/25], Train Loss: 8.245863136835396e-05, Validation Loss: 8.87296553022073e-05\n",
      "Epoch [8/25], Train Loss: 7.056562753859907e-05, Validation Loss: 8.80559394621135e-05\n",
      "Epoch [8/25], Train Loss: 9.001916623674333e-05, Validation Loss: 9.027878598620495e-05\n",
      "Epoch [8/25], Train Loss: 8.883108239388093e-05, Validation Loss: 8.914140271372162e-05\n",
      "Epoch [8/25], Train Loss: 8.041736873565242e-05, Validation Loss: 8.765532499334464e-05\n",
      "Epoch [8/25], Train Loss: 9.360292460769415e-05, Validation Loss: 8.924353533075191e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Train Loss: 0.000103343918453902, Validation Loss: 8.919064785004594e-05\n",
      "Epoch [8/25], Train Loss: 0.00010087144619319588, Validation Loss: 8.763847169272292e-05\n",
      "Epoch [8/25], Train Loss: 8.301732304971665e-05, Validation Loss: 8.837227578624151e-05\n",
      "Epoch [8/25], Train Loss: 8.346459799213335e-05, Validation Loss: 8.893752844111684e-05\n",
      "Epoch [8/25], Train Loss: 7.398548041237518e-05, Validation Loss: 8.777476784113483e-05\n",
      "Epoch [8/25], Train Loss: 6.682574894512072e-05, Validation Loss: 8.7876727047842e-05\n",
      "Epoch [8/25], Train Loss: 9.621501521905884e-05, Validation Loss: 8.920760786471268e-05\n",
      "Epoch [8/25], Train Loss: 7.40522300475277e-05, Validation Loss: 8.874537670635618e-05\n",
      "Epoch [8/25], Train Loss: 6.834361556684598e-05, Validation Loss: 8.789787631637106e-05\n",
      "Epoch [8/25], Train Loss: 7.17286893632263e-05, Validation Loss: 8.880744668810318e-05\n",
      "Epoch [8/25], Train Loss: 8.366728434339166e-05, Validation Loss: 8.861877940944397e-05\n",
      "Epoch [8/25], Train Loss: 9.525138011667877e-05, Validation Loss: 8.762130431326417e-05\n",
      "Epoch [8/25], Train Loss: 9.463004971621558e-05, Validation Loss: 8.804928487127957e-05\n",
      "Epoch [8/25], Train Loss: 8.458014781353995e-05, Validation Loss: 8.854735375886472e-05\n",
      "Epoch [8/25], Train Loss: 0.00011685030767694116, Validation Loss: 8.79650183681709e-05\n",
      "Epoch [8/25], Train Loss: 7.574399205623195e-05, Validation Loss: 8.780357287226555e-05\n",
      "Epoch [8/25], Train Loss: 0.00010134444164577872, Validation Loss: 8.816480937336261e-05\n",
      "Epoch [8/25], Train Loss: 0.00010222125274594873, Validation Loss: 8.785840424631411e-05\n",
      "Epoch [8/25], Train Loss: 8.505896403221413e-05, Validation Loss: 8.74687117175199e-05\n",
      "Epoch [8/25], Train Loss: 8.165257895598188e-05, Validation Loss: 8.774504046111057e-05\n",
      "Epoch [8/25], Train Loss: 9.058748401002958e-05, Validation Loss: 8.785096627737706e-05\n",
      "Epoch [8/25], Train Loss: 7.460836786776781e-05, Validation Loss: 8.751011240140846e-05\n",
      "Epoch [8/25], Train Loss: 7.631991320522502e-05, Validation Loss: 8.750669949222356e-05\n",
      "Epoch [8/25], Train Loss: 9.073694673134014e-05, Validation Loss: 8.76481620556054e-05\n",
      "Epoch [8/25], Train Loss: 9.216205216944218e-05, Validation Loss: 8.750112295577614e-05\n",
      "Epoch [8/25], Train Loss: 0.00010018263856181875, Validation Loss: 8.739387048990465e-05\n",
      "Epoch [8/25], Train Loss: 9.691136074252427e-05, Validation Loss: 8.750145837742215e-05\n",
      "Epoch [8/25], Train Loss: 8.706974040251225e-05, Validation Loss: 8.751691833216076e-05\n",
      "Epoch [8/25], Train Loss: 0.00010154589108424261, Validation Loss: 8.74126844185715e-05\n",
      "Epoch [8/25], Train Loss: 0.00011045107385143638, Validation Loss: 8.735594456084072e-05\n",
      "Epoch [8/25], Train Loss: 9.555186261422932e-05, Validation Loss: 8.738836428771417e-05\n",
      "Epoch [8/25], Train Loss: 0.00010191107867285609, Validation Loss: 8.735398490292331e-05\n",
      "Epoch [8/25], Train Loss: 9.202136425301433e-05, Validation Loss: 8.724687237796995e-05\n",
      "Epoch [8/25], Train Loss: 0.00011439622903708369, Validation Loss: 8.729865876375698e-05\n",
      "Epoch [8/25], Train Loss: 9.956998110283166e-05, Validation Loss: 8.730940220023816e-05\n",
      "Epoch [8/25], Train Loss: 8.603011519880965e-05, Validation Loss: 8.722769804686929e-05\n",
      "Epoch [8/25], Train Loss: 9.01142557268031e-05, Validation Loss: 8.715326669819964e-05\n",
      "Epoch [8/25], Train Loss: 8.942183194449171e-05, Validation Loss: 8.713038550922647e-05\n",
      "Epoch [8/25], Train Loss: 9.44856001297012e-05, Validation Loss: 8.710250913281924e-05\n",
      "Epoch [8/25], Train Loss: 9.414731175638735e-05, Validation Loss: 8.70523372820268e-05\n",
      "Epoch [8/25], Train Loss: 9.90307453321293e-05, Validation Loss: 8.710135904645236e-05\n",
      "Epoch [8/25], Train Loss: 8.07169999461621e-05, Validation Loss: 8.749087016137006e-05\n",
      "Epoch [8/25], Train Loss: 9.10884264158085e-05, Validation Loss: 8.834409891278483e-05\n",
      "Epoch [8/25], Train Loss: 9.621497156331316e-05, Validation Loss: 8.928287740369948e-05\n",
      "Epoch [8/25], Train Loss: 8.908885502023622e-05, Validation Loss: 8.976777705053489e-05\n",
      "Epoch [8/25], Train Loss: 9.365635924041271e-05, Validation Loss: 8.954346000488537e-05\n",
      "Epoch [8/25], Train Loss: 0.00010086067049996927, Validation Loss: 8.881892354111187e-05\n",
      "Epoch [8/25], Train Loss: 9.351520566269755e-05, Validation Loss: 8.793149536359123e-05\n",
      "Epoch [8/25], Train Loss: 9.469317592447624e-05, Validation Loss: 8.721725850288445e-05\n",
      "Epoch [8/25], Train Loss: 0.0001040504575939849, Validation Loss: 8.7000236089807e-05\n",
      "Epoch [8/25], Train Loss: 8.315977174788713e-05, Validation Loss: 8.734320193373909e-05\n",
      "Epoch [9/25], Train Loss: 9.168080578092486e-05, Validation Loss: 8.785437579111507e-05\n",
      "Epoch [9/25], Train Loss: 8.667944348417222e-05, Validation Loss: 8.806523934860404e-05\n",
      "Epoch [9/25], Train Loss: 8.477905066683888e-05, Validation Loss: 8.803360178717412e-05\n",
      "Epoch [9/25], Train Loss: 9.092121035791934e-05, Validation Loss: 8.778093615546823e-05\n",
      "Epoch [9/25], Train Loss: 8.911888289730996e-05, Validation Loss: 8.741219329143254e-05\n",
      "Epoch [9/25], Train Loss: 8.491657354170457e-05, Validation Loss: 8.703569134619708e-05\n",
      "Epoch [9/25], Train Loss: 8.228640217566863e-05, Validation Loss: 8.681677403122497e-05\n",
      "Epoch [9/25], Train Loss: 7.050663407426327e-05, Validation Loss: 8.684553734686537e-05\n",
      "Epoch [9/25], Train Loss: 8.420892845606431e-05, Validation Loss: 8.697413383439804e-05\n",
      "Epoch [9/25], Train Loss: 0.00010393519914941862, Validation Loss: 8.716403972357512e-05\n",
      "Epoch [9/25], Train Loss: 0.00010405652574263513, Validation Loss: 8.729318045273734e-05\n",
      "Epoch [9/25], Train Loss: 0.00010136691707884893, Validation Loss: 8.727903308075232e-05\n",
      "Epoch [9/25], Train Loss: 7.573833136120811e-05, Validation Loss: 8.717204351948264e-05\n",
      "Epoch [9/25], Train Loss: 8.705850632395595e-05, Validation Loss: 8.712801524476768e-05\n",
      "Epoch [9/25], Train Loss: 8.453623740933836e-05, Validation Loss: 8.735174778848887e-05\n",
      "Epoch [9/25], Train Loss: 7.832877599867061e-05, Validation Loss: 8.767823674133979e-05\n",
      "Epoch [9/25], Train Loss: 9.965075150830671e-05, Validation Loss: 8.768339685047977e-05\n",
      "Epoch [9/25], Train Loss: 9.858714474830776e-05, Validation Loss: 8.749941674371561e-05\n",
      "Epoch [9/25], Train Loss: 9.200484782923013e-05, Validation Loss: 8.714008654351347e-05\n",
      "Epoch [9/25], Train Loss: 0.00010263040894642472, Validation Loss: 8.693511748181966e-05\n",
      "Epoch [9/25], Train Loss: 0.00011105735757155344, Validation Loss: 8.684586258217072e-05\n",
      "Epoch [9/25], Train Loss: 9.856747783487663e-05, Validation Loss: 8.675571759037363e-05\n",
      "Epoch [9/25], Train Loss: 9.280026279157028e-05, Validation Loss: 8.669811601672943e-05\n",
      "Epoch [9/25], Train Loss: 8.439332304988056e-05, Validation Loss: 8.681854208892522e-05\n",
      "Epoch [9/25], Train Loss: 8.452156180283055e-05, Validation Loss: 8.695448971896743e-05\n",
      "Epoch [9/25], Train Loss: 0.00011149384954478592, Validation Loss: 8.696786802223263e-05\n",
      "Epoch [9/25], Train Loss: 7.492700387956575e-05, Validation Loss: 8.693048633479823e-05\n",
      "Epoch [9/25], Train Loss: 9.656524343881756e-05, Validation Loss: 8.681689869263209e-05\n",
      "Epoch [9/25], Train Loss: 0.00010255804954795167, Validation Loss: 8.669559416982034e-05\n",
      "Epoch [9/25], Train Loss: 9.25833301153034e-05, Validation Loss: 8.674179844092578e-05\n",
      "Epoch [9/25], Train Loss: 7.594507042085752e-05, Validation Loss: 8.68869414262008e-05\n",
      "Epoch [9/25], Train Loss: 9.360499825561419e-05, Validation Loss: 8.675128459193124e-05\n",
      "Epoch [9/25], Train Loss: 0.00011272889969404787, Validation Loss: 8.65205809532199e-05\n",
      "Epoch [9/25], Train Loss: 7.482005457859486e-05, Validation Loss: 8.644345119440307e-05\n",
      "Epoch [9/25], Train Loss: 0.00010040888446383178, Validation Loss: 8.644004095306931e-05\n",
      "Epoch [9/25], Train Loss: 0.00012944606714881957, Validation Loss: 8.641363601782359e-05\n",
      "Epoch [9/25], Train Loss: 9.174852311844006e-05, Validation Loss: 8.637130498148812e-05\n",
      "Epoch [9/25], Train Loss: 8.526111923856661e-05, Validation Loss: 8.629235744592734e-05\n",
      "Epoch [9/25], Train Loss: 9.007267362903804e-05, Validation Loss: 8.622280753722104e-05\n",
      "Epoch [9/25], Train Loss: 0.00011821086081909016, Validation Loss: 8.625229335545252e-05\n",
      "Epoch [9/25], Train Loss: 8.292456186609343e-05, Validation Loss: 8.638892953361695e-05\n",
      "Epoch [9/25], Train Loss: 9.753013000590727e-05, Validation Loss: 8.710466839450722e-05\n",
      "Epoch [9/25], Train Loss: 6.959625898161903e-05, Validation Loss: 9.015352164472763e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Train Loss: 6.835609383415431e-05, Validation Loss: 9.418991588366528e-05\n",
      "Epoch [9/25], Train Loss: 9.352022607345134e-05, Validation Loss: 9.680024231784046e-05\n",
      "Epoch [9/25], Train Loss: 9.356778173241764e-05, Validation Loss: 9.769216558197513e-05\n",
      "Epoch [9/25], Train Loss: 8.720892219571397e-05, Validation Loss: 9.694878050747017e-05\n",
      "Epoch [9/25], Train Loss: 0.00010721671424107626, Validation Loss: 9.53091929356257e-05\n",
      "Epoch [9/25], Train Loss: 8.853464532876387e-05, Validation Loss: 9.320533523956934e-05\n",
      "Epoch [9/25], Train Loss: 7.653072680113837e-05, Validation Loss: 9.059601191741725e-05\n",
      "Epoch [9/25], Train Loss: 0.00011757637548726052, Validation Loss: 8.845516761842494e-05\n",
      "Epoch [9/25], Train Loss: 0.00010142884275410324, Validation Loss: 8.772486083519955e-05\n",
      "Epoch [9/25], Train Loss: 6.58551580272615e-05, Validation Loss: 8.844178931515974e-05\n",
      "Epoch [9/25], Train Loss: 7.634715439053252e-05, Validation Loss: 9.002755250548944e-05\n",
      "Epoch [9/25], Train Loss: 6.125141226220876e-05, Validation Loss: 9.097409395811459e-05\n",
      "Epoch [9/25], Train Loss: 0.00010449012188473716, Validation Loss: 9.015178560124089e-05\n",
      "Epoch [9/25], Train Loss: 9.331804903922603e-05, Validation Loss: 8.820042082030947e-05\n",
      "Epoch [9/25], Train Loss: 9.948185470420867e-05, Validation Loss: 8.667902705686478e-05\n",
      "Epoch [9/25], Train Loss: 8.408643043367192e-05, Validation Loss: 8.668413962974834e-05\n",
      "Epoch [9/25], Train Loss: 9.118085290538147e-05, Validation Loss: 8.799721375301791e-05\n",
      "Epoch [9/25], Train Loss: 9.23260158742778e-05, Validation Loss: 8.905029171728529e-05\n",
      "Epoch [9/25], Train Loss: 8.29735363367945e-05, Validation Loss: 8.872200147986102e-05\n",
      "Epoch [9/25], Train Loss: 0.00010763044701889157, Validation Loss: 8.732847976110255e-05\n",
      "Epoch [9/25], Train Loss: 0.00010660938278306276, Validation Loss: 8.628622066074362e-05\n",
      "Epoch [9/25], Train Loss: 9.409934864379466e-05, Validation Loss: 8.636509470913248e-05\n",
      "Epoch [9/25], Train Loss: 7.399088644888252e-05, Validation Loss: 8.727845973529232e-05\n",
      "Epoch [9/25], Train Loss: 0.00011081454431405291, Validation Loss: 8.784405169232438e-05\n",
      "Epoch [9/25], Train Loss: 7.849443500163034e-05, Validation Loss: 8.747927131480537e-05\n",
      "Epoch [9/25], Train Loss: 9.676029731053859e-05, Validation Loss: 8.667556733901924e-05\n",
      "Epoch [9/25], Train Loss: 0.0001010965570458211, Validation Loss: 8.610266959294677e-05\n",
      "Epoch [9/25], Train Loss: 7.254348747665063e-05, Validation Loss: 8.613016398157924e-05\n",
      "Epoch [9/25], Train Loss: 7.934738096082583e-05, Validation Loss: 8.65030349814333e-05\n",
      "Epoch [9/25], Train Loss: 0.00010214361100224778, Validation Loss: 8.668127338751219e-05\n",
      "Epoch [9/25], Train Loss: 9.454139944864437e-05, Validation Loss: 8.653928452986292e-05\n",
      "Epoch [9/25], Train Loss: 8.153349335771054e-05, Validation Loss: 8.622335226391443e-05\n",
      "Epoch [9/25], Train Loss: 8.941970008891076e-05, Validation Loss: 8.596728002885357e-05\n",
      "Epoch [9/25], Train Loss: 9.855769167188555e-05, Validation Loss: 8.592551384936086e-05\n",
      "Epoch [9/25], Train Loss: 7.96847598394379e-05, Validation Loss: 8.631727202252174e-05\n",
      "Epoch [9/25], Train Loss: 8.695299038663507e-05, Validation Loss: 8.72792094014585e-05\n",
      "Epoch [9/25], Train Loss: 8.771492139203474e-05, Validation Loss: 8.852415242775654e-05\n",
      "Epoch [9/25], Train Loss: 9.942208271240816e-05, Validation Loss: 8.863291780774792e-05\n",
      "Epoch [9/25], Train Loss: 9.180885535897687e-05, Validation Loss: 8.825841190021796e-05\n",
      "Epoch [9/25], Train Loss: 9.91468841675669e-05, Validation Loss: 8.740454553238427e-05\n",
      "Epoch [9/25], Train Loss: 8.472872286802158e-05, Validation Loss: 8.663441136983845e-05\n",
      "Epoch [9/25], Train Loss: 9.727151336846873e-05, Validation Loss: 8.628887080703862e-05\n",
      "Epoch [9/25], Train Loss: 7.686161552555859e-05, Validation Loss: 8.633356240655606e-05\n",
      "Epoch [9/25], Train Loss: 9.567249071551487e-05, Validation Loss: 8.668402200176692e-05\n",
      "Epoch [9/25], Train Loss: 8.497710223309696e-05, Validation Loss: 8.690252191930388e-05\n",
      "Epoch [9/25], Train Loss: 9.35167699935846e-05, Validation Loss: 8.682617529605825e-05\n",
      "Epoch [9/25], Train Loss: 9.290184243582189e-05, Validation Loss: 8.683203074421423e-05\n",
      "Epoch [9/25], Train Loss: 6.69457294861786e-05, Validation Loss: 8.673712363815866e-05\n",
      "Epoch [9/25], Train Loss: 9.066765051102266e-05, Validation Loss: 8.627437249136468e-05\n",
      "Epoch [9/25], Train Loss: 7.784531044308096e-05, Validation Loss: 8.58763853708903e-05\n",
      "Epoch [9/25], Train Loss: 8.667622751090676e-05, Validation Loss: 8.570439264682742e-05\n",
      "Epoch [9/25], Train Loss: 9.659002535045147e-05, Validation Loss: 8.554495822560663e-05\n",
      "Epoch [9/25], Train Loss: 8.0457168223802e-05, Validation Loss: 8.57070697141656e-05\n",
      "Epoch [9/25], Train Loss: 8.686037472216412e-05, Validation Loss: 8.694627928586366e-05\n",
      "Epoch [9/25], Train Loss: 9.110051905736327e-05, Validation Loss: 8.845835109241306e-05\n",
      "Epoch [9/25], Train Loss: 9.762409899849445e-05, Validation Loss: 8.936262165661901e-05\n",
      "Epoch [9/25], Train Loss: 7.542929233750328e-05, Validation Loss: 8.962928453305115e-05\n",
      "Epoch [9/25], Train Loss: 7.485806418117136e-05, Validation Loss: 8.88000286067836e-05\n",
      "Epoch [9/25], Train Loss: 7.073648157529533e-05, Validation Loss: 8.743920552660711e-05\n",
      "Epoch [9/25], Train Loss: 7.756976992823184e-05, Validation Loss: 8.639105799375102e-05\n",
      "Epoch [9/25], Train Loss: 8.41496730572544e-05, Validation Loss: 8.560028266704952e-05\n",
      "Epoch [9/25], Train Loss: 7.460783672286198e-05, Validation Loss: 8.535400823651192e-05\n",
      "Epoch [9/25], Train Loss: 9.738234075484797e-05, Validation Loss: 8.582631053286605e-05\n",
      "Epoch [9/25], Train Loss: 8.21352077764459e-05, Validation Loss: 8.737285728178297e-05\n",
      "Epoch [9/25], Train Loss: 7.09124215063639e-05, Validation Loss: 9.124507244753962e-05\n",
      "Epoch [9/25], Train Loss: 0.00010077231127070263, Validation Loss: 9.596961317583918e-05\n",
      "Epoch [9/25], Train Loss: 9.275030606659129e-05, Validation Loss: 9.709549776744097e-05\n",
      "Epoch [9/25], Train Loss: 9.959511953638867e-05, Validation Loss: 9.445548785151914e-05\n",
      "Epoch [9/25], Train Loss: 0.00010062758519779891, Validation Loss: 8.949238059964652e-05\n",
      "Epoch [9/25], Train Loss: 9.733893966767937e-05, Validation Loss: 8.632809719226013e-05\n",
      "Epoch [9/25], Train Loss: 9.69305110629648e-05, Validation Loss: 8.632462146730783e-05\n",
      "Epoch [9/25], Train Loss: 8.406744746025652e-05, Validation Loss: 8.875039105381196e-05\n",
      "Epoch [9/25], Train Loss: 7.850609836168587e-05, Validation Loss: 9.094735626907398e-05\n",
      "Epoch [9/25], Train Loss: 0.0001032166910590604, Validation Loss: 9.049651610742634e-05\n",
      "Epoch [9/25], Train Loss: 8.951485506258905e-05, Validation Loss: 8.786413721585025e-05\n",
      "Epoch [9/25], Train Loss: 9.55317445914261e-05, Validation Loss: 8.58404026075732e-05\n",
      "Epoch [9/25], Train Loss: 8.263123163487762e-05, Validation Loss: 8.585198132398849e-05\n",
      "Epoch [9/25], Train Loss: 8.18735861685127e-05, Validation Loss: 8.715203051300099e-05\n",
      "Epoch [9/25], Train Loss: 9.548879461362958e-05, Validation Loss: 8.819792080127324e-05\n",
      "Epoch [9/25], Train Loss: 8.3388906205073e-05, Validation Loss: 8.77493742639975e-05\n",
      "Epoch [9/25], Train Loss: 8.936382073443383e-05, Validation Loss: 8.628590730950237e-05\n",
      "Epoch [9/25], Train Loss: 6.47066262899898e-05, Validation Loss: 8.5379146427537e-05\n",
      "Epoch [9/25], Train Loss: 0.00010382205800851807, Validation Loss: 8.57888914955159e-05\n",
      "Epoch [9/25], Train Loss: 9.65088838711381e-05, Validation Loss: 8.678304560210866e-05\n",
      "Epoch [9/25], Train Loss: 8.767870895098895e-05, Validation Loss: 8.705812991441539e-05\n",
      "Epoch [9/25], Train Loss: 8.890515891835093e-05, Validation Loss: 8.63693431407834e-05\n",
      "Epoch [9/25], Train Loss: 7.818607991794124e-05, Validation Loss: 8.552870785933919e-05\n",
      "Epoch [9/25], Train Loss: 9.05415290617384e-05, Validation Loss: 8.516752617045616e-05\n",
      "Epoch [9/25], Train Loss: 8.448093285551295e-05, Validation Loss: 8.544620529088812e-05\n",
      "Epoch [9/25], Train Loss: 8.090400660876185e-05, Validation Loss: 8.595239269197919e-05\n",
      "Epoch [9/25], Train Loss: 5.481955304276198e-05, Validation Loss: 8.596612121133754e-05\n",
      "Epoch [10/25], Train Loss: 7.43478667573072e-05, Validation Loss: 8.557142937206663e-05\n",
      "Epoch [10/25], Train Loss: 0.0001079599533113651, Validation Loss: 8.507524762535468e-05\n",
      "Epoch [10/25], Train Loss: 0.00011751118290703744, Validation Loss: 8.490056619242144e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Train Loss: 0.0001002220087684691, Validation Loss: 8.51388744194992e-05\n",
      "Epoch [10/25], Train Loss: 8.612476813141257e-05, Validation Loss: 8.542665964341722e-05\n",
      "Epoch [10/25], Train Loss: 8.290968253277242e-05, Validation Loss: 8.563110629135432e-05\n",
      "Epoch [10/25], Train Loss: 0.00010952678712783381, Validation Loss: 8.599862218640434e-05\n",
      "Epoch [10/25], Train Loss: 9.5730836619623e-05, Validation Loss: 8.590200256245832e-05\n",
      "Epoch [10/25], Train Loss: 8.175842958735302e-05, Validation Loss: 8.527939207851887e-05\n",
      "Epoch [10/25], Train Loss: 0.00010564468539087102, Validation Loss: 8.496621012454852e-05\n",
      "Epoch [10/25], Train Loss: 6.961942563066259e-05, Validation Loss: 8.478196759824641e-05\n",
      "Epoch [10/25], Train Loss: 8.854553016135469e-05, Validation Loss: 8.483174751745537e-05\n",
      "Epoch [10/25], Train Loss: 7.419446774292737e-05, Validation Loss: 8.495197107549757e-05\n",
      "Epoch [10/25], Train Loss: 7.625663420185447e-05, Validation Loss: 8.600212483239981e-05\n",
      "Epoch [10/25], Train Loss: 8.734635775908828e-05, Validation Loss: 8.959675712200502e-05\n",
      "Epoch [10/25], Train Loss: 0.00010026065865531564, Validation Loss: 9.278100866746778e-05\n",
      "Epoch [10/25], Train Loss: 0.00010691084753489122, Validation Loss: 9.184948673161368e-05\n",
      "Epoch [10/25], Train Loss: 8.846438868204132e-05, Validation Loss: 8.973989849134037e-05\n",
      "Epoch [10/25], Train Loss: 6.808438774896786e-05, Validation Loss: 8.698931633261963e-05\n",
      "Epoch [10/25], Train Loss: 8.076909580267966e-05, Validation Loss: 8.54950128996279e-05\n",
      "Epoch [10/25], Train Loss: 0.00010438291064929217, Validation Loss: 8.678507947479375e-05\n",
      "Epoch [10/25], Train Loss: 8.544557204004377e-05, Validation Loss: 8.888243464753032e-05\n",
      "Epoch [10/25], Train Loss: 0.00010011430276790634, Validation Loss: 8.936314843595028e-05\n",
      "Epoch [10/25], Train Loss: 7.862853817641735e-05, Validation Loss: 8.785066602285951e-05\n",
      "Epoch [10/25], Train Loss: 7.380948954960331e-05, Validation Loss: 8.587996683975993e-05\n",
      "Epoch [10/25], Train Loss: 9.808163304114714e-05, Validation Loss: 8.514805910332749e-05\n",
      "Epoch [10/25], Train Loss: 8.834443724481389e-05, Validation Loss: 8.579592467867769e-05\n",
      "Epoch [10/25], Train Loss: 8.437671203864738e-05, Validation Loss: 8.66519983295196e-05\n",
      "Epoch [10/25], Train Loss: 8.126519969664514e-05, Validation Loss: 8.670794438027466e-05\n",
      "Epoch [10/25], Train Loss: 8.814436296233907e-05, Validation Loss: 8.579890369825686e-05\n",
      "Epoch [10/25], Train Loss: 0.00010155771451536566, Validation Loss: 8.449116260938657e-05\n",
      "Epoch [10/25], Train Loss: 7.479927444364876e-05, Validation Loss: 8.438026125077159e-05\n",
      "Epoch [10/25], Train Loss: 8.468424493912607e-05, Validation Loss: 8.433469071557435e-05\n",
      "Epoch [10/25], Train Loss: 7.28738377802074e-05, Validation Loss: 8.46171084655604e-05\n",
      "Epoch [10/25], Train Loss: 9.352951747132465e-05, Validation Loss: 8.476287306014759e-05\n",
      "Epoch [10/25], Train Loss: 7.310060027521104e-05, Validation Loss: 8.617417503652784e-05\n",
      "Epoch [10/25], Train Loss: 9.730102465255186e-05, Validation Loss: 8.994310580116387e-05\n",
      "Epoch [10/25], Train Loss: 8.827478450257331e-05, Validation Loss: 9.896407912795742e-05\n",
      "Epoch [10/25], Train Loss: 9.224197128787637e-05, Validation Loss: 0.00010406310369338219\n",
      "Epoch [10/25], Train Loss: 0.00011216184793738648, Validation Loss: 9.729975572554394e-05\n",
      "Epoch [10/25], Train Loss: 9.90540866041556e-05, Validation Loss: 9.230666764779017e-05\n",
      "Epoch [10/25], Train Loss: 8.60254731378518e-05, Validation Loss: 8.6856660588334e-05\n",
      "Epoch [10/25], Train Loss: 9.542435873299837e-05, Validation Loss: 8.725676428487835e-05\n",
      "Epoch [10/25], Train Loss: 7.859592005843297e-05, Validation Loss: 8.943666665193936e-05\n",
      "Epoch [10/25], Train Loss: 0.00011327472020639107, Validation Loss: 8.965671634844815e-05\n",
      "Epoch [10/25], Train Loss: 8.171934314304963e-05, Validation Loss: 8.774971744666497e-05\n",
      "Epoch [10/25], Train Loss: 9.633582521928474e-05, Validation Loss: 8.536722258819887e-05\n",
      "Epoch [10/25], Train Loss: 7.542398088844493e-05, Validation Loss: 8.567791034389909e-05\n",
      "Epoch [10/25], Train Loss: 9.21772516448982e-05, Validation Loss: 8.741665612130115e-05\n",
      "Epoch [10/25], Train Loss: 8.248446101788431e-05, Validation Loss: 8.715505246073007e-05\n",
      "Epoch [10/25], Train Loss: 8.731518755666912e-05, Validation Loss: 8.618477683436746e-05\n",
      "Epoch [10/25], Train Loss: 9.334136120742187e-05, Validation Loss: 8.584859436571909e-05\n",
      "Epoch [10/25], Train Loss: 7.524234388256446e-05, Validation Loss: 8.601496301707812e-05\n",
      "Epoch [10/25], Train Loss: 8.670848910696805e-05, Validation Loss: 8.670432968453194e-05\n",
      "Epoch [10/25], Train Loss: 0.00010076728358399123, Validation Loss: 8.643456700762424e-05\n",
      "Epoch [10/25], Train Loss: 9.148810931947082e-05, Validation Loss: 8.516494854120538e-05\n",
      "Epoch [10/25], Train Loss: 9.162357309833169e-05, Validation Loss: 8.476359532020676e-05\n",
      "Epoch [10/25], Train Loss: 6.626684626098722e-05, Validation Loss: 8.528319182611691e-05\n",
      "Epoch [10/25], Train Loss: 9.985759970732033e-05, Validation Loss: 8.549649282940663e-05\n",
      "Epoch [10/25], Train Loss: 7.661794370505959e-05, Validation Loss: 8.525656036605748e-05\n",
      "Epoch [10/25], Train Loss: 8.704629726707935e-05, Validation Loss: 8.484042676476141e-05\n",
      "Epoch [10/25], Train Loss: 8.310924749821424e-05, Validation Loss: 8.477822896869232e-05\n",
      "Epoch [10/25], Train Loss: 7.298534183064476e-05, Validation Loss: 8.51315155159682e-05\n",
      "Epoch [10/25], Train Loss: 9.195182792609558e-05, Validation Loss: 8.511578271281905e-05\n",
      "Epoch [10/25], Train Loss: 8.615619299234822e-05, Validation Loss: 8.475267532048747e-05\n",
      "Epoch [10/25], Train Loss: 0.00010378113074693829, Validation Loss: 8.460703732756276e-05\n",
      "Epoch [10/25], Train Loss: 8.881431131158024e-05, Validation Loss: 8.457342967934285e-05\n",
      "Epoch [10/25], Train Loss: 8.182974852388725e-05, Validation Loss: 8.452445520864178e-05\n",
      "Epoch [10/25], Train Loss: 6.98649455443956e-05, Validation Loss: 8.449667099436435e-05\n",
      "Epoch [10/25], Train Loss: 6.977720477152616e-05, Validation Loss: 8.434348904605334e-05\n",
      "Epoch [10/25], Train Loss: 7.314950926229358e-05, Validation Loss: 8.42500832125855e-05\n",
      "Epoch [10/25], Train Loss: 8.40022403281182e-05, Validation Loss: 8.428155997535214e-05\n",
      "Epoch [10/25], Train Loss: 9.197281178785488e-05, Validation Loss: 8.428959990851581e-05\n",
      "Epoch [10/25], Train Loss: 7.649167673662305e-05, Validation Loss: 8.423812493371466e-05\n",
      "Epoch [10/25], Train Loss: 7.467177783837542e-05, Validation Loss: 8.418795429558183e-05\n",
      "Epoch [10/25], Train Loss: 8.253500709543005e-05, Validation Loss: 8.414312154248667e-05\n",
      "Epoch [10/25], Train Loss: 8.882659312803298e-05, Validation Loss: 8.416933487751522e-05\n",
      "Epoch [10/25], Train Loss: 9.266603592550382e-05, Validation Loss: 8.415338864627604e-05\n",
      "Epoch [10/25], Train Loss: 9.549150126986206e-05, Validation Loss: 8.4067610684239e-05\n",
      "Epoch [10/25], Train Loss: 9.292460890719667e-05, Validation Loss: 8.399370223438988e-05\n",
      "Epoch [10/25], Train Loss: 8.469409658573568e-05, Validation Loss: 8.396264359665414e-05\n",
      "Epoch [10/25], Train Loss: 9.723733819555491e-05, Validation Loss: 8.395595844679822e-05\n",
      "Epoch [10/25], Train Loss: 9.376737580168992e-05, Validation Loss: 8.396490981491904e-05\n",
      "Epoch [10/25], Train Loss: 0.00010121166269527748, Validation Loss: 8.394117539864965e-05\n",
      "Epoch [10/25], Train Loss: 7.213912613224238e-05, Validation Loss: 8.390199097145039e-05\n",
      "Epoch [10/25], Train Loss: 9.592277638148516e-05, Validation Loss: 8.391966136211219e-05\n",
      "Epoch [10/25], Train Loss: 8.864953997544944e-05, Validation Loss: 8.394842346509298e-05\n",
      "Epoch [10/25], Train Loss: 9.099962335312739e-05, Validation Loss: 8.399572082756398e-05\n",
      "Epoch [10/25], Train Loss: 0.00010951262811431661, Validation Loss: 8.405376405183537e-05\n",
      "Epoch [10/25], Train Loss: 7.29745370335877e-05, Validation Loss: 8.412263656888778e-05\n",
      "Epoch [10/25], Train Loss: 8.579993300372735e-05, Validation Loss: 8.41949753521476e-05\n",
      "Epoch [10/25], Train Loss: 9.350592154078186e-05, Validation Loss: 8.430362771226404e-05\n",
      "Epoch [10/25], Train Loss: 6.900756125105545e-05, Validation Loss: 8.441965765086934e-05\n",
      "Epoch [10/25], Train Loss: 9.353076166007668e-05, Validation Loss: 8.456812356598676e-05\n",
      "Epoch [10/25], Train Loss: 9.884357132250443e-05, Validation Loss: 8.468743083843341e-05\n",
      "Epoch [10/25], Train Loss: 8.162520680343732e-05, Validation Loss: 8.485561241589797e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Train Loss: 8.331311983056366e-05, Validation Loss: 8.522448430691535e-05\n",
      "Epoch [10/25], Train Loss: 7.630226173205301e-05, Validation Loss: 8.547989345970563e-05\n",
      "Epoch [10/25], Train Loss: 0.00011137822002638131, Validation Loss: 8.603569513070397e-05\n",
      "Epoch [10/25], Train Loss: 8.925522706704214e-05, Validation Loss: 8.649996452732011e-05\n",
      "Epoch [10/25], Train Loss: 8.106447057798505e-05, Validation Loss: 8.71661245279635e-05\n",
      "Epoch [10/25], Train Loss: 0.00011286779044894502, Validation Loss: 8.774495921291722e-05\n",
      "Epoch [10/25], Train Loss: 6.71582092763856e-05, Validation Loss: 8.864276702903832e-05\n",
      "Epoch [10/25], Train Loss: 9.13693438633345e-05, Validation Loss: 8.932284254115075e-05\n",
      "Epoch [10/25], Train Loss: 8.879863889887929e-05, Validation Loss: 8.978485226786385e-05\n",
      "Epoch [10/25], Train Loss: 9.433558443561196e-05, Validation Loss: 9.031452743026117e-05\n",
      "Epoch [10/25], Train Loss: 7.830965478206053e-05, Validation Loss: 9.109026238244648e-05\n",
      "Epoch [10/25], Train Loss: 8.267335942946374e-05, Validation Loss: 9.198200956840689e-05\n",
      "Epoch [10/25], Train Loss: 8.787558181211352e-05, Validation Loss: 9.441997438746815e-05\n",
      "Epoch [10/25], Train Loss: 7.170136814238504e-05, Validation Loss: 9.824147661371777e-05\n",
      "Epoch [10/25], Train Loss: 9.753034828463569e-05, Validation Loss: 0.00010259835447262352\n",
      "Epoch [10/25], Train Loss: 8.521191193722188e-05, Validation Loss: 0.00010458757606102154\n",
      "Epoch [10/25], Train Loss: 9.625330130802467e-05, Validation Loss: 0.00010252761664257075\n",
      "Epoch [10/25], Train Loss: 9.97606766759418e-05, Validation Loss: 9.563610171123097e-05\n",
      "Epoch [10/25], Train Loss: 0.00011628030188148841, Validation Loss: 8.83701727919591e-05\n",
      "Epoch [10/25], Train Loss: 8.238814189098775e-05, Validation Loss: 8.543484800611622e-05\n",
      "Epoch [10/25], Train Loss: 7.634746725670993e-05, Validation Loss: 8.655995843582786e-05\n",
      "Epoch [10/25], Train Loss: 9.503978071734309e-05, Validation Loss: 8.81627255391019e-05\n",
      "Epoch [10/25], Train Loss: 7.829056266928092e-05, Validation Loss: 8.802783437810528e-05\n",
      "Epoch [10/25], Train Loss: 9.378878166899085e-05, Validation Loss: 8.6371695700412e-05\n",
      "Epoch [10/25], Train Loss: 8.968429028755054e-05, Validation Loss: 8.495836421692123e-05\n",
      "Epoch [10/25], Train Loss: 9.038664575200528e-05, Validation Loss: 8.432668279662418e-05\n",
      "Epoch [10/25], Train Loss: 0.00010461784404469654, Validation Loss: 8.387835090009807e-05\n",
      "Epoch [10/25], Train Loss: 0.0001062116352841258, Validation Loss: 8.381468505831435e-05\n",
      "Epoch [10/25], Train Loss: 8.249782695202157e-05, Validation Loss: 9.110115012542034e-05\n",
      "Epoch [10/25], Train Loss: 0.00011191763042006642, Validation Loss: 0.00011561720311874524\n",
      "Epoch [10/25], Train Loss: 0.00010623726848280057, Validation Loss: 0.0001272594221518375\n",
      "Epoch [10/25], Train Loss: 0.00012852910731453449, Validation Loss: 0.00010110835137311369\n",
      "Epoch [10/25], Train Loss: 0.00011670493404380977, Validation Loss: 8.288925722202597e-05\n",
      "Epoch [10/25], Train Loss: 8.182173769455403e-05, Validation Loss: 9.837518834198515e-05\n",
      "Epoch [10/25], Train Loss: 9.025463077705353e-05, Validation Loss: 0.00010677154350560158\n",
      "Epoch [10/25], Train Loss: 0.00011970446212217212, Validation Loss: 9.123962178515891e-05\n",
      "Epoch [10/25], Train Loss: 8.666575013194233e-05, Validation Loss: 8.271000042441301e-05\n",
      "Epoch [10/25], Train Loss: 9.052777022588998e-05, Validation Loss: 9.591675334377214e-05\n",
      "Epoch [11/25], Train Loss: 0.00011122022260678932, Validation Loss: 9.469944634474814e-05\n",
      "Epoch [11/25], Train Loss: 8.646704372949898e-05, Validation Loss: 8.197394466454473e-05\n",
      "Epoch [11/25], Train Loss: 7.620568067068234e-05, Validation Loss: 8.735134639816048e-05\n",
      "Epoch [11/25], Train Loss: 7.403697236441076e-05, Validation Loss: 9.229323380471518e-05\n",
      "Epoch [11/25], Train Loss: 8.312654244946316e-05, Validation Loss: 8.325248345499858e-05\n",
      "Epoch [11/25], Train Loss: 7.982274837559089e-05, Validation Loss: 8.3289389294805e-05\n",
      "Epoch [11/25], Train Loss: 7.582366379210725e-05, Validation Loss: 8.890129489979396e-05\n",
      "Epoch [11/25], Train Loss: 9.498876897851005e-05, Validation Loss: 8.397645772978043e-05\n",
      "Epoch [11/25], Train Loss: 8.375832112506032e-05, Validation Loss: 8.177872102047938e-05\n",
      "Epoch [11/25], Train Loss: 0.00010189628665102646, Validation Loss: 8.559465156091998e-05\n",
      "Epoch [11/25], Train Loss: 8.72376185725443e-05, Validation Loss: 8.418264405918308e-05\n",
      "Epoch [11/25], Train Loss: 7.307423948077485e-05, Validation Loss: 8.082978044209692e-05\n",
      "Epoch [11/25], Train Loss: 7.890722918091342e-05, Validation Loss: 8.377421884991539e-05\n",
      "Epoch [11/25], Train Loss: 9.595829760655761e-05, Validation Loss: 8.359286900182876e-05\n",
      "Epoch [11/25], Train Loss: 9.872713417280465e-05, Validation Loss: 8.064253294530015e-05\n",
      "Epoch [11/25], Train Loss: 8.269819954875857e-05, Validation Loss: 8.26396661674759e-05\n",
      "Epoch [11/25], Train Loss: 8.464163693133742e-05, Validation Loss: 8.289451652672142e-05\n",
      "Epoch [11/25], Train Loss: 7.275935786310583e-05, Validation Loss: 8.058952395610201e-05\n",
      "Epoch [11/25], Train Loss: 7.705499592702836e-05, Validation Loss: 8.155667455866933e-05\n",
      "Epoch [11/25], Train Loss: 9.444852184969932e-05, Validation Loss: 8.207154241972603e-05\n",
      "Epoch [11/25], Train Loss: 9.043926547747105e-05, Validation Loss: 8.030947671310666e-05\n",
      "Epoch [11/25], Train Loss: 6.907005445100367e-05, Validation Loss: 8.092431016848423e-05\n",
      "Epoch [11/25], Train Loss: 9.099744784180075e-05, Validation Loss: 8.141086121516612e-05\n",
      "Epoch [11/25], Train Loss: 8.867812721291557e-05, Validation Loss: 8.034813072299585e-05\n",
      "Epoch [11/25], Train Loss: 9.560811304254457e-05, Validation Loss: 8.025969291338697e-05\n",
      "Epoch [11/25], Train Loss: 9.104984201258048e-05, Validation Loss: 8.088463364401832e-05\n",
      "Epoch [11/25], Train Loss: 6.172790745040402e-05, Validation Loss: 8.040805575243818e-05\n",
      "Epoch [11/25], Train Loss: 6.601791392313316e-05, Validation Loss: 7.983385318463357e-05\n",
      "Epoch [11/25], Train Loss: 6.452418892877176e-05, Validation Loss: 8.040363706337908e-05\n",
      "Epoch [11/25], Train Loss: 8.714940486242995e-05, Validation Loss: 8.009476611429515e-05\n",
      "Epoch [11/25], Train Loss: 7.924798410385847e-05, Validation Loss: 7.95909162358536e-05\n",
      "Epoch [11/25], Train Loss: 8.039480599109083e-05, Validation Loss: 7.998496876098216e-05\n",
      "Epoch [11/25], Train Loss: 8.120523125398904e-05, Validation Loss: 7.988960351212882e-05\n",
      "Epoch [11/25], Train Loss: 7.817930600140244e-05, Validation Loss: 7.94121658448906e-05\n",
      "Epoch [11/25], Train Loss: 8.390777657041326e-05, Validation Loss: 7.951296380876253e-05\n",
      "Epoch [11/25], Train Loss: 8.88292197487317e-05, Validation Loss: 7.964101556960183e-05\n",
      "Epoch [11/25], Train Loss: 7.894801819929853e-05, Validation Loss: 7.928291524876841e-05\n",
      "Epoch [11/25], Train Loss: 5.8175926824333146e-05, Validation Loss: 7.921236562348591e-05\n",
      "Epoch [11/25], Train Loss: 9.36986762098968e-05, Validation Loss: 7.930721403681673e-05\n",
      "Epoch [11/25], Train Loss: 7.06335631548427e-05, Validation Loss: 7.91935766756069e-05\n",
      "Epoch [11/25], Train Loss: 7.924638339318335e-05, Validation Loss: 7.89756818752115e-05\n",
      "Epoch [11/25], Train Loss: 7.89133773650974e-05, Validation Loss: 7.902517851713735e-05\n",
      "Epoch [11/25], Train Loss: 7.321043813135475e-05, Validation Loss: 7.90491649240721e-05\n",
      "Epoch [11/25], Train Loss: 6.50699803372845e-05, Validation Loss: 7.883016878622584e-05\n",
      "Epoch [11/25], Train Loss: 7.539240323239937e-05, Validation Loss: 7.876082163420506e-05\n",
      "Epoch [11/25], Train Loss: 8.627858915133402e-05, Validation Loss: 7.884406416754548e-05\n",
      "Epoch [11/25], Train Loss: 8.319556945934892e-05, Validation Loss: 7.872502804578592e-05\n",
      "Epoch [11/25], Train Loss: 8.877069194568321e-05, Validation Loss: 7.856413673531884e-05\n",
      "Epoch [11/25], Train Loss: 9.914926340570673e-05, Validation Loss: 7.857775538771724e-05\n",
      "Epoch [11/25], Train Loss: 9.190081618726254e-05, Validation Loss: 7.853466013330035e-05\n",
      "Epoch [11/25], Train Loss: 7.800244929967448e-05, Validation Loss: 7.843403194177276e-05\n",
      "Epoch [11/25], Train Loss: 9.78593816398643e-05, Validation Loss: 7.831553302821704e-05\n",
      "Epoch [11/25], Train Loss: 7.881291821831837e-05, Validation Loss: 7.82788925183316e-05\n",
      "Epoch [11/25], Train Loss: 7.059355266392231e-05, Validation Loss: 7.825374244324242e-05\n",
      "Epoch [11/25], Train Loss: 8.781400538282469e-05, Validation Loss: 7.817072085648154e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Train Loss: 7.155015919124708e-05, Validation Loss: 7.811398851724032e-05\n",
      "Epoch [11/25], Train Loss: 7.232195639517158e-05, Validation Loss: 7.804261913406663e-05\n",
      "Epoch [11/25], Train Loss: 8.112326031550765e-05, Validation Loss: 7.797723834907326e-05\n",
      "Epoch [11/25], Train Loss: 9.075064735952765e-05, Validation Loss: 7.791785828885623e-05\n",
      "Epoch [11/25], Train Loss: 7.68026293371804e-05, Validation Loss: 7.78473722069369e-05\n",
      "Epoch [11/25], Train Loss: 6.164357910165563e-05, Validation Loss: 7.7783359301975e-05\n",
      "Epoch [11/25], Train Loss: 9.006342588691041e-05, Validation Loss: 7.772561487702963e-05\n",
      "Epoch [11/25], Train Loss: 7.574028131784871e-05, Validation Loss: 7.767768790169308e-05\n",
      "Epoch [11/25], Train Loss: 9.612864960217848e-05, Validation Loss: 7.767108957826471e-05\n",
      "Epoch [11/25], Train Loss: 8.930702460929751e-05, Validation Loss: 7.756867053103633e-05\n",
      "Epoch [11/25], Train Loss: 8.227860962506384e-05, Validation Loss: 7.751180819468573e-05\n",
      "Epoch [11/25], Train Loss: 9.160507033811882e-05, Validation Loss: 7.745246645451213e-05\n",
      "Epoch [11/25], Train Loss: 5.9014706494053826e-05, Validation Loss: 7.739779175608419e-05\n",
      "Epoch [11/25], Train Loss: 6.470266089309007e-05, Validation Loss: 7.740312551807922e-05\n",
      "Epoch [11/25], Train Loss: 7.243791333166882e-05, Validation Loss: 7.746939081698656e-05\n",
      "Epoch [11/25], Train Loss: 7.345982157858089e-05, Validation Loss: 7.757048006169498e-05\n",
      "Epoch [11/25], Train Loss: 6.753147317795083e-05, Validation Loss: 7.781767538593461e-05\n",
      "Epoch [11/25], Train Loss: 7.741204899502918e-05, Validation Loss: 7.817025689291768e-05\n",
      "Epoch [11/25], Train Loss: 6.841870344942436e-05, Validation Loss: 7.876757905857327e-05\n",
      "Epoch [11/25], Train Loss: 8.87623755261302e-05, Validation Loss: 7.927626647870056e-05\n",
      "Epoch [11/25], Train Loss: 8.792222797637805e-05, Validation Loss: 7.99888975355619e-05\n",
      "Epoch [11/25], Train Loss: 9.962131298379973e-05, Validation Loss: 8.045458622897664e-05\n",
      "Epoch [11/25], Train Loss: 7.755625119898468e-05, Validation Loss: 8.084399814833887e-05\n",
      "Epoch [11/25], Train Loss: 8.506231097271666e-05, Validation Loss: 8.071973303837391e-05\n",
      "Epoch [11/25], Train Loss: 9.805648733163252e-05, Validation Loss: 8.03280478673211e-05\n",
      "Epoch [11/25], Train Loss: 9.716492786537856e-05, Validation Loss: 7.887462585737618e-05\n",
      "Epoch [11/25], Train Loss: 8.134175004670396e-05, Validation Loss: 7.742442491386707e-05\n",
      "Epoch [11/25], Train Loss: 7.182638364611194e-05, Validation Loss: 7.664373891505724e-05\n",
      "Epoch [11/25], Train Loss: 6.851390935480595e-05, Validation Loss: 7.671742617579488e-05\n",
      "Epoch [11/25], Train Loss: 9.453432721784338e-05, Validation Loss: 7.76027254081176e-05\n",
      "Epoch [11/25], Train Loss: 8.551005157642066e-05, Validation Loss: 7.900066508833939e-05\n",
      "Epoch [11/25], Train Loss: 6.503072654595599e-05, Validation Loss: 7.97841394766389e-05\n",
      "Epoch [11/25], Train Loss: 6.915719859534875e-05, Validation Loss: 7.959275972098112e-05\n",
      "Epoch [11/25], Train Loss: 9.723305265652016e-05, Validation Loss: 7.879837430664338e-05\n",
      "Epoch [11/25], Train Loss: 7.3537856223993e-05, Validation Loss: 7.736326588201337e-05\n",
      "Epoch [11/25], Train Loss: 8.406247798120603e-05, Validation Loss: 7.641114740787694e-05\n",
      "Epoch [11/25], Train Loss: 9.172753198072314e-05, Validation Loss: 7.629529524516935e-05\n",
      "Epoch [11/25], Train Loss: 6.69397268211469e-05, Validation Loss: 7.694849361238691e-05\n",
      "Epoch [11/25], Train Loss: 7.95147570897825e-05, Validation Loss: 7.784399106943359e-05\n",
      "Epoch [11/25], Train Loss: 8.422495739068836e-05, Validation Loss: 7.806860885466449e-05\n",
      "Epoch [11/25], Train Loss: 7.33364577172324e-05, Validation Loss: 7.740294240647927e-05\n",
      "Epoch [11/25], Train Loss: 6.910039519425482e-05, Validation Loss: 7.648023529327475e-05\n",
      "Epoch [11/25], Train Loss: 7.55659639253281e-05, Validation Loss: 7.595906863571145e-05\n",
      "Epoch [11/25], Train Loss: 7.906226528575644e-05, Validation Loss: 7.592700834114415e-05\n",
      "Epoch [11/25], Train Loss: 8.85841145645827e-05, Validation Loss: 7.61558357529187e-05\n",
      "Epoch [11/25], Train Loss: 7.145933341234922e-05, Validation Loss: 7.63302513708671e-05\n",
      "Epoch [11/25], Train Loss: 7.743594323983416e-05, Validation Loss: 7.633296578812103e-05\n",
      "Epoch [11/25], Train Loss: 6.998051685513929e-05, Validation Loss: 7.606180831013869e-05\n",
      "Epoch [11/25], Train Loss: 7.615443610120565e-05, Validation Loss: 7.572476048759806e-05\n",
      "Epoch [11/25], Train Loss: 8.485756552545354e-05, Validation Loss: 7.560263911727816e-05\n",
      "Epoch [11/25], Train Loss: 6.797284731874242e-05, Validation Loss: 7.562232397807141e-05\n",
      "Epoch [11/25], Train Loss: 8.096341480268165e-05, Validation Loss: 7.565027432671438e-05\n",
      "Epoch [11/25], Train Loss: 8.193494431907311e-05, Validation Loss: 7.562261210599293e-05\n",
      "Epoch [11/25], Train Loss: 7.936144538689405e-05, Validation Loss: 7.552784203047243e-05\n",
      "Epoch [11/25], Train Loss: 6.716758070979267e-05, Validation Loss: 7.542908788309433e-05\n",
      "Epoch [11/25], Train Loss: 6.765076977899298e-05, Validation Loss: 7.536363627878018e-05\n",
      "Epoch [11/25], Train Loss: 7.936247857287526e-05, Validation Loss: 7.539117044264761e-05\n",
      "Epoch [11/25], Train Loss: 7.118606299627572e-05, Validation Loss: 7.54121860760885e-05\n",
      "Epoch [11/25], Train Loss: 8.145208994392306e-05, Validation Loss: 7.562619042194759e-05\n",
      "Epoch [11/25], Train Loss: 9.465693437959999e-05, Validation Loss: 7.63444673793856e-05\n",
      "Epoch [11/25], Train Loss: 7.598648517159745e-05, Validation Loss: 7.782146300693664e-05\n",
      "Epoch [11/25], Train Loss: 8.028803131310269e-05, Validation Loss: 8.114569257789602e-05\n",
      "Epoch [11/25], Train Loss: 8.348903065780178e-05, Validation Loss: 8.798193448456004e-05\n",
      "Epoch [11/25], Train Loss: 0.00010682730498956516, Validation Loss: 9.884752265255277e-05\n",
      "Epoch [11/25], Train Loss: 9.3769260274712e-05, Validation Loss: 0.00010660398208225766\n",
      "Epoch [11/25], Train Loss: 0.00010522217053221539, Validation Loss: 9.470105190606167e-05\n",
      "Epoch [11/25], Train Loss: 0.0001105777409975417, Validation Loss: 7.762111902896626e-05\n",
      "Epoch [11/25], Train Loss: 7.490238203899935e-05, Validation Loss: 8.18161953551074e-05\n",
      "Epoch [11/25], Train Loss: 0.00010301570000592619, Validation Loss: 9.166561988725638e-05\n",
      "Epoch [11/25], Train Loss: 0.00010396302241133526, Validation Loss: 8.246638099080883e-05\n",
      "Epoch [11/25], Train Loss: 5.985032839816995e-05, Validation Loss: 7.583216405085599e-05\n",
      "Epoch [11/25], Train Loss: 6.673708412563428e-05, Validation Loss: 8.567848174910372e-05\n",
      "Epoch [11/25], Train Loss: 0.00010959280916722491, Validation Loss: 8.441552490694449e-05\n",
      "Epoch [11/25], Train Loss: 7.754931721137837e-05, Validation Loss: 7.558469029997164e-05\n",
      "Epoch [11/25], Train Loss: 7.955758337629959e-05, Validation Loss: 8.09012516886772e-05\n",
      "Epoch [11/25], Train Loss: 8.444359991699457e-05, Validation Loss: 8.122137563380724e-05\n",
      "Epoch [11/25], Train Loss: 8.740279008634388e-05, Validation Loss: 7.513234061965099e-05\n",
      "Epoch [11/25], Train Loss: 7.390575774479657e-05, Validation Loss: 7.967844770367568e-05\n",
      "Epoch [11/25], Train Loss: 6.558740278705955e-05, Validation Loss: 7.984690382727422e-05\n",
      "Epoch [12/25], Train Loss: 8.304800576297566e-05, Validation Loss: 7.513297653834645e-05\n",
      "Epoch [12/25], Train Loss: 6.490425585070625e-05, Validation Loss: 7.84260431828443e-05\n",
      "Epoch [12/25], Train Loss: 8.218808943638578e-05, Validation Loss: 7.741336958133616e-05\n",
      "Epoch [12/25], Train Loss: 7.299421849893406e-05, Validation Loss: 7.498918979157073e-05\n",
      "Epoch [12/25], Train Loss: 7.51294574001804e-05, Validation Loss: 7.785015065261783e-05\n",
      "Epoch [12/25], Train Loss: 7.969745638547465e-05, Validation Loss: 7.634523814582886e-05\n",
      "Epoch [12/25], Train Loss: 6.456988921854645e-05, Validation Loss: 7.521258279060324e-05\n",
      "Epoch [12/25], Train Loss: 9.0109693701379e-05, Validation Loss: 7.72556202718988e-05\n",
      "Epoch [12/25], Train Loss: 7.706656469963491e-05, Validation Loss: 7.529704841241861e-05\n",
      "Epoch [12/25], Train Loss: 8.475866343360394e-05, Validation Loss: 7.527721318183467e-05\n",
      "Epoch [12/25], Train Loss: 7.783148612361401e-05, Validation Loss: 7.656328598386608e-05\n",
      "Epoch [12/25], Train Loss: 8.186210470739752e-05, Validation Loss: 7.494287201552652e-05\n",
      "Epoch [12/25], Train Loss: 7.91917773312889e-05, Validation Loss: 7.540643297640296e-05\n",
      "Epoch [12/25], Train Loss: 8.569268538849428e-05, Validation Loss: 7.572157240550344e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Train Loss: 7.465449016308412e-05, Validation Loss: 7.459175709906655e-05\n",
      "Epoch [12/25], Train Loss: 7.643359276698902e-05, Validation Loss: 7.53808022030474e-05\n",
      "Epoch [12/25], Train Loss: 7.512399315601215e-05, Validation Loss: 7.538248537457548e-05\n",
      "Epoch [12/25], Train Loss: 6.089073576731607e-05, Validation Loss: 7.454159858752974e-05\n",
      "Epoch [12/25], Train Loss: 6.163912621559575e-05, Validation Loss: 7.499303901568056e-05\n",
      "Epoch [12/25], Train Loss: 9.481202141614631e-05, Validation Loss: 7.492727648544436e-05\n",
      "Epoch [12/25], Train Loss: 6.840370770078152e-05, Validation Loss: 7.437660242430866e-05\n",
      "Epoch [12/25], Train Loss: 6.419786950573325e-05, Validation Loss: 7.483344064288152e-05\n",
      "Epoch [12/25], Train Loss: 8.804220124147832e-05, Validation Loss: 7.49541841893612e-05\n",
      "Epoch [12/25], Train Loss: 9.472384408582002e-05, Validation Loss: 7.429585991000446e-05\n",
      "Epoch [12/25], Train Loss: 8.898457599570975e-05, Validation Loss: 7.466050155926495e-05\n",
      "Epoch [12/25], Train Loss: 8.546491153538227e-05, Validation Loss: 7.462455663092745e-05\n",
      "Epoch [12/25], Train Loss: 9.25854837987572e-05, Validation Loss: 7.416972512146458e-05\n",
      "Epoch [12/25], Train Loss: 8.146624895744026e-05, Validation Loss: 7.443513216761251e-05\n",
      "Epoch [12/25], Train Loss: 7.302965968847275e-05, Validation Loss: 7.434468667876596e-05\n",
      "Epoch [12/25], Train Loss: 7.051068678265437e-05, Validation Loss: 7.405846190522425e-05\n",
      "Epoch [12/25], Train Loss: 7.303252641577274e-05, Validation Loss: 7.426259908243083e-05\n",
      "Epoch [12/25], Train Loss: 6.410988862626255e-05, Validation Loss: 7.419261867956569e-05\n",
      "Epoch [12/25], Train Loss: 8.511194755556062e-05, Validation Loss: 7.392982976549926e-05\n",
      "Epoch [12/25], Train Loss: 6.622588989557698e-05, Validation Loss: 7.403219351544976e-05\n",
      "Epoch [12/25], Train Loss: 7.999529771041125e-05, Validation Loss: 7.40807234251406e-05\n",
      "Epoch [12/25], Train Loss: 6.566562660736963e-05, Validation Loss: 7.383444681181572e-05\n",
      "Epoch [12/25], Train Loss: 6.98562289471738e-05, Validation Loss: 7.385944118141197e-05\n",
      "Epoch [12/25], Train Loss: 7.03887126292102e-05, Validation Loss: 7.392002056197574e-05\n",
      "Epoch [12/25], Train Loss: 5.7759127230383456e-05, Validation Loss: 7.375567705215265e-05\n",
      "Epoch [12/25], Train Loss: 7.127090793801472e-05, Validation Loss: 7.370937237283215e-05\n",
      "Epoch [12/25], Train Loss: 8.714537398191169e-05, Validation Loss: 7.380122139390247e-05\n",
      "Epoch [12/25], Train Loss: 7.183443085523322e-05, Validation Loss: 7.370396657885673e-05\n",
      "Epoch [12/25], Train Loss: 7.305253529921174e-05, Validation Loss: 7.355613294445599e-05\n",
      "Epoch [12/25], Train Loss: 7.408976671285927e-05, Validation Loss: 7.364188398544987e-05\n",
      "Epoch [12/25], Train Loss: 8.532949141226709e-05, Validation Loss: 7.360924573731608e-05\n",
      "Epoch [12/25], Train Loss: 6.602057692361996e-05, Validation Loss: 7.346564913556601e-05\n",
      "Epoch [12/25], Train Loss: 8.44651585794054e-05, Validation Loss: 7.343675946079505e-05\n",
      "Epoch [12/25], Train Loss: 8.480765973217785e-05, Validation Loss: 7.345280367493009e-05\n",
      "Epoch [12/25], Train Loss: 6.343997665680945e-05, Validation Loss: 7.334266944477955e-05\n",
      "Epoch [12/25], Train Loss: 6.358664541039616e-05, Validation Loss: 7.331582043358745e-05\n",
      "Epoch [12/25], Train Loss: 7.425618241541088e-05, Validation Loss: 7.336098885086055e-05\n",
      "Epoch [12/25], Train Loss: 6.500334711745381e-05, Validation Loss: 7.328481369768269e-05\n",
      "Epoch [12/25], Train Loss: 7.665198791073635e-05, Validation Loss: 7.318435794635055e-05\n",
      "Epoch [12/25], Train Loss: 8.076643280219287e-05, Validation Loss: 7.314497876601915e-05\n",
      "Epoch [12/25], Train Loss: 7.927536353236064e-05, Validation Loss: 7.319300396678349e-05\n",
      "Epoch [12/25], Train Loss: 6.93486726959236e-05, Validation Loss: 7.313172682188451e-05\n",
      "Epoch [12/25], Train Loss: 7.093475869623944e-05, Validation Loss: 7.303472302737646e-05\n",
      "Epoch [12/25], Train Loss: 7.290070061571896e-05, Validation Loss: 7.300142193950402e-05\n",
      "Epoch [12/25], Train Loss: 7.314184767892584e-05, Validation Loss: 7.305539062751147e-05\n",
      "Epoch [12/25], Train Loss: 6.817916437285021e-05, Validation Loss: 7.305506393701459e-05\n",
      "Epoch [12/25], Train Loss: 6.519991438835859e-05, Validation Loss: 7.297788348902638e-05\n",
      "Epoch [12/25], Train Loss: 8.331695426022634e-05, Validation Loss: 7.294202441698872e-05\n",
      "Epoch [12/25], Train Loss: 9.536346624372527e-05, Validation Loss: 7.290071589522995e-05\n",
      "Epoch [12/25], Train Loss: 6.337236845865846e-05, Validation Loss: 7.291473787821209e-05\n",
      "Epoch [12/25], Train Loss: 5.5034226534189656e-05, Validation Loss: 7.287979824468493e-05\n",
      "Epoch [12/25], Train Loss: 7.770312367938459e-05, Validation Loss: 7.282243192700359e-05\n",
      "Epoch [12/25], Train Loss: 7.1566944825463e-05, Validation Loss: 7.288171836989931e-05\n",
      "Epoch [12/25], Train Loss: 6.890352960908785e-05, Validation Loss: 7.303395662650776e-05\n",
      "Epoch [12/25], Train Loss: 6.384109292412177e-05, Validation Loss: 7.317430524077888e-05\n",
      "Epoch [12/25], Train Loss: 7.010775152593851e-05, Validation Loss: 7.320041792506042e-05\n",
      "Epoch [12/25], Train Loss: 7.737427222309634e-05, Validation Loss: 7.320584942741941e-05\n",
      "Epoch [12/25], Train Loss: 7.445742085110396e-05, Validation Loss: 7.330638569934915e-05\n",
      "Epoch [12/25], Train Loss: 7.381926116067916e-05, Validation Loss: 7.349124740964422e-05\n",
      "Epoch [12/25], Train Loss: 6.64303224766627e-05, Validation Loss: 7.372707914328202e-05\n",
      "Epoch [12/25], Train Loss: 6.751556793460622e-05, Validation Loss: 7.401329470061077e-05\n",
      "Epoch [12/25], Train Loss: 7.146431016735733e-05, Validation Loss: 7.433538145657318e-05\n",
      "Epoch [12/25], Train Loss: 9.653628512751311e-05, Validation Loss: 7.488434081703114e-05\n",
      "Epoch [12/25], Train Loss: 8.371339208679274e-05, Validation Loss: 7.584222015187455e-05\n",
      "Epoch [12/25], Train Loss: 7.823390478733927e-05, Validation Loss: 7.748403149889782e-05\n",
      "Epoch [12/25], Train Loss: 6.480934825958684e-05, Validation Loss: 7.946710344792033e-05\n",
      "Epoch [12/25], Train Loss: 6.673741881968454e-05, Validation Loss: 8.261160716453257e-05\n",
      "Epoch [12/25], Train Loss: 8.579310087952763e-05, Validation Loss: 8.553100536422183e-05\n",
      "Epoch [12/25], Train Loss: 8.37423067423515e-05, Validation Loss: 8.8135415474729e-05\n",
      "Epoch [12/25], Train Loss: 8.341452485183254e-05, Validation Loss: 8.874019355668376e-05\n",
      "Epoch [12/25], Train Loss: 8.362560038222e-05, Validation Loss: 8.620419393992051e-05\n",
      "Epoch [12/25], Train Loss: 9.620992932468653e-05, Validation Loss: 8.095745821871485e-05\n",
      "Epoch [12/25], Train Loss: 0.0001072189406841062, Validation Loss: 7.53069827624131e-05\n",
      "Epoch [12/25], Train Loss: 7.659026596229523e-05, Validation Loss: 7.258919188946796e-05\n",
      "Epoch [12/25], Train Loss: 9.01670937309973e-05, Validation Loss: 7.369132969567241e-05\n",
      "Epoch [12/25], Train Loss: 7.685278251301497e-05, Validation Loss: 7.682446642623594e-05\n",
      "Epoch [12/25], Train Loss: 6.829163612565026e-05, Validation Loss: 7.841274370245325e-05\n",
      "Epoch [12/25], Train Loss: 7.629430911038071e-05, Validation Loss: 7.720052623578037e-05\n",
      "Epoch [12/25], Train Loss: 5.685025462298654e-05, Validation Loss: 7.428849955128195e-05\n",
      "Epoch [12/25], Train Loss: 6.683106767013669e-05, Validation Loss: 7.257210575820258e-05\n",
      "Epoch [12/25], Train Loss: 9.893094829749316e-05, Validation Loss: 7.258355035446584e-05\n",
      "Epoch [12/25], Train Loss: 7.088397251209244e-05, Validation Loss: 7.354632034548559e-05\n",
      "Epoch [12/25], Train Loss: 8.604725735494867e-05, Validation Loss: 7.396298824460245e-05\n",
      "Epoch [12/25], Train Loss: 7.92888313299045e-05, Validation Loss: 7.344133506800668e-05\n",
      "Epoch [12/25], Train Loss: 8.120774145936593e-05, Validation Loss: 7.245787516391526e-05\n",
      "Epoch [12/25], Train Loss: 6.902222958160564e-05, Validation Loss: 7.198964231065474e-05\n",
      "Epoch [12/25], Train Loss: 6.999407196417451e-05, Validation Loss: 7.233660265531701e-05\n",
      "Epoch [12/25], Train Loss: 8.340935892192647e-05, Validation Loss: 7.288004271686078e-05\n",
      "Epoch [12/25], Train Loss: 8.229698141803965e-05, Validation Loss: 7.291772538640847e-05\n",
      "Epoch [12/25], Train Loss: 6.593825673917308e-05, Validation Loss: 7.250938312305758e-05\n",
      "Epoch [12/25], Train Loss: 5.347904152586125e-05, Validation Loss: 7.188905607714938e-05\n",
      "Epoch [12/25], Train Loss: 8.015765342861414e-05, Validation Loss: 7.156455879642938e-05\n",
      "Epoch [12/25], Train Loss: 6.581402703886852e-05, Validation Loss: 7.178439263952897e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Train Loss: 7.514847675338387e-05, Validation Loss: 7.223018959242229e-05\n",
      "Epoch [12/25], Train Loss: 5.5755685025360435e-05, Validation Loss: 7.257193719851784e-05\n",
      "Epoch [12/25], Train Loss: 8.366840484086424e-05, Validation Loss: 7.276198351367688e-05\n",
      "Epoch [12/25], Train Loss: 5.563627928495407e-05, Validation Loss: 7.301235333822357e-05\n",
      "Epoch [12/25], Train Loss: 6.527928780997172e-05, Validation Loss: 7.337457354879006e-05\n",
      "Epoch [12/25], Train Loss: 6.26283508609049e-05, Validation Loss: 7.391097969957627e-05\n",
      "Epoch [12/25], Train Loss: 0.00011078730312874541, Validation Loss: 7.441093912348151e-05\n",
      "Epoch [12/25], Train Loss: 8.89153016032651e-05, Validation Loss: 7.440087235105845e-05\n",
      "Epoch [12/25], Train Loss: 7.252518116729334e-05, Validation Loss: 7.371057945420035e-05\n",
      "Epoch [12/25], Train Loss: 6.443273014156148e-05, Validation Loss: 7.298983303674808e-05\n",
      "Epoch [12/25], Train Loss: 8.55772741488181e-05, Validation Loss: 7.240308793067621e-05\n",
      "Epoch [12/25], Train Loss: 6.92835237714462e-05, Validation Loss: 7.194146601250396e-05\n",
      "Epoch [12/25], Train Loss: 6.877809209981933e-05, Validation Loss: 7.163665795815178e-05\n",
      "Epoch [12/25], Train Loss: 8.415801130468026e-05, Validation Loss: 7.129024088499136e-05\n",
      "Epoch [12/25], Train Loss: 9.694735490484163e-05, Validation Loss: 7.112214661901817e-05\n",
      "Epoch [12/25], Train Loss: 8.113784861052409e-05, Validation Loss: 7.102746628030824e-05\n",
      "Epoch [12/25], Train Loss: 8.50083160912618e-05, Validation Loss: 7.098578062141314e-05\n",
      "Epoch [12/25], Train Loss: 6.800798291806132e-05, Validation Loss: 7.104765221204919e-05\n",
      "Epoch [12/25], Train Loss: 6.693811883451417e-05, Validation Loss: 7.117886513393993e-05\n",
      "Epoch [12/25], Train Loss: 7.467056275345385e-05, Validation Loss: 7.143618907624235e-05\n",
      "Epoch [12/25], Train Loss: 7.61933479225263e-05, Validation Loss: 7.16248958876046e-05\n",
      "Epoch [12/25], Train Loss: 7.545128755737096e-05, Validation Loss: 7.188420931925066e-05\n",
      "Epoch [12/25], Train Loss: 7.759167056065053e-05, Validation Loss: 7.20995233374803e-05\n",
      "Epoch [12/25], Train Loss: 7.071115396684036e-05, Validation Loss: 7.249909734431033e-05\n",
      "Epoch [12/25], Train Loss: 8.239450835390016e-05, Validation Loss: 7.29540639440529e-05\n",
      "Epoch [12/25], Train Loss: 7.061053474899381e-05, Validation Loss: 7.37289611909849e-05\n",
      "Epoch [12/25], Train Loss: 9.764976130099967e-05, Validation Loss: 7.468051650600197e-05\n",
      "Epoch [13/25], Train Loss: 7.32369371689856e-05, Validation Loss: 7.602666834524522e-05\n",
      "Epoch [13/25], Train Loss: 6.431509245885536e-05, Validation Loss: 7.825174422274965e-05\n",
      "Epoch [13/25], Train Loss: 6.224799290066585e-05, Validation Loss: 8.043271057734576e-05\n",
      "Epoch [13/25], Train Loss: 7.613452908117324e-05, Validation Loss: 8.246398453290263e-05\n",
      "Epoch [13/25], Train Loss: 8.934373909141868e-05, Validation Loss: 8.324748996528797e-05\n",
      "Epoch [13/25], Train Loss: 9.212220902554691e-05, Validation Loss: 8.151542715495452e-05\n",
      "Epoch [13/25], Train Loss: 8.873607293935493e-05, Validation Loss: 7.684687467796417e-05\n",
      "Epoch [13/25], Train Loss: 7.707907207077369e-05, Validation Loss: 7.251629504025913e-05\n",
      "Epoch [13/25], Train Loss: 7.397353328997269e-05, Validation Loss: 7.055622142312737e-05\n",
      "Epoch [13/25], Train Loss: 7.936960173537955e-05, Validation Loss: 7.19028728781268e-05\n",
      "Epoch [13/25], Train Loss: 7.446423842338845e-05, Validation Loss: 7.44913416080332e-05\n",
      "Epoch [13/25], Train Loss: 9.796347876545042e-05, Validation Loss: 7.557009181861456e-05\n",
      "Epoch [13/25], Train Loss: 8.033205813262612e-05, Validation Loss: 7.376798215166977e-05\n",
      "Epoch [13/25], Train Loss: 0.00010022681090049446, Validation Loss: 7.152703158984272e-05\n",
      "Epoch [13/25], Train Loss: 5.7192231906810775e-05, Validation Loss: 7.083498009402926e-05\n",
      "Epoch [13/25], Train Loss: 7.407195516861975e-05, Validation Loss: 7.185078308490726e-05\n",
      "Epoch [13/25], Train Loss: 5.235012577031739e-05, Validation Loss: 7.287717186651813e-05\n",
      "Epoch [13/25], Train Loss: 7.941856165416539e-05, Validation Loss: 7.236391223462609e-05\n",
      "Epoch [13/25], Train Loss: 8.896759391063824e-05, Validation Loss: 7.10728629201185e-05\n",
      "Epoch [13/25], Train Loss: 5.4077088861959055e-05, Validation Loss: 7.029978393499428e-05\n",
      "Epoch [13/25], Train Loss: 5.5589178373338655e-05, Validation Loss: 7.060202769935132e-05\n",
      "Epoch [13/25], Train Loss: 6.978649616939947e-05, Validation Loss: 7.133985515489864e-05\n",
      "Epoch [13/25], Train Loss: 7.68775717006065e-05, Validation Loss: 7.143253460526467e-05\n",
      "Epoch [13/25], Train Loss: 6.98855728842318e-05, Validation Loss: 7.079335870609308e-05\n",
      "Epoch [13/25], Train Loss: 7.913766603451222e-05, Validation Loss: 7.008958394483973e-05\n",
      "Epoch [13/25], Train Loss: 8.613484533270821e-05, Validation Loss: 7.009164546616376e-05\n",
      "Epoch [13/25], Train Loss: 8.326298848260194e-05, Validation Loss: 7.058394306416934e-05\n",
      "Epoch [13/25], Train Loss: 6.315082282526419e-05, Validation Loss: 7.077652214017386e-05\n",
      "Epoch [13/25], Train Loss: 7.679792906856164e-05, Validation Loss: 7.038809756825989e-05\n",
      "Epoch [13/25], Train Loss: 8.29250129754655e-05, Validation Loss: 6.993288188823499e-05\n",
      "Epoch [13/25], Train Loss: 7.02550751157105e-05, Validation Loss: 6.984340652707032e-05\n",
      "Epoch [13/25], Train Loss: 7.262956205522642e-05, Validation Loss: 7.010406334302388e-05\n",
      "Epoch [13/25], Train Loss: 7.67025412642397e-05, Validation Loss: 7.021750958908039e-05\n",
      "Epoch [13/25], Train Loss: 7.70950282458216e-05, Validation Loss: 7.012228306848555e-05\n",
      "Epoch [13/25], Train Loss: 6.642762309638783e-05, Validation Loss: 6.988299768030022e-05\n",
      "Epoch [13/25], Train Loss: 7.900470518507063e-05, Validation Loss: 6.97265968483407e-05\n",
      "Epoch [13/25], Train Loss: 7.212753553176299e-05, Validation Loss: 6.9696193774386e-05\n",
      "Epoch [13/25], Train Loss: 7.037329487502575e-05, Validation Loss: 6.970160320634023e-05\n",
      "Epoch [13/25], Train Loss: 8.159982826327905e-05, Validation Loss: 6.974975597889473e-05\n",
      "Epoch [13/25], Train Loss: 6.677440978819504e-05, Validation Loss: 6.975904592157653e-05\n",
      "Epoch [13/25], Train Loss: 5.091492130304687e-05, Validation Loss: 6.963389290225072e-05\n",
      "Epoch [13/25], Train Loss: 7.805743371136487e-05, Validation Loss: 6.951613613637164e-05\n",
      "Epoch [13/25], Train Loss: 7.34534187358804e-05, Validation Loss: 6.948641675990075e-05\n",
      "Epoch [13/25], Train Loss: 5.8042871387442574e-05, Validation Loss: 6.953748112816053e-05\n",
      "Epoch [13/25], Train Loss: 7.253919466165826e-05, Validation Loss: 6.958156009204686e-05\n",
      "Epoch [13/25], Train Loss: 6.410455534933135e-05, Validation Loss: 6.963364745994719e-05\n",
      "Epoch [13/25], Train Loss: 6.476984708569944e-05, Validation Loss: 6.971951176334793e-05\n",
      "Epoch [13/25], Train Loss: 7.99615663709119e-05, Validation Loss: 6.980548641877249e-05\n",
      "Epoch [13/25], Train Loss: 6.968989328015596e-05, Validation Loss: 6.98456261792065e-05\n",
      "Epoch [13/25], Train Loss: 8.280648034997284e-05, Validation Loss: 6.994795767241157e-05\n",
      "Epoch [13/25], Train Loss: 8.205878839362413e-05, Validation Loss: 7.016241555296195e-05\n",
      "Epoch [13/25], Train Loss: 9.224042878486216e-05, Validation Loss: 7.035281256927798e-05\n",
      "Epoch [13/25], Train Loss: 9.012926602736115e-05, Validation Loss: 7.0711130683776e-05\n",
      "Epoch [13/25], Train Loss: 7.560780068160966e-05, Validation Loss: 7.143963302951306e-05\n",
      "Epoch [13/25], Train Loss: 8.810457802610472e-05, Validation Loss: 7.282652659341693e-05\n",
      "Epoch [13/25], Train Loss: 6.292259058682248e-05, Validation Loss: 7.541015365859493e-05\n",
      "Epoch [13/25], Train Loss: 8.648740913486108e-05, Validation Loss: 7.932689089405661e-05\n",
      "Epoch [13/25], Train Loss: 6.902460154378787e-05, Validation Loss: 8.534273511031642e-05\n",
      "Epoch [13/25], Train Loss: 8.29471173346974e-05, Validation Loss: 9.278517342560614e-05\n",
      "Epoch [13/25], Train Loss: 0.00010036981257144362, Validation Loss: 0.00010010967137835299\n",
      "Epoch [13/25], Train Loss: 9.950348612619564e-05, Validation Loss: 0.00010105566664909323\n",
      "Epoch [13/25], Train Loss: 0.00010719587589846924, Validation Loss: 9.41008620429784e-05\n",
      "Epoch [13/25], Train Loss: 8.114972297335044e-05, Validation Loss: 8.085191657301039e-05\n",
      "Epoch [13/25], Train Loss: 7.386248762486503e-05, Validation Loss: 7.258651700491707e-05\n",
      "Epoch [13/25], Train Loss: 7.350771920755506e-05, Validation Loss: 7.449984429210114e-05\n",
      "Epoch [13/25], Train Loss: 7.800070306984708e-05, Validation Loss: 8.036527530445407e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Train Loss: 8.707852975931019e-05, Validation Loss: 8.009780576685443e-05\n",
      "Epoch [13/25], Train Loss: 8.155415707733482e-05, Validation Loss: 7.438263492076658e-05\n",
      "Epoch [13/25], Train Loss: 8.102634456008673e-05, Validation Loss: 7.18991672329139e-05\n",
      "Epoch [13/25], Train Loss: 6.66653795633465e-05, Validation Loss: 7.482278742827475e-05\n",
      "Epoch [13/25], Train Loss: 8.068409078987315e-05, Validation Loss: 7.599649761687033e-05\n",
      "Epoch [13/25], Train Loss: 7.221972191473469e-05, Validation Loss: 7.212372656795196e-05\n",
      "Epoch [13/25], Train Loss: 7.031694985926151e-05, Validation Loss: 6.909614967298694e-05\n",
      "Epoch [13/25], Train Loss: 5.312253051670268e-05, Validation Loss: 7.140674812641615e-05\n",
      "Epoch [13/25], Train Loss: 7.35777139198035e-05, Validation Loss: 7.409675575521154e-05\n",
      "Epoch [13/25], Train Loss: 5.925727964495309e-05, Validation Loss: 7.169099771999753e-05\n",
      "Epoch [13/25], Train Loss: 8.51358927320689e-05, Validation Loss: 6.878524024311143e-05\n",
      "Epoch [13/25], Train Loss: 5.8990528486901894e-05, Validation Loss: 7.025719411709966e-05\n",
      "Epoch [13/25], Train Loss: 7.392500265268609e-05, Validation Loss: 7.199466490419582e-05\n",
      "Epoch [13/25], Train Loss: 6.583550566574559e-05, Validation Loss: 7.069661078276112e-05\n",
      "Epoch [13/25], Train Loss: 6.788816972402856e-05, Validation Loss: 6.935800411156379e-05\n",
      "Epoch [13/25], Train Loss: 6.05579225521069e-05, Validation Loss: 7.031921656259025e-05\n",
      "Epoch [13/25], Train Loss: 7.093056774465367e-05, Validation Loss: 7.056242587471691e-05\n",
      "Epoch [13/25], Train Loss: 6.366800516843796e-05, Validation Loss: 6.905375169784141e-05\n",
      "Epoch [13/25], Train Loss: 7.28260274627246e-05, Validation Loss: 6.879272211032609e-05\n",
      "Epoch [13/25], Train Loss: 6.370827759383246e-05, Validation Loss: 6.994329548130433e-05\n",
      "Epoch [13/25], Train Loss: 7.011997513473034e-05, Validation Loss: 6.981073238421232e-05\n",
      "Epoch [13/25], Train Loss: 7.091232691891491e-05, Validation Loss: 6.868623822811059e-05\n",
      "Epoch [13/25], Train Loss: 8.785323734628037e-05, Validation Loss: 6.852534255206896e-05\n",
      "Epoch [13/25], Train Loss: 7.134290353860706e-05, Validation Loss: 6.902291133883409e-05\n",
      "Epoch [13/25], Train Loss: 8.226413046941161e-05, Validation Loss: 6.888584127106394e-05\n",
      "Epoch [13/25], Train Loss: 6.726334686391056e-05, Validation Loss: 6.850303980172612e-05\n",
      "Epoch [13/25], Train Loss: 6.124303763499483e-05, Validation Loss: 6.862446947100883e-05\n",
      "Epoch [13/25], Train Loss: 5.817400960950181e-05, Validation Loss: 6.878714678653826e-05\n",
      "Epoch [13/25], Train Loss: 6.930054223630577e-05, Validation Loss: 6.846626711194403e-05\n",
      "Epoch [13/25], Train Loss: 6.59039433230646e-05, Validation Loss: 6.81489259780695e-05\n",
      "Epoch [13/25], Train Loss: 6.67062631691806e-05, Validation Loss: 6.83162892528344e-05\n",
      "Epoch [13/25], Train Loss: 5.436693754745647e-05, Validation Loss: 6.847449088430343e-05\n",
      "Epoch [13/25], Train Loss: 6.71873931423761e-05, Validation Loss: 6.82904862818153e-05\n",
      "Epoch [13/25], Train Loss: 7.830629328964278e-05, Validation Loss: 6.804765628961225e-05\n",
      "Epoch [13/25], Train Loss: 7.676499808439985e-05, Validation Loss: 6.803596140040706e-05\n",
      "Epoch [13/25], Train Loss: 7.743891183054075e-05, Validation Loss: 6.812405990785919e-05\n",
      "Epoch [13/25], Train Loss: 7.344086043303832e-05, Validation Loss: 6.807722190084556e-05\n",
      "Epoch [13/25], Train Loss: 5.4512551287189126e-05, Validation Loss: 6.792999386865025e-05\n",
      "Epoch [13/25], Train Loss: 8.029858872760087e-05, Validation Loss: 6.785056903026998e-05\n",
      "Epoch [13/25], Train Loss: 8.433253242401406e-05, Validation Loss: 6.787108820086966e-05\n",
      "Epoch [13/25], Train Loss: 6.808299804106355e-05, Validation Loss: 6.786029359015325e-05\n",
      "Epoch [13/25], Train Loss: 7.056316098896787e-05, Validation Loss: 6.778524524027792e-05\n",
      "Epoch [13/25], Train Loss: 5.936637535342015e-05, Validation Loss: 6.772969500161708e-05\n",
      "Epoch [13/25], Train Loss: 5.7343215303262696e-05, Validation Loss: 6.769646618825694e-05\n",
      "Epoch [13/25], Train Loss: 6.878922431496903e-05, Validation Loss: 6.771710638228493e-05\n",
      "Epoch [13/25], Train Loss: 7.626760634593666e-05, Validation Loss: 6.771595023262005e-05\n",
      "Epoch [13/25], Train Loss: 6.540944741573185e-05, Validation Loss: 6.771687452176897e-05\n",
      "Epoch [13/25], Train Loss: 5.711564881494269e-05, Validation Loss: 6.774769087011615e-05\n",
      "Epoch [13/25], Train Loss: 5.3703657613368705e-05, Validation Loss: 6.770965628675186e-05\n",
      "Epoch [13/25], Train Loss: 8.2641483459156e-05, Validation Loss: 6.78405032279746e-05\n",
      "Epoch [13/25], Train Loss: 6.830588245065883e-05, Validation Loss: 6.791131915330576e-05\n",
      "Epoch [13/25], Train Loss: 7.138663931982592e-05, Validation Loss: 6.799776238040068e-05\n",
      "Epoch [13/25], Train Loss: 7.901097706053406e-05, Validation Loss: 6.815060260123573e-05\n",
      "Epoch [13/25], Train Loss: 7.871786510804668e-05, Validation Loss: 6.849174290740242e-05\n",
      "Epoch [13/25], Train Loss: 7.298905256902799e-05, Validation Loss: 6.890879206669828e-05\n",
      "Epoch [13/25], Train Loss: 6.124072388047352e-05, Validation Loss: 6.939524100744166e-05\n",
      "Epoch [13/25], Train Loss: 6.32810770184733e-05, Validation Loss: 7.019280989576752e-05\n",
      "Epoch [13/25], Train Loss: 6.456227856688201e-05, Validation Loss: 7.115270467087006e-05\n",
      "Epoch [13/25], Train Loss: 6.249587750062346e-05, Validation Loss: 7.266520430372717e-05\n",
      "Epoch [13/25], Train Loss: 6.407655018847436e-05, Validation Loss: 7.433454908702212e-05\n",
      "Epoch [13/25], Train Loss: 8.336436440004036e-05, Validation Loss: 7.611736727994867e-05\n",
      "Epoch [13/25], Train Loss: 8.74504548846744e-05, Validation Loss: 7.799395777207489e-05\n",
      "Epoch [13/25], Train Loss: 0.00010181811376241967, Validation Loss: 7.899847162965065e-05\n",
      "Epoch [13/25], Train Loss: 6.163024954730645e-05, Validation Loss: 7.8471813564344e-05\n",
      "Epoch [13/25], Train Loss: 7.705453026574105e-05, Validation Loss: 7.635591852401073e-05\n",
      "Epoch [13/25], Train Loss: 8.120380516629666e-05, Validation Loss: 7.300677971215919e-05\n",
      "Epoch [13/25], Train Loss: 8.946384332375601e-05, Validation Loss: 6.949419087807959e-05\n",
      "Epoch [13/25], Train Loss: 5.9073550801258534e-05, Validation Loss: 6.723905583688368e-05\n",
      "Epoch [14/25], Train Loss: 7.153241313062608e-05, Validation Loss: 6.711076760742192e-05\n",
      "Epoch [14/25], Train Loss: 5.839310688315891e-05, Validation Loss: 6.850294739706442e-05\n",
      "Epoch [14/25], Train Loss: 7.236478268168867e-05, Validation Loss: 7.035464417034139e-05\n",
      "Epoch [14/25], Train Loss: 5.536862954613753e-05, Validation Loss: 7.122605117425944e-05\n",
      "Epoch [14/25], Train Loss: 6.937277066754177e-05, Validation Loss: 7.061220555139395e-05\n",
      "Epoch [14/25], Train Loss: 6.23319938313216e-05, Validation Loss: 6.897906544812334e-05\n",
      "Epoch [14/25], Train Loss: 6.63377286400646e-05, Validation Loss: 6.732548742244641e-05\n",
      "Epoch [14/25], Train Loss: 6.060349187464453e-05, Validation Loss: 6.673871175735257e-05\n",
      "Epoch [14/25], Train Loss: 4.755599729833193e-05, Validation Loss: 6.726316884548093e-05\n",
      "Epoch [14/25], Train Loss: 5.832228634972125e-05, Validation Loss: 6.84372462274041e-05\n",
      "Epoch [14/25], Train Loss: 7.036267925286666e-05, Validation Loss: 6.9078985931507e-05\n",
      "Epoch [14/25], Train Loss: 6.898576975800097e-05, Validation Loss: 6.878287725461026e-05\n",
      "Epoch [14/25], Train Loss: 6.648599082836881e-05, Validation Loss: 6.77233018601934e-05\n",
      "Epoch [14/25], Train Loss: 7.139892113627866e-05, Validation Loss: 6.685163243673742e-05\n",
      "Epoch [14/25], Train Loss: 7.88078032201156e-05, Validation Loss: 6.655926287445861e-05\n",
      "Epoch [14/25], Train Loss: 6.598933396162465e-05, Validation Loss: 6.701176874533606e-05\n",
      "Epoch [14/25], Train Loss: 8.444168634014204e-05, Validation Loss: 6.760023704070288e-05\n",
      "Epoch [14/25], Train Loss: 7.772543904138729e-05, Validation Loss: 6.778002401309398e-05\n",
      "Epoch [14/25], Train Loss: 7.316890696529299e-05, Validation Loss: 6.746131402906031e-05\n",
      "Epoch [14/25], Train Loss: 7.246007589856163e-05, Validation Loss: 6.682396415271796e-05\n",
      "Epoch [14/25], Train Loss: 5.1961502322228625e-05, Validation Loss: 6.644588138442487e-05\n",
      "Epoch [14/25], Train Loss: 7.117439963622019e-05, Validation Loss: 6.662655068794266e-05\n",
      "Epoch [14/25], Train Loss: 6.079124068492092e-05, Validation Loss: 6.701051970594562e-05\n",
      "Epoch [14/25], Train Loss: 6.914899859111756e-05, Validation Loss: 6.722143371007405e-05\n",
      "Epoch [14/25], Train Loss: 7.389594975393265e-05, Validation Loss: 6.70102102352151e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Train Loss: 7.162138354033232e-05, Validation Loss: 6.653644013567827e-05\n",
      "Epoch [14/25], Train Loss: 8.368184353457764e-05, Validation Loss: 6.608518669963815e-05\n",
      "Epoch [14/25], Train Loss: 9.13817566470243e-05, Validation Loss: 6.60870377032552e-05\n",
      "Epoch [14/25], Train Loss: 6.620007479796186e-05, Validation Loss: 6.620728114891487e-05\n",
      "Epoch [14/25], Train Loss: 8.171875379048288e-05, Validation Loss: 6.641063664574176e-05\n",
      "Epoch [14/25], Train Loss: 6.54762625345029e-05, Validation Loss: 6.654030051625645e-05\n",
      "Epoch [14/25], Train Loss: 5.852359390701167e-05, Validation Loss: 6.65654491361541e-05\n",
      "Epoch [14/25], Train Loss: 6.527798541355878e-05, Validation Loss: 6.653176727316653e-05\n",
      "Epoch [14/25], Train Loss: 6.50278088869527e-05, Validation Loss: 6.63729188090656e-05\n",
      "Epoch [14/25], Train Loss: 7.003619975876063e-05, Validation Loss: 6.617397884838283e-05\n",
      "Epoch [14/25], Train Loss: 5.7401819503866136e-05, Validation Loss: 6.608820185647347e-05\n",
      "Epoch [14/25], Train Loss: 5.7894063502317294e-05, Validation Loss: 6.632220198904785e-05\n",
      "Epoch [14/25], Train Loss: 8.526026067556813e-05, Validation Loss: 6.773582766375816e-05\n",
      "Epoch [14/25], Train Loss: 6.903339817654341e-05, Validation Loss: 7.063448574626819e-05\n",
      "Epoch [14/25], Train Loss: 7.586526771774516e-05, Validation Loss: 8.040825535620873e-05\n",
      "Epoch [14/25], Train Loss: 7.757964340271428e-05, Validation Loss: 9.412750174912314e-05\n",
      "Epoch [14/25], Train Loss: 9.344406862510368e-05, Validation Loss: 0.00010856263543246314\n",
      "Epoch [14/25], Train Loss: 0.00010396601282991469, Validation Loss: 0.00010955913069968423\n",
      "Epoch [14/25], Train Loss: 0.0001085570766008459, Validation Loss: 8.920158676725501e-05\n",
      "Epoch [14/25], Train Loss: 0.00010283489245921373, Validation Loss: 7.182197490086158e-05\n",
      "Epoch [14/25], Train Loss: 7.659903349122033e-05, Validation Loss: 7.751101681302922e-05\n",
      "Epoch [14/25], Train Loss: 7.057798211462796e-05, Validation Loss: 8.777212303054208e-05\n",
      "Epoch [14/25], Train Loss: 7.957655179779977e-05, Validation Loss: 7.95843579301921e-05\n",
      "Epoch [14/25], Train Loss: 7.109743455657735e-05, Validation Loss: 6.664898828603327e-05\n",
      "Epoch [14/25], Train Loss: 6.884111644467339e-05, Validation Loss: 7.202081518092503e-05\n",
      "Epoch [14/25], Train Loss: 7.719040877418593e-05, Validation Loss: 7.999862864380703e-05\n",
      "Epoch [14/25], Train Loss: 8.567318582208827e-05, Validation Loss: 7.253108293904612e-05\n",
      "Epoch [14/25], Train Loss: 7.863729115342721e-05, Validation Loss: 6.749220968534549e-05\n",
      "Epoch [14/25], Train Loss: 6.662355008302256e-05, Validation Loss: 7.30093920234746e-05\n",
      "Epoch [14/25], Train Loss: 6.826187745900825e-05, Validation Loss: 7.177425310752975e-05\n",
      "Epoch [14/25], Train Loss: 6.637451588176191e-05, Validation Loss: 6.635127429035492e-05\n",
      "Epoch [14/25], Train Loss: 8.388498099520802e-05, Validation Loss: 6.980115940677934e-05\n",
      "Epoch [14/25], Train Loss: 6.663396925432608e-05, Validation Loss: 7.176222934504039e-05\n",
      "Epoch [14/25], Train Loss: 6.948976079002023e-05, Validation Loss: 6.70592312720449e-05\n",
      "Epoch [14/25], Train Loss: 7.197750528575853e-05, Validation Loss: 6.702388758033825e-05\n",
      "Epoch [14/25], Train Loss: 6.145509541966021e-05, Validation Loss: 6.931207293140082e-05\n",
      "Epoch [14/25], Train Loss: 7.401038601528853e-05, Validation Loss: 6.670802952915741e-05\n",
      "Epoch [14/25], Train Loss: 6.76939234836027e-05, Validation Loss: 6.636600107109794e-05\n",
      "Epoch [14/25], Train Loss: 6.0284233768470585e-05, Validation Loss: 6.843520338103795e-05\n",
      "Epoch [14/25], Train Loss: 8.154780516633764e-05, Validation Loss: 6.662093267853683e-05\n",
      "Epoch [14/25], Train Loss: 6.713651237078011e-05, Validation Loss: 6.550260610917272e-05\n",
      "Epoch [14/25], Train Loss: 6.861798465251923e-05, Validation Loss: 6.699864922363e-05\n",
      "Epoch [14/25], Train Loss: 6.501510506495833e-05, Validation Loss: 6.639350128049652e-05\n",
      "Epoch [14/25], Train Loss: 7.920141069917008e-05, Validation Loss: 6.552123644117576e-05\n",
      "Epoch [14/25], Train Loss: 7.306608313228935e-05, Validation Loss: 6.652288235879193e-05\n",
      "Epoch [14/25], Train Loss: 6.341392145259306e-05, Validation Loss: 6.628455278890518e-05\n",
      "Epoch [14/25], Train Loss: 7.083204400260001e-05, Validation Loss: 6.507049887053048e-05\n",
      "Epoch [14/25], Train Loss: 7.464741793228313e-05, Validation Loss: 6.55905925668776e-05\n",
      "Epoch [14/25], Train Loss: 7.301897858269513e-05, Validation Loss: 6.641966028837487e-05\n",
      "Epoch [14/25], Train Loss: 7.74212385294959e-05, Validation Loss: 6.658686834271066e-05\n",
      "Epoch [14/25], Train Loss: 6.905700138304383e-05, Validation Loss: 6.514221774220156e-05\n",
      "Epoch [14/25], Train Loss: 6.0157555708428845e-05, Validation Loss: 6.543812899811504e-05\n",
      "Epoch [14/25], Train Loss: 6.356628000503406e-05, Validation Loss: 6.656740273077351e-05\n",
      "Epoch [14/25], Train Loss: 5.401327143772505e-05, Validation Loss: 6.558804840703184e-05\n",
      "Epoch [14/25], Train Loss: 6.0298258176771924e-05, Validation Loss: 6.488145275701148e-05\n",
      "Epoch [14/25], Train Loss: 7.651548366993666e-05, Validation Loss: 6.587938478332944e-05\n",
      "Epoch [14/25], Train Loss: 6.223436503205448e-05, Validation Loss: 6.619238047278486e-05\n",
      "Epoch [14/25], Train Loss: 5.140195571584627e-05, Validation Loss: 6.491953414903644e-05\n",
      "Epoch [14/25], Train Loss: 7.168153388192877e-05, Validation Loss: 6.558915095714232e-05\n",
      "Epoch [14/25], Train Loss: 6.653174932580441e-05, Validation Loss: 6.59761836383647e-05\n",
      "Epoch [14/25], Train Loss: 6.309182936092839e-05, Validation Loss: 6.472900495282374e-05\n",
      "Epoch [14/25], Train Loss: 6.885176844662055e-05, Validation Loss: 6.475386107922532e-05\n",
      "Epoch [14/25], Train Loss: 6.842100265203044e-05, Validation Loss: 6.550105366234979e-05\n",
      "Epoch [14/25], Train Loss: 5.4527561587747186e-05, Validation Loss: 6.517771568420964e-05\n",
      "Epoch [14/25], Train Loss: 8.040211105253547e-05, Validation Loss: 6.421004630586443e-05\n",
      "Epoch [14/25], Train Loss: 6.515203131129965e-05, Validation Loss: 6.441412576047393e-05\n",
      "Epoch [14/25], Train Loss: 5.0966409617103636e-05, Validation Loss: 6.481640787872797e-05\n",
      "Epoch [14/25], Train Loss: 4.977241769665852e-05, Validation Loss: 6.69946059739838e-05\n",
      "Epoch [14/25], Train Loss: 6.65964325889945e-05, Validation Loss: 7.316603126431195e-05\n",
      "Epoch [14/25], Train Loss: 8.916920342016965e-05, Validation Loss: 7.179593618881579e-05\n",
      "Epoch [14/25], Train Loss: 6.487307837232947e-05, Validation Loss: 7.165747180503483e-05\n",
      "Epoch [14/25], Train Loss: 8.43848247313872e-05, Validation Loss: 6.586534776336824e-05\n",
      "Epoch [14/25], Train Loss: 7.485148671548814e-05, Validation Loss: 6.594052004705493e-05\n",
      "Epoch [14/25], Train Loss: 6.814252265030518e-05, Validation Loss: 6.885975017212331e-05\n",
      "Epoch [14/25], Train Loss: 6.835010572103783e-05, Validation Loss: 6.707189992691079e-05\n",
      "Epoch [14/25], Train Loss: 7.024483784334734e-05, Validation Loss: 6.439897697418928e-05\n",
      "Epoch [14/25], Train Loss: 5.97861289861612e-05, Validation Loss: 6.674808391835541e-05\n",
      "Epoch [14/25], Train Loss: 8.172159141395241e-05, Validation Loss: 6.6375430469634e-05\n",
      "Epoch [14/25], Train Loss: 5.421250170911662e-05, Validation Loss: 6.443620635157762e-05\n",
      "Epoch [14/25], Train Loss: 6.092871626606211e-05, Validation Loss: 6.558731183758937e-05\n",
      "Epoch [14/25], Train Loss: 7.249344344018027e-05, Validation Loss: 6.625026411105258e-05\n",
      "Epoch [14/25], Train Loss: 6.329405005089939e-05, Validation Loss: 6.446980260079726e-05\n",
      "Epoch [14/25], Train Loss: 6.603007932426408e-05, Validation Loss: 6.463528770837002e-05\n",
      "Epoch [14/25], Train Loss: 7.71569466451183e-05, Validation Loss: 6.534517330389159e-05\n",
      "Epoch [14/25], Train Loss: 7.53861095290631e-05, Validation Loss: 6.430512075894512e-05\n",
      "Epoch [14/25], Train Loss: 7.20523894415237e-05, Validation Loss: 6.386426127088876e-05\n",
      "Epoch [14/25], Train Loss: 5.8209840062772855e-05, Validation Loss: 6.46108504345951e-05\n",
      "Epoch [14/25], Train Loss: 7.15810529072769e-05, Validation Loss: 6.509215066519876e-05\n",
      "Epoch [14/25], Train Loss: 6.385133019648492e-05, Validation Loss: 6.480422938087334e-05\n",
      "Epoch [14/25], Train Loss: 5.823959509143606e-05, Validation Loss: 6.458097632275895e-05\n",
      "Epoch [14/25], Train Loss: 7.901112985564396e-05, Validation Loss: 6.37856409108887e-05\n",
      "Epoch [14/25], Train Loss: 5.2124694775557145e-05, Validation Loss: 6.346604883826028e-05\n",
      "Epoch [14/25], Train Loss: 6.365969602484256e-05, Validation Loss: 6.34403906587977e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Train Loss: 4.8792244342621416e-05, Validation Loss: 6.323278915563909e-05\n",
      "Epoch [14/25], Train Loss: 7.271313370438293e-05, Validation Loss: 6.321145046968013e-05\n",
      "Epoch [14/25], Train Loss: 5.46892624697648e-05, Validation Loss: 6.319841365135896e-05\n",
      "Epoch [14/25], Train Loss: 7.004170038271695e-05, Validation Loss: 6.299670688652744e-05\n",
      "Epoch [14/25], Train Loss: 7.578188524348661e-05, Validation Loss: 6.301298077839116e-05\n",
      "Epoch [14/25], Train Loss: 6.0878635849803686e-05, Validation Loss: 6.312281863453487e-05\n",
      "Epoch [14/25], Train Loss: 5.791172952740453e-05, Validation Loss: 6.366853970879068e-05\n",
      "Epoch [14/25], Train Loss: 7.648127939319238e-05, Validation Loss: 6.526126793081252e-05\n",
      "Epoch [14/25], Train Loss: 7.058966002659872e-05, Validation Loss: 7.023977474697555e-05\n",
      "Epoch [14/25], Train Loss: 7.32914631953463e-05, Validation Loss: 8.27518398485457e-05\n",
      "Epoch [14/25], Train Loss: 8.458118099952117e-05, Validation Loss: 0.00010898178249287108\n",
      "Epoch [14/25], Train Loss: 0.00010724992898758501, Validation Loss: 0.00013382304168771953\n",
      "Epoch [14/25], Train Loss: 0.00014593449304811656, Validation Loss: 0.00011975993208276728\n",
      "Epoch [14/25], Train Loss: 0.00012494543625507504, Validation Loss: 7.270787731007052e-05\n",
      "Epoch [14/25], Train Loss: 7.402659684885293e-05, Validation Loss: 7.208968575772209e-05\n",
      "Epoch [14/25], Train Loss: 5.835963020217605e-05, Validation Loss: 9.768335245704899e-05\n",
      "Epoch [15/25], Train Loss: 9.505756315775216e-05, Validation Loss: 8.064858023620521e-05\n",
      "Epoch [15/25], Train Loss: 8.61362786963582e-05, Validation Loss: 6.552131720430529e-05\n",
      "Epoch [15/25], Train Loss: 7.421572809107602e-05, Validation Loss: 8.205757039831951e-05\n",
      "Epoch [15/25], Train Loss: 9.760670218383893e-05, Validation Loss: 7.463094710449999e-05\n",
      "Epoch [15/25], Train Loss: 7.331486995099112e-05, Validation Loss: 6.719028509299581e-05\n",
      "Epoch [15/25], Train Loss: 4.7375211579492316e-05, Validation Loss: 7.531382216257043e-05\n",
      "Epoch [15/25], Train Loss: 6.935856072232127e-05, Validation Loss: 6.982544728089124e-05\n",
      "Epoch [15/25], Train Loss: 8.081137639237568e-05, Validation Loss: 6.867304012606232e-05\n",
      "Epoch [15/25], Train Loss: 6.638617196585983e-05, Validation Loss: 6.945444692973979e-05\n",
      "Epoch [15/25], Train Loss: 6.327765004243702e-05, Validation Loss: 6.836157360036547e-05\n",
      "Epoch [15/25], Train Loss: 6.68028587824665e-05, Validation Loss: 6.715161168055298e-05\n",
      "Epoch [15/25], Train Loss: 7.689791527809575e-05, Validation Loss: 6.608560167175407e-05\n",
      "Epoch [15/25], Train Loss: 7.557502976851538e-05, Validation Loss: 6.87585639146467e-05\n",
      "Epoch [15/25], Train Loss: 6.594318256247789e-05, Validation Loss: 6.427275438909419e-05\n",
      "Epoch [15/25], Train Loss: 6.484730693046004e-05, Validation Loss: 6.672363160760142e-05\n",
      "Epoch [15/25], Train Loss: 5.276718729874119e-05, Validation Loss: 6.6629742650548e-05\n",
      "Epoch [15/25], Train Loss: 7.457690662704408e-05, Validation Loss: 6.304495327640325e-05\n",
      "Epoch [15/25], Train Loss: 6.102205588831566e-05, Validation Loss: 6.721148335297282e-05\n",
      "Epoch [15/25], Train Loss: 6.4262785599567e-05, Validation Loss: 6.364156846151066e-05\n",
      "Epoch [15/25], Train Loss: 6.052066237316467e-05, Validation Loss: 6.45372715856259e-05\n",
      "Epoch [15/25], Train Loss: 5.3879371989751235e-05, Validation Loss: 6.53508325437239e-05\n",
      "Epoch [15/25], Train Loss: 7.919888594187796e-05, Validation Loss: 6.316588381499363e-05\n",
      "Epoch [15/25], Train Loss: 8.255002467194572e-05, Validation Loss: 6.442677501278619e-05\n",
      "Epoch [15/25], Train Loss: 7.1273410867434e-05, Validation Loss: 6.3772797875572e-05\n",
      "Epoch [15/25], Train Loss: 6.686637789243832e-05, Validation Loss: 6.337821638832489e-05\n",
      "Epoch [15/25], Train Loss: 6.453042442444712e-05, Validation Loss: 6.350258845486679e-05\n",
      "Epoch [15/25], Train Loss: 8.574068488087505e-05, Validation Loss: 6.367349366579826e-05\n",
      "Epoch [15/25], Train Loss: 6.929088704055175e-05, Validation Loss: 6.2867722347922e-05\n",
      "Epoch [15/25], Train Loss: 6.62958700559102e-05, Validation Loss: 6.328574866832544e-05\n",
      "Epoch [15/25], Train Loss: 6.377155659720302e-05, Validation Loss: 6.324278486620945e-05\n",
      "Epoch [15/25], Train Loss: 5.1134131354046986e-05, Validation Loss: 6.245278806697267e-05\n",
      "Epoch [15/25], Train Loss: 5.250590038485825e-05, Validation Loss: 6.328161495427291e-05\n",
      "Epoch [15/25], Train Loss: 5.665255957865156e-05, Validation Loss: 6.266319323913194e-05\n",
      "Epoch [15/25], Train Loss: 5.8063335018232465e-05, Validation Loss: 6.24690158777715e-05\n",
      "Epoch [15/25], Train Loss: 6.862849841127172e-05, Validation Loss: 6.299417679353306e-05\n",
      "Epoch [15/25], Train Loss: 5.770674397354014e-05, Validation Loss: 6.230484189776083e-05\n",
      "Epoch [15/25], Train Loss: 6.999197648838162e-05, Validation Loss: 6.254727365255046e-05\n",
      "Epoch [15/25], Train Loss: 6.254923209780827e-05, Validation Loss: 6.254862358521981e-05\n",
      "Epoch [15/25], Train Loss: 6.104727071942762e-05, Validation Loss: 6.224252210813574e-05\n",
      "Epoch [15/25], Train Loss: 5.513191717909649e-05, Validation Loss: 6.240615475689992e-05\n",
      "Epoch [15/25], Train Loss: 6.31523143965751e-05, Validation Loss: 6.230367386403183e-05\n",
      "Epoch [15/25], Train Loss: 6.492563261417672e-05, Validation Loss: 6.217162444954738e-05\n",
      "Epoch [15/25], Train Loss: 6.000734356348403e-05, Validation Loss: 6.217653693359655e-05\n",
      "Epoch [15/25], Train Loss: 6.607008253922686e-05, Validation Loss: 6.211779618752189e-05\n",
      "Epoch [15/25], Train Loss: 6.162694626254961e-05, Validation Loss: 6.201460006802032e-05\n",
      "Epoch [15/25], Train Loss: 5.588606290984899e-05, Validation Loss: 6.196749163791537e-05\n",
      "Epoch [15/25], Train Loss: 6.301176472334191e-05, Validation Loss: 6.198188154182087e-05\n",
      "Epoch [15/25], Train Loss: 6.45522159175016e-05, Validation Loss: 6.187049633202454e-05\n",
      "Epoch [15/25], Train Loss: 6.625110108871013e-05, Validation Loss: 6.182338887204727e-05\n",
      "Epoch [15/25], Train Loss: 6.271159509196877e-05, Validation Loss: 6.188104016473517e-05\n",
      "Epoch [15/25], Train Loss: 6.951610703254119e-05, Validation Loss: 6.175524104037322e-05\n",
      "Epoch [15/25], Train Loss: 6.742355617461726e-05, Validation Loss: 6.170653747782732e-05\n",
      "Epoch [15/25], Train Loss: 6.100480823079124e-05, Validation Loss: 6.17526699594843e-05\n",
      "Epoch [15/25], Train Loss: 5.8711641031550243e-05, Validation Loss: 6.164155201986432e-05\n",
      "Epoch [15/25], Train Loss: 5.975300882710144e-05, Validation Loss: 6.160326083772815e-05\n",
      "Epoch [15/25], Train Loss: 7.645376172149554e-05, Validation Loss: 6.164786949132879e-05\n",
      "Epoch [15/25], Train Loss: 6.298624066403136e-05, Validation Loss: 6.155406687563906e-05\n",
      "Epoch [15/25], Train Loss: 4.976256605004892e-05, Validation Loss: 6.151507501878465e-05\n",
      "Epoch [15/25], Train Loss: 4.821396214538254e-05, Validation Loss: 6.154808773620365e-05\n",
      "Epoch [15/25], Train Loss: 5.3390769608085975e-05, Validation Loss: 6.149024726861777e-05\n",
      "Epoch [15/25], Train Loss: 6.122652848716825e-05, Validation Loss: 6.144761500763707e-05\n",
      "Epoch [15/25], Train Loss: 6.277045758906752e-05, Validation Loss: 6.146327747652928e-05\n",
      "Epoch [15/25], Train Loss: 6.751831097062677e-05, Validation Loss: 6.142586183462602e-05\n",
      "Epoch [15/25], Train Loss: 7.081568037392572e-05, Validation Loss: 6.135859293863178e-05\n",
      "Epoch [15/25], Train Loss: 5.654987398884259e-05, Validation Loss: 6.136373388775004e-05\n",
      "Epoch [15/25], Train Loss: 6.746087456122041e-05, Validation Loss: 6.136175458474706e-05\n",
      "Epoch [15/25], Train Loss: 7.206945883808658e-05, Validation Loss: 6.13172536153191e-05\n",
      "Epoch [15/25], Train Loss: 6.89303342369385e-05, Validation Loss: 6.133556744316592e-05\n",
      "Epoch [15/25], Train Loss: 6.690518057439476e-05, Validation Loss: 6.136960607060852e-05\n",
      "Epoch [15/25], Train Loss: 5.526402674149722e-05, Validation Loss: 6.136864564420345e-05\n",
      "Epoch [15/25], Train Loss: 6.556361768161878e-05, Validation Loss: 6.140449428736853e-05\n",
      "Epoch [15/25], Train Loss: 7.651429041288793e-05, Validation Loss: 6.147155218059198e-05\n",
      "Epoch [15/25], Train Loss: 6.672394374618307e-05, Validation Loss: 6.157889341314633e-05\n",
      "Epoch [15/25], Train Loss: 7.604015263495967e-05, Validation Loss: 6.164573448283287e-05\n",
      "Epoch [15/25], Train Loss: 6.784575816709548e-05, Validation Loss: 6.182504390987258e-05\n",
      "Epoch [15/25], Train Loss: 6.431523070205003e-05, Validation Loss: 6.202343599094698e-05\n",
      "Epoch [15/25], Train Loss: 6.250296428333968e-05, Validation Loss: 6.236891616329861e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Train Loss: 5.8728437579702586e-05, Validation Loss: 6.291211951368799e-05\n",
      "Epoch [15/25], Train Loss: 6.328478775685653e-05, Validation Loss: 6.383387711442387e-05\n",
      "Epoch [15/25], Train Loss: 5.9973146562697366e-05, Validation Loss: 6.521196967999762e-05\n",
      "Epoch [15/25], Train Loss: 8.408297435380518e-05, Validation Loss: 6.731418106937781e-05\n",
      "Epoch [15/25], Train Loss: 8.022553811315447e-05, Validation Loss: 7.012025574416232e-05\n",
      "Epoch [15/25], Train Loss: 6.680416845483705e-05, Validation Loss: 7.374748747679405e-05\n",
      "Epoch [15/25], Train Loss: 7.560634549008682e-05, Validation Loss: 7.751138133850569e-05\n",
      "Epoch [15/25], Train Loss: 6.29751812084578e-05, Validation Loss: 8.093494155521815e-05\n",
      "Epoch [15/25], Train Loss: 7.320809527300298e-05, Validation Loss: 8.162202235932152e-05\n",
      "Epoch [15/25], Train Loss: 8.793042798060924e-05, Validation Loss: 7.848633952865688e-05\n",
      "Epoch [15/25], Train Loss: 8.07636315585114e-05, Validation Loss: 7.139474109862931e-05\n",
      "Epoch [15/25], Train Loss: 6.633651355514303e-05, Validation Loss: 6.420546997105702e-05\n",
      "Epoch [15/25], Train Loss: 8.238039299612865e-05, Validation Loss: 6.070299908363571e-05\n",
      "Epoch [15/25], Train Loss: 6.65492334519513e-05, Validation Loss: 6.223465752555057e-05\n",
      "Epoch [15/25], Train Loss: 8.506260201102123e-05, Validation Loss: 6.616164658529063e-05\n",
      "Epoch [15/25], Train Loss: 6.363545981002972e-05, Validation Loss: 6.80852543155197e-05\n",
      "Epoch [15/25], Train Loss: 7.420419569825754e-05, Validation Loss: 6.641395836292456e-05\n",
      "Epoch [15/25], Train Loss: 5.9241581766400486e-05, Validation Loss: 6.27196748003674e-05\n",
      "Epoch [15/25], Train Loss: 6.121522892499343e-05, Validation Loss: 6.056739221094176e-05\n",
      "Epoch [15/25], Train Loss: 5.9363195759942755e-05, Validation Loss: 6.148802106811976e-05\n",
      "Epoch [15/25], Train Loss: 6.641058280365542e-05, Validation Loss: 6.366677310628195e-05\n",
      "Epoch [15/25], Train Loss: 6.030044096405618e-05, Validation Loss: 6.43847105190313e-05\n",
      "Epoch [15/25], Train Loss: 6.642036169068888e-05, Validation Loss: 6.268486904446036e-05\n",
      "Epoch [15/25], Train Loss: 6.638122431468219e-05, Validation Loss: 6.082086013824058e-05\n",
      "Epoch [15/25], Train Loss: 5.375158798415214e-05, Validation Loss: 6.064207846065983e-05\n",
      "Epoch [15/25], Train Loss: 6.286131974775344e-05, Validation Loss: 6.185514818450126e-05\n",
      "Epoch [15/25], Train Loss: 6.073155964259058e-05, Validation Loss: 6.26925449372114e-05\n",
      "Epoch [15/25], Train Loss: 5.565560786635615e-05, Validation Loss: 6.21541119471658e-05\n",
      "Epoch [15/25], Train Loss: 5.4910400649532676e-05, Validation Loss: 6.0932255049313726e-05\n",
      "Epoch [15/25], Train Loss: 6.260637019295245e-05, Validation Loss: 6.037404746166431e-05\n",
      "Epoch [15/25], Train Loss: 8.121852442855015e-05, Validation Loss: 6.08473303145729e-05\n",
      "Epoch [15/25], Train Loss: 6.150585249997675e-05, Validation Loss: 6.159478822761836e-05\n",
      "Epoch [15/25], Train Loss: 6.498004222521558e-05, Validation Loss: 6.165514738919834e-05\n",
      "Epoch [15/25], Train Loss: 5.6634991778992116e-05, Validation Loss: 6.10633236647118e-05\n",
      "Epoch [15/25], Train Loss: 8.353702287422493e-05, Validation Loss: 6.040427688276395e-05\n",
      "Epoch [15/25], Train Loss: 5.116340616950765e-05, Validation Loss: 6.0349554405547676e-05\n",
      "Epoch [15/25], Train Loss: 6.259646761463955e-05, Validation Loss: 6.079757561868367e-05\n",
      "Epoch [15/25], Train Loss: 5.4771637223893777e-05, Validation Loss: 6.116279206859568e-05\n",
      "Epoch [15/25], Train Loss: 7.123653631424531e-05, Validation Loss: 6.101429462432861e-05\n",
      "Epoch [15/25], Train Loss: 6.121822661953047e-05, Validation Loss: 6.05495789689788e-05\n",
      "Epoch [15/25], Train Loss: 4.9418173148296773e-05, Validation Loss: 6.0156856731434044e-05\n",
      "Epoch [15/25], Train Loss: 5.753396908403374e-05, Validation Loss: 6.012492061321003e-05\n",
      "Epoch [15/25], Train Loss: 5.3566673159366474e-05, Validation Loss: 6.033129563244681e-05\n",
      "Epoch [15/25], Train Loss: 6.653099990217015e-05, Validation Loss: 6.049837975297123e-05\n",
      "Epoch [15/25], Train Loss: 5.8064772019861266e-05, Validation Loss: 6.0446440087010464e-05\n",
      "Epoch [15/25], Train Loss: 6.390163616742939e-05, Validation Loss: 6.028850912116468e-05\n",
      "Epoch [15/25], Train Loss: 5.608195351669565e-05, Validation Loss: 6.009333204322805e-05\n",
      "Epoch [15/25], Train Loss: 6.185269739944488e-05, Validation Loss: 5.9977814332038784e-05\n",
      "Epoch [15/25], Train Loss: 4.459316187421791e-05, Validation Loss: 5.995996471028775e-05\n",
      "Epoch [15/25], Train Loss: 5.983421942801215e-05, Validation Loss: 5.9994873542261e-05\n",
      "Epoch [15/25], Train Loss: 5.0123442633775994e-05, Validation Loss: 6.0035372977533065e-05\n",
      "Epoch [15/25], Train Loss: 4.874599108006805e-05, Validation Loss: 6.002415005544511e-05\n",
      "Epoch [15/25], Train Loss: 5.715462611988187e-05, Validation Loss: 5.997491365026993e-05\n",
      "Epoch [15/25], Train Loss: 7.343001925619319e-05, Validation Loss: 5.989364556929407e-05\n",
      "Epoch [15/25], Train Loss: 6.0964797739870846e-05, Validation Loss: 5.984149271777521e-05\n",
      "Epoch [15/25], Train Loss: 6.98594085406512e-05, Validation Loss: 5.983655913344895e-05\n",
      "Epoch [15/25], Train Loss: 5.934415094088763e-05, Validation Loss: 5.985259655669021e-05\n",
      "Epoch [16/25], Train Loss: 4.843049100600183e-05, Validation Loss: 5.9876179633041224e-05\n",
      "Epoch [16/25], Train Loss: 6.644571840297431e-05, Validation Loss: 5.984913586871698e-05\n",
      "Epoch [16/25], Train Loss: 5.926368248765357e-05, Validation Loss: 5.982801812933758e-05\n",
      "Epoch [16/25], Train Loss: 5.3930660214973614e-05, Validation Loss: 5.979223399966334e-05\n",
      "Epoch [16/25], Train Loss: 7.411691331071779e-05, Validation Loss: 5.9772946163623906e-05\n",
      "Epoch [16/25], Train Loss: 6.511704123113304e-05, Validation Loss: 5.976518053406228e-05\n",
      "Epoch [16/25], Train Loss: 6.650976138189435e-05, Validation Loss: 5.9780964268914737e-05\n",
      "Epoch [16/25], Train Loss: 5.893620982533321e-05, Validation Loss: 5.98347898630891e-05\n",
      "Epoch [16/25], Train Loss: 6.434714305214584e-05, Validation Loss: 5.997084226692095e-05\n",
      "Epoch [16/25], Train Loss: 4.639005055651069e-05, Validation Loss: 6.023563522224625e-05\n",
      "Epoch [16/25], Train Loss: 5.798695201519877e-05, Validation Loss: 6.065311996887127e-05\n",
      "Epoch [16/25], Train Loss: 6.227080302778631e-05, Validation Loss: 6.146175025302606e-05\n",
      "Epoch [16/25], Train Loss: 5.872769543202594e-05, Validation Loss: 6.301536098665869e-05\n",
      "Epoch [16/25], Train Loss: 6.475632108049467e-05, Validation Loss: 6.617038961849175e-05\n",
      "Epoch [16/25], Train Loss: 5.9871337725780904e-05, Validation Loss: 7.244620986360436e-05\n",
      "Epoch [16/25], Train Loss: 6.903367466293275e-05, Validation Loss: 8.357498639573653e-05\n",
      "Epoch [16/25], Train Loss: 9.436914115212858e-05, Validation Loss: 0.00010067460971185938\n",
      "Epoch [16/25], Train Loss: 0.00011339793854858726, Validation Loss: 0.00011769532381246487\n",
      "Epoch [16/25], Train Loss: 0.00012420807615853846, Validation Loss: 0.00011931457265745848\n",
      "Epoch [16/25], Train Loss: 0.00011522894783411175, Validation Loss: 9.370022113823022e-05\n",
      "Epoch [16/25], Train Loss: 9.853134542936459e-05, Validation Loss: 6.472410726322171e-05\n",
      "Epoch [16/25], Train Loss: 5.770153438788839e-05, Validation Loss: 6.516899763179633e-05\n",
      "Epoch [16/25], Train Loss: 6.634063902311027e-05, Validation Loss: 8.301945539036145e-05\n",
      "Epoch [16/25], Train Loss: 8.05898307589814e-05, Validation Loss: 8.179120244070267e-05\n",
      "Epoch [16/25], Train Loss: 8.623652684036642e-05, Validation Loss: 6.441143608147589e-05\n",
      "Epoch [16/25], Train Loss: 7.325582555495203e-05, Validation Loss: 6.460132038531204e-05\n",
      "Epoch [16/25], Train Loss: 5.372881787479855e-05, Validation Loss: 7.495582516033512e-05\n",
      "Epoch [16/25], Train Loss: 7.561773963971063e-05, Validation Loss: 6.845945123738299e-05\n",
      "Epoch [16/25], Train Loss: 6.227852281881496e-05, Validation Loss: 6.0976037396661316e-05\n",
      "Epoch [16/25], Train Loss: 5.3353829571278766e-05, Validation Loss: 6.810451110747332e-05\n",
      "Epoch [16/25], Train Loss: 6.696603668387979e-05, Validation Loss: 6.847924305475317e-05\n",
      "Epoch [16/25], Train Loss: 7.061825454002246e-05, Validation Loss: 6.037737184669822e-05\n",
      "Epoch [16/25], Train Loss: 6.503787881229073e-05, Validation Loss: 6.344604359280008e-05\n",
      "Epoch [16/25], Train Loss: 6.002580630593002e-05, Validation Loss: 6.706524800392799e-05\n",
      "Epoch [16/25], Train Loss: 7.851624832255766e-05, Validation Loss: 6.137962166879637e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Train Loss: 5.943299402133562e-05, Validation Loss: 6.155502802963989e-05\n",
      "Epoch [16/25], Train Loss: 6.0866430430905893e-05, Validation Loss: 6.467993468201409e-05\n",
      "Epoch [16/25], Train Loss: 6.677458441117778e-05, Validation Loss: 6.11922381115922e-05\n",
      "Epoch [16/25], Train Loss: 6.3723637140356e-05, Validation Loss: 6.112290599655049e-05\n",
      "Epoch [16/25], Train Loss: 7.599556556669995e-05, Validation Loss: 6.34257211155879e-05\n",
      "Epoch [16/25], Train Loss: 7.48187376302667e-05, Validation Loss: 6.0704880888806655e-05\n",
      "Epoch [16/25], Train Loss: 6.684922846034169e-05, Validation Loss: 6.06048182817176e-05\n",
      "Epoch [16/25], Train Loss: 6.178124021971598e-05, Validation Loss: 6.251477413267518e-05\n",
      "Epoch [16/25], Train Loss: 5.752106153522618e-05, Validation Loss: 6.0586152782586095e-05\n",
      "Epoch [16/25], Train Loss: 5.709016477339901e-05, Validation Loss: 6.0143932205392045e-05\n",
      "Epoch [16/25], Train Loss: 5.4014006309444085e-05, Validation Loss: 6.155684047068158e-05\n",
      "Epoch [16/25], Train Loss: 6.986594962654635e-05, Validation Loss: 6.0416072665248065e-05\n",
      "Epoch [16/25], Train Loss: 5.727401003241539e-05, Validation Loss: 6.026570651253375e-05\n",
      "Epoch [16/25], Train Loss: 6.807418685639277e-05, Validation Loss: 6.112297633080744e-05\n",
      "Epoch [16/25], Train Loss: 5.77046193939168e-05, Validation Loss: 6.008411170720744e-05\n",
      "Epoch [16/25], Train Loss: 6.0578197007998824e-05, Validation Loss: 6.000248419392544e-05\n",
      "Epoch [16/25], Train Loss: 5.027091538067907e-05, Validation Loss: 6.073111847702724e-05\n",
      "Epoch [16/25], Train Loss: 4.846730371355079e-05, Validation Loss: 5.9986288154808186e-05\n",
      "Epoch [16/25], Train Loss: 6.630355346715078e-05, Validation Loss: 5.981175951698485e-05\n",
      "Epoch [16/25], Train Loss: 6.858651613583788e-05, Validation Loss: 6.0387889243429525e-05\n",
      "Epoch [16/25], Train Loss: 6.78007272654213e-05, Validation Loss: 5.994717478946162e-05\n",
      "Epoch [16/25], Train Loss: 5.0944639951922e-05, Validation Loss: 5.9790296654682605e-05\n",
      "Epoch [16/25], Train Loss: 6.41503938823007e-05, Validation Loss: 6.01471823756583e-05\n",
      "Epoch [16/25], Train Loss: 6.250155274756253e-05, Validation Loss: 5.982546960391725e-05\n",
      "Epoch [16/25], Train Loss: 5.9905447415076196e-05, Validation Loss: 5.963322473689914e-05\n",
      "Epoch [16/25], Train Loss: 5.547371620195918e-05, Validation Loss: 5.994004944417005e-05\n",
      "Epoch [16/25], Train Loss: 5.999468339723535e-05, Validation Loss: 5.9798715422706054e-05\n",
      "Epoch [16/25], Train Loss: 4.662755236495286e-05, Validation Loss: 5.958908538256461e-05\n",
      "Epoch [16/25], Train Loss: 5.523735308088362e-05, Validation Loss: 5.974454203775773e-05\n",
      "Epoch [16/25], Train Loss: 5.731283818022348e-05, Validation Loss: 5.969112899038009e-05\n",
      "Epoch [16/25], Train Loss: 6.866483454359695e-05, Validation Loss: 5.954447769909166e-05\n",
      "Epoch [16/25], Train Loss: 5.738667459809221e-05, Validation Loss: 5.962827223508308e-05\n",
      "Epoch [16/25], Train Loss: 5.507432433660142e-05, Validation Loss: 5.961308973686149e-05\n",
      "Epoch [16/25], Train Loss: 5.0138529331889004e-05, Validation Loss: 5.947211757302284e-05\n",
      "Epoch [16/25], Train Loss: 6.74034163239412e-05, Validation Loss: 5.9524761551680666e-05\n",
      "Epoch [16/25], Train Loss: 4.864958464168012e-05, Validation Loss: 5.959104964858852e-05\n",
      "Epoch [16/25], Train Loss: 6.262243550736457e-05, Validation Loss: 5.9485694509930906e-05\n",
      "Epoch [16/25], Train Loss: 5.496069206856191e-05, Validation Loss: 5.945208079841298e-05\n",
      "Epoch [16/25], Train Loss: 6.313240010058507e-05, Validation Loss: 5.946800447418354e-05\n",
      "Epoch [16/25], Train Loss: 5.641869574901648e-05, Validation Loss: 5.9414897987153384e-05\n",
      "Epoch [16/25], Train Loss: 5.6728735216893256e-05, Validation Loss: 5.9406037325970826e-05\n",
      "Epoch [16/25], Train Loss: 6.537552690133452e-05, Validation Loss: 5.94517919428957e-05\n",
      "Epoch [16/25], Train Loss: 6.247020064620301e-05, Validation Loss: 5.9416245009439686e-05\n",
      "Epoch [16/25], Train Loss: 6.837013643234968e-05, Validation Loss: 5.935798593175908e-05\n",
      "Epoch [16/25], Train Loss: 6.993852002779022e-05, Validation Loss: 5.9379581459021816e-05\n",
      "Epoch [16/25], Train Loss: 7.152063335524872e-05, Validation Loss: 5.937531944558335e-05\n",
      "Epoch [16/25], Train Loss: 5.505417357198894e-05, Validation Loss: 5.933102074777708e-05\n",
      "Epoch [16/25], Train Loss: 7.545667904196307e-05, Validation Loss: 5.932271233177744e-05\n",
      "Epoch [16/25], Train Loss: 5.759537816629745e-05, Validation Loss: 5.9328184336967144e-05\n",
      "Epoch [16/25], Train Loss: 6.01887222728692e-05, Validation Loss: 5.929906425687174e-05\n",
      "Epoch [16/25], Train Loss: 6.083620246499777e-05, Validation Loss: 5.9272372163832186e-05\n",
      "Epoch [16/25], Train Loss: 4.99625202792231e-05, Validation Loss: 5.92869565783379e-05\n",
      "Epoch [16/25], Train Loss: 6.15592798567377e-05, Validation Loss: 5.9299416655752187e-05\n",
      "Epoch [16/25], Train Loss: 6.483920151367784e-05, Validation Loss: 5.923956584107752e-05\n",
      "Epoch [16/25], Train Loss: 5.040047108195722e-05, Validation Loss: 5.9217546853081636e-05\n",
      "Epoch [16/25], Train Loss: 4.49290600954555e-05, Validation Loss: 5.920357216382399e-05\n",
      "Epoch [16/25], Train Loss: 5.256225631455891e-05, Validation Loss: 5.918108799960464e-05\n",
      "Epoch [16/25], Train Loss: 6.110571121098474e-05, Validation Loss: 5.914975311801148e-05\n",
      "Epoch [16/25], Train Loss: 6.193535955389962e-05, Validation Loss: 5.915139142113427e-05\n",
      "Epoch [16/25], Train Loss: 6.460180884459987e-05, Validation Loss: 5.916059720523966e-05\n",
      "Epoch [16/25], Train Loss: 5.225852146395482e-05, Validation Loss: 5.912798636321289e-05\n",
      "Epoch [16/25], Train Loss: 7.082887168508023e-05, Validation Loss: 5.911037636299928e-05\n",
      "Epoch [16/25], Train Loss: 5.899069583392702e-05, Validation Loss: 5.91126629539455e-05\n",
      "Epoch [16/25], Train Loss: 5.7782242947723716e-05, Validation Loss: 5.9105707623530177e-05\n",
      "Epoch [16/25], Train Loss: 6.946104986127466e-05, Validation Loss: 5.9097800355327e-05\n",
      "Epoch [16/25], Train Loss: 7.659294351469725e-05, Validation Loss: 5.910828549531289e-05\n",
      "Epoch [16/25], Train Loss: 6.446830957429484e-05, Validation Loss: 5.912910564802587e-05\n",
      "Epoch [16/25], Train Loss: 7.471718708984554e-05, Validation Loss: 5.9118883412641784e-05\n",
      "Epoch [16/25], Train Loss: 6.356888479785994e-05, Validation Loss: 5.911274662745806e-05\n",
      "Epoch [16/25], Train Loss: 6.308922456810251e-05, Validation Loss: 5.914260060914482e-05\n",
      "Epoch [16/25], Train Loss: 6.288471195148304e-05, Validation Loss: 5.9189091067916404e-05\n",
      "Epoch [16/25], Train Loss: 6.0701248003169894e-05, Validation Loss: 5.922444203558067e-05\n",
      "Epoch [16/25], Train Loss: 7.009778346400708e-05, Validation Loss: 5.930213713630413e-05\n",
      "Epoch [16/25], Train Loss: 4.759007424581796e-05, Validation Loss: 5.946723880091061e-05\n",
      "Epoch [16/25], Train Loss: 6.0480400861706585e-05, Validation Loss: 5.976903460881052e-05\n",
      "Epoch [16/25], Train Loss: 5.713070277124643e-05, Validation Loss: 6.015792581213948e-05\n",
      "Epoch [16/25], Train Loss: 6.557401502504945e-05, Validation Loss: 6.07731625981008e-05\n",
      "Epoch [16/25], Train Loss: 7.070790888974443e-05, Validation Loss: 6.172109715407714e-05\n",
      "Epoch [16/25], Train Loss: 5.723246795241721e-05, Validation Loss: 6.33892561988129e-05\n",
      "Epoch [16/25], Train Loss: 6.1011218349449337e-05, Validation Loss: 6.594129639173238e-05\n",
      "Epoch [16/25], Train Loss: 6.672738527413458e-05, Validation Loss: 6.983958713438673e-05\n",
      "Epoch [16/25], Train Loss: 6.629998824791983e-05, Validation Loss: 7.498082389550594e-05\n",
      "Epoch [16/25], Train Loss: 7.365378405665979e-05, Validation Loss: 8.121646533254534e-05\n",
      "Epoch [16/25], Train Loss: 9.951947868103161e-05, Validation Loss: 8.618179272161797e-05\n",
      "Epoch [16/25], Train Loss: 8.537712710676715e-05, Validation Loss: 8.743340828611205e-05\n",
      "Epoch [16/25], Train Loss: 9.31940958253108e-05, Validation Loss: 8.153537589047724e-05\n",
      "Epoch [16/25], Train Loss: 8.384385000681505e-05, Validation Loss: 7.071454310789705e-05\n",
      "Epoch [16/25], Train Loss: 6.640967330895364e-05, Validation Loss: 6.149643838095168e-05\n",
      "Epoch [16/25], Train Loss: 6.24234598944895e-05, Validation Loss: 5.971491530848046e-05\n",
      "Epoch [16/25], Train Loss: 5.6906690588220954e-05, Validation Loss: 6.441139315332597e-05\n",
      "Epoch [16/25], Train Loss: 5.467296068673022e-05, Validation Loss: 6.862003428977914e-05\n",
      "Epoch [16/25], Train Loss: 6.214735185494646e-05, Validation Loss: 6.729806676351776e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Train Loss: 7.249255577335134e-05, Validation Loss: 6.224933919535639e-05\n",
      "Epoch [16/25], Train Loss: 6.452044181060046e-05, Validation Loss: 5.980584125306147e-05\n",
      "Epoch [16/25], Train Loss: 7.670083869015798e-05, Validation Loss: 6.16439045794929e-05\n",
      "Epoch [16/25], Train Loss: 6.0128360928501934e-05, Validation Loss: 6.365813460433856e-05\n",
      "Epoch [16/25], Train Loss: 6.0444501286838204e-05, Validation Loss: 6.257008450726668e-05\n",
      "Epoch [16/25], Train Loss: 7.089572318363935e-05, Validation Loss: 5.999546895812576e-05\n",
      "Epoch [16/25], Train Loss: 7.121537782950327e-05, Validation Loss: 5.975428624272657e-05\n",
      "Epoch [17/25], Train Loss: 5.4284850193653256e-05, Validation Loss: 6.152299926422226e-05\n",
      "Epoch [17/25], Train Loss: 5.1603958127088845e-05, Validation Loss: 6.189968407852576e-05\n",
      "Epoch [17/25], Train Loss: 5.4487019951920956e-05, Validation Loss: 6.011971199768595e-05\n",
      "Epoch [17/25], Train Loss: 5.095631058793515e-05, Validation Loss: 5.889707414704996e-05\n",
      "Epoch [17/25], Train Loss: 5.656585199176334e-05, Validation Loss: 5.980518932725924e-05\n",
      "Epoch [17/25], Train Loss: 6.489954103017226e-05, Validation Loss: 6.093868820850427e-05\n",
      "Epoch [17/25], Train Loss: 5.858129225089215e-05, Validation Loss: 6.0344123388252534e-05\n",
      "Epoch [17/25], Train Loss: 7.889664266258478e-05, Validation Loss: 5.902627963223494e-05\n",
      "Epoch [17/25], Train Loss: 5.952125138719566e-05, Validation Loss: 5.893370253033936e-05\n",
      "Epoch [17/25], Train Loss: 5.601858356385492e-05, Validation Loss: 5.974779390574743e-05\n",
      "Epoch [17/25], Train Loss: 5.7513952924637124e-05, Validation Loss: 5.991943932410019e-05\n",
      "Epoch [17/25], Train Loss: 6.625055539188907e-05, Validation Loss: 5.92201645000993e-05\n",
      "Epoch [17/25], Train Loss: 4.723506935988553e-05, Validation Loss: 5.8840364848341174e-05\n",
      "Epoch [17/25], Train Loss: 5.7808763813227415e-05, Validation Loss: 5.917269469743284e-05\n",
      "Epoch [17/25], Train Loss: 5.246366708888672e-05, Validation Loss: 5.9400198127453524e-05\n",
      "Epoch [17/25], Train Loss: 6.143921200418845e-05, Validation Loss: 5.9067696808294084e-05\n",
      "Epoch [17/25], Train Loss: 5.731364944949746e-05, Validation Loss: 5.877034661049644e-05\n",
      "Epoch [17/25], Train Loss: 6.82044992572628e-05, Validation Loss: 5.893786316543507e-05\n",
      "Epoch [17/25], Train Loss: 6.768298771930858e-05, Validation Loss: 5.9254924660005294e-05\n",
      "Epoch [17/25], Train Loss: 5.684383359039202e-05, Validation Loss: 5.9135770667732385e-05\n",
      "Epoch [17/25], Train Loss: 6.594432488782331e-05, Validation Loss: 5.877245979111952e-05\n",
      "Epoch [17/25], Train Loss: 5.082999632577412e-05, Validation Loss: 5.8636654042250784e-05\n",
      "Epoch [17/25], Train Loss: 6.68932480039075e-05, Validation Loss: 5.882053325573603e-05\n",
      "Epoch [17/25], Train Loss: 6.62315942463465e-05, Validation Loss: 5.8975185675080864e-05\n",
      "Epoch [17/25], Train Loss: 6.0569338529603556e-05, Validation Loss: 5.8817521979411445e-05\n",
      "Epoch [17/25], Train Loss: 6.302686233539134e-05, Validation Loss: 5.864696746963697e-05\n",
      "Epoch [17/25], Train Loss: 7.443086360581219e-05, Validation Loss: 5.867292638868093e-05\n",
      "Epoch [17/25], Train Loss: 6.434974784497172e-05, Validation Loss: 5.8768060747145985e-05\n",
      "Epoch [17/25], Train Loss: 5.774375676992349e-05, Validation Loss: 5.870931126992218e-05\n",
      "Epoch [17/25], Train Loss: 6.132782436907291e-05, Validation Loss: 5.857634508477834e-05\n",
      "Epoch [17/25], Train Loss: 6.381646380759776e-05, Validation Loss: 5.857238817649583e-05\n",
      "Epoch [17/25], Train Loss: 7.09633095539175e-05, Validation Loss: 5.8646680796906975e-05\n",
      "Epoch [17/25], Train Loss: 6.553559069288895e-05, Validation Loss: 5.8665273051398496e-05\n",
      "Epoch [17/25], Train Loss: 6.981526530580595e-05, Validation Loss: 5.859506394093235e-05\n",
      "Epoch [17/25], Train Loss: 6.303872214630246e-05, Validation Loss: 5.851090584959214e-05\n",
      "Epoch [17/25], Train Loss: 5.972793951514177e-05, Validation Loss: 5.849268394134318e-05\n",
      "Epoch [17/25], Train Loss: 5.677970329998061e-05, Validation Loss: 5.851395835634321e-05\n",
      "Epoch [17/25], Train Loss: 7.356993592111394e-05, Validation Loss: 5.850905993914542e-05\n",
      "Epoch [17/25], Train Loss: 5.1862069085473195e-05, Validation Loss: 5.8474463973349584e-05\n",
      "Epoch [17/25], Train Loss: 5.648863225360401e-05, Validation Loss: 5.845408013556152e-05\n",
      "Epoch [17/25], Train Loss: 6.53701281407848e-05, Validation Loss: 5.8476051344769074e-05\n",
      "Epoch [17/25], Train Loss: 6.741070683347061e-05, Validation Loss: 5.848545382226196e-05\n",
      "Epoch [17/25], Train Loss: 7.190764154074714e-05, Validation Loss: 5.8441106133007756e-05\n",
      "Epoch [17/25], Train Loss: 5.556259930017404e-05, Validation Loss: 5.839219860111674e-05\n",
      "Epoch [17/25], Train Loss: 5.814586620545015e-05, Validation Loss: 5.838651729087966e-05\n",
      "Epoch [17/25], Train Loss: 6.0835220210719854e-05, Validation Loss: 5.842284202420463e-05\n",
      "Epoch [17/25], Train Loss: 6.472640234278515e-05, Validation Loss: 5.843752248135085e-05\n",
      "Epoch [17/25], Train Loss: 6.127916276454926e-05, Validation Loss: 5.8432211274824417e-05\n",
      "Epoch [17/25], Train Loss: 6.385732558555901e-05, Validation Loss: 5.8409798172457764e-05\n",
      "Epoch [17/25], Train Loss: 7.269415073096752e-05, Validation Loss: 5.8378849401681995e-05\n",
      "Epoch [17/25], Train Loss: 6.392363138729706e-05, Validation Loss: 5.836222238334206e-05\n",
      "Epoch [17/25], Train Loss: 4.888853436568752e-05, Validation Loss: 5.835929138508315e-05\n",
      "Epoch [17/25], Train Loss: 6.357962411129847e-05, Validation Loss: 5.833725881529972e-05\n",
      "Epoch [17/25], Train Loss: 6.361395207932219e-05, Validation Loss: 5.833757701717938e-05\n",
      "Epoch [17/25], Train Loss: 5.998884444124997e-05, Validation Loss: 5.835293001534107e-05\n",
      "Epoch [17/25], Train Loss: 4.9750160542316735e-05, Validation Loss: 5.835892031124483e-05\n",
      "Epoch [17/25], Train Loss: 7.14316192897968e-05, Validation Loss: 5.834583450147572e-05\n",
      "Epoch [17/25], Train Loss: 4.703344529843889e-05, Validation Loss: 5.832139067933895e-05\n",
      "Epoch [17/25], Train Loss: 5.969376798020676e-05, Validation Loss: 5.8285405248170716e-05\n",
      "Epoch [17/25], Train Loss: 6.341888365568593e-05, Validation Loss: 5.8259944732223325e-05\n",
      "Epoch [17/25], Train Loss: 6.224311800906435e-05, Validation Loss: 5.8254293495944394e-05\n",
      "Epoch [17/25], Train Loss: 5.702553244191222e-05, Validation Loss: 5.825699481647462e-05\n",
      "Epoch [17/25], Train Loss: 5.2378876716829836e-05, Validation Loss: 5.8268976378409816e-05\n",
      "Epoch [17/25], Train Loss: 7.229208131320775e-05, Validation Loss: 5.826214061623129e-05\n",
      "Epoch [17/25], Train Loss: 4.5842472900403664e-05, Validation Loss: 5.824585435523962e-05\n",
      "Epoch [17/25], Train Loss: 5.1533017540350556e-05, Validation Loss: 5.823489069977465e-05\n",
      "Epoch [17/25], Train Loss: 4.961590457241982e-05, Validation Loss: 5.8241912241404256e-05\n",
      "Epoch [17/25], Train Loss: 5.422306276159361e-05, Validation Loss: 5.824817053508013e-05\n",
      "Epoch [17/25], Train Loss: 5.733954094466753e-05, Validation Loss: 5.826687265653163e-05\n",
      "Epoch [17/25], Train Loss: 5.140435678185895e-05, Validation Loss: 5.827939846009637e-05\n",
      "Epoch [17/25], Train Loss: 5.686805161531083e-05, Validation Loss: 5.8332017457966384e-05\n",
      "Epoch [17/25], Train Loss: 5.697692176909186e-05, Validation Loss: 5.8414290106156844e-05\n",
      "Epoch [17/25], Train Loss: 6.67441199766472e-05, Validation Loss: 5.8535655504480626e-05\n",
      "Epoch [17/25], Train Loss: 6.0789821873186156e-05, Validation Loss: 5.873800182598643e-05\n",
      "Epoch [17/25], Train Loss: 6.552947888849303e-05, Validation Loss: 5.9115010662935676e-05\n",
      "Epoch [17/25], Train Loss: 5.581358709605411e-05, Validation Loss: 5.987763021645757e-05\n",
      "Epoch [17/25], Train Loss: 5.329724808689207e-05, Validation Loss: 6.124393063752601e-05\n",
      "Epoch [17/25], Train Loss: 7.17422881280072e-05, Validation Loss: 6.390550940219934e-05\n",
      "Epoch [17/25], Train Loss: 5.055720976088196e-05, Validation Loss: 6.88161084932896e-05\n",
      "Epoch [17/25], Train Loss: 6.623734225286171e-05, Validation Loss: 7.77755417705824e-05\n",
      "Epoch [17/25], Train Loss: 7.999222725629807e-05, Validation Loss: 9.201859502354637e-05\n",
      "Epoch [17/25], Train Loss: 9.490212687524036e-05, Validation Loss: 0.00011038583130963767\n",
      "Epoch [17/25], Train Loss: 9.833471267484128e-05, Validation Loss: 0.00012330384779488668\n",
      "Epoch [17/25], Train Loss: 0.00013337197015061975, Validation Loss: 0.00011486959119793028\n",
      "Epoch [17/25], Train Loss: 0.00011173858365509659, Validation Loss: 8.38174043262067e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Train Loss: 9.001541911857203e-05, Validation Loss: 6.018428636404375e-05\n",
      "Epoch [17/25], Train Loss: 6.198089249664918e-05, Validation Loss: 6.712348476867191e-05\n",
      "Epoch [17/25], Train Loss: 6.20599021203816e-05, Validation Loss: 8.368344084980587e-05\n",
      "Epoch [17/25], Train Loss: 9.734792547533289e-05, Validation Loss: 7.83068052745269e-05\n",
      "Epoch [17/25], Train Loss: 6.996042793616652e-05, Validation Loss: 6.200923938498211e-05\n",
      "Epoch [17/25], Train Loss: 5.855285417055711e-05, Validation Loss: 6.377940032204303e-05\n",
      "Epoch [17/25], Train Loss: 6.895766273373738e-05, Validation Loss: 7.279416992484281e-05\n",
      "Epoch [17/25], Train Loss: 8.027566218515858e-05, Validation Loss: 6.660377451529105e-05\n",
      "Epoch [17/25], Train Loss: 6.486675556516275e-05, Validation Loss: 5.993820862689366e-05\n",
      "Epoch [17/25], Train Loss: 6.714409391861409e-05, Validation Loss: 6.592038480448536e-05\n",
      "Epoch [17/25], Train Loss: 7.218491373350844e-05, Validation Loss: 6.628684811100053e-05\n",
      "Epoch [17/25], Train Loss: 7.552059832960367e-05, Validation Loss: 5.949082503017659e-05\n",
      "Epoch [17/25], Train Loss: 5.2547213272191584e-05, Validation Loss: 6.184406253548028e-05\n",
      "Epoch [17/25], Train Loss: 7.232887583086267e-05, Validation Loss: 6.525149825999202e-05\n",
      "Epoch [17/25], Train Loss: 6.102899351390079e-05, Validation Loss: 6.006460413724805e-05\n",
      "Epoch [17/25], Train Loss: 5.04739218740724e-05, Validation Loss: 5.9229945569920044e-05\n",
      "Epoch [17/25], Train Loss: 5.5628304835408926e-05, Validation Loss: 6.315654560845966e-05\n",
      "Epoch [17/25], Train Loss: 6.424612365663052e-05, Validation Loss: 6.0812972030059124e-05\n",
      "Epoch [17/25], Train Loss: 7.423959323205054e-05, Validation Loss: 5.8676067904646816e-05\n",
      "Epoch [17/25], Train Loss: 5.788895578007214e-05, Validation Loss: 6.13821241131518e-05\n",
      "Epoch [17/25], Train Loss: 5.3282456065062433e-05, Validation Loss: 6.0599650411556164e-05\n",
      "Epoch [17/25], Train Loss: 6.36005715932697e-05, Validation Loss: 5.873821573914029e-05\n",
      "Epoch [17/25], Train Loss: 4.838830136577599e-05, Validation Loss: 6.036458047068057e-05\n",
      "Epoch [17/25], Train Loss: 6.652934825979173e-05, Validation Loss: 5.996114293035741e-05\n",
      "Epoch [17/25], Train Loss: 6.22417064732872e-05, Validation Loss: 5.854392220498994e-05\n",
      "Epoch [17/25], Train Loss: 5.4720538173569366e-05, Validation Loss: 5.9914478091135e-05\n",
      "Epoch [17/25], Train Loss: 6.559873872902244e-05, Validation Loss: 5.976984248263761e-05\n",
      "Epoch [17/25], Train Loss: 6.401173595804721e-05, Validation Loss: 5.838002907694317e-05\n",
      "Epoch [17/25], Train Loss: 6.102105908212252e-05, Validation Loss: 5.9303078160155565e-05\n",
      "Epoch [17/25], Train Loss: 6.310746539384127e-05, Validation Loss: 5.95500164005595e-05\n",
      "Epoch [17/25], Train Loss: 5.8465611800784245e-05, Validation Loss: 5.8465623442316425e-05\n",
      "Epoch [17/25], Train Loss: 5.38488311576657e-05, Validation Loss: 5.887562947464176e-05\n",
      "Epoch [17/25], Train Loss: 5.20968678756617e-05, Validation Loss: 5.9156697291958454e-05\n",
      "Epoch [17/25], Train Loss: 5.6898770708357915e-05, Validation Loss: 5.849660980553987e-05\n",
      "Epoch [17/25], Train Loss: 6.001672227284871e-05, Validation Loss: 5.87328470525487e-05\n",
      "Epoch [17/25], Train Loss: 6.277148349909112e-05, Validation Loss: 5.893724834701667e-05\n",
      "Epoch [17/25], Train Loss: 6.755939102731645e-05, Validation Loss: 5.8391390727289645e-05\n",
      "Epoch [17/25], Train Loss: 5.9303176385583356e-05, Validation Loss: 5.859518617702027e-05\n",
      "Epoch [17/25], Train Loss: 6.774414941901341e-05, Validation Loss: 5.889009213812339e-05\n",
      "Epoch [17/25], Train Loss: 5.029927342548035e-05, Validation Loss: 5.844982006237842e-05\n",
      "Epoch [17/25], Train Loss: 5.456264625536278e-05, Validation Loss: 5.836776302506526e-05\n",
      "Epoch [17/25], Train Loss: 6.349826435325667e-05, Validation Loss: 5.865182077589755e-05\n",
      "Epoch [17/25], Train Loss: 5.775076715508476e-05, Validation Loss: 5.844803405731606e-05\n",
      "Epoch [17/25], Train Loss: 5.406873606261797e-05, Validation Loss: 5.832572229943859e-05\n",
      "Epoch [17/25], Train Loss: 5.575670729740523e-05, Validation Loss: 5.854277333128266e-05\n",
      "Epoch [17/25], Train Loss: 5.809266076539643e-05, Validation Loss: 5.839985072573957e-05\n",
      "Epoch [17/25], Train Loss: 5.92615942878183e-05, Validation Loss: 5.8269385772291574e-05\n",
      "Epoch [17/25], Train Loss: 5.670571044902317e-05, Validation Loss: 5.843850885867141e-05\n",
      "Epoch [17/25], Train Loss: 5.346196121536195e-05, Validation Loss: 5.84074992123836e-05\n",
      "Epoch [18/25], Train Loss: 7.10299500497058e-05, Validation Loss: 5.8228872755231954e-05\n",
      "Epoch [18/25], Train Loss: 5.519512706086971e-05, Validation Loss: 5.8317962733174984e-05\n",
      "Epoch [18/25], Train Loss: 6.127214874140918e-05, Validation Loss: 5.8347558418366434e-05\n",
      "Epoch [18/25], Train Loss: 6.073964686947875e-05, Validation Loss: 5.821074616202774e-05\n",
      "Epoch [18/25], Train Loss: 6.550318357767537e-05, Validation Loss: 5.822412131237797e-05\n",
      "Epoch [18/25], Train Loss: 6.636946636717767e-05, Validation Loss: 5.8297627644302946e-05\n",
      "Epoch [18/25], Train Loss: 6.163057696539909e-05, Validation Loss: 5.821805946955768e-05\n",
      "Epoch [18/25], Train Loss: 6.252278399188071e-05, Validation Loss: 5.818334999882306e-05\n",
      "Epoch [18/25], Train Loss: 5.495038931258023e-05, Validation Loss: 5.8217714589166765e-05\n",
      "Epoch [18/25], Train Loss: 4.8139525461010635e-05, Validation Loss: 5.818259135897582e-05\n",
      "Epoch [18/25], Train Loss: 6.743675476172939e-05, Validation Loss: 5.813814301897461e-05\n",
      "Epoch [18/25], Train Loss: 4.7678717237431556e-05, Validation Loss: 5.817690980620682e-05\n",
      "Epoch [18/25], Train Loss: 6.0504244174808264e-05, Validation Loss: 5.8175428906300414e-05\n",
      "Epoch [18/25], Train Loss: 5.969662015559152e-05, Validation Loss: 5.8130859542870894e-05\n",
      "Epoch [18/25], Train Loss: 6.0564536397578195e-05, Validation Loss: 5.812037246262965e-05\n",
      "Epoch [18/25], Train Loss: 6.309209857136011e-05, Validation Loss: 5.81186315685045e-05\n",
      "Epoch [18/25], Train Loss: 6.917716382304206e-05, Validation Loss: 5.808107501555545e-05\n",
      "Epoch [18/25], Train Loss: 5.838744982611388e-05, Validation Loss: 5.8084531095422186e-05\n",
      "Epoch [18/25], Train Loss: 7.612961053382605e-05, Validation Loss: 5.81107939069625e-05\n",
      "Epoch [18/25], Train Loss: 6.10410570516251e-05, Validation Loss: 5.809983170668905e-05\n",
      "Epoch [18/25], Train Loss: 6.173935980768874e-05, Validation Loss: 5.807069343669961e-05\n",
      "Epoch [18/25], Train Loss: 6.533219129778445e-05, Validation Loss: 5.805433005055723e-05\n",
      "Epoch [18/25], Train Loss: 4.7274403186747804e-05, Validation Loss: 5.805252876598388e-05\n",
      "Epoch [18/25], Train Loss: 5.110475831315853e-05, Validation Loss: 5.8033181509623925e-05\n",
      "Epoch [18/25], Train Loss: 6.35047908872366e-05, Validation Loss: 5.8032829595807316e-05\n",
      "Epoch [18/25], Train Loss: 6.791223859181628e-05, Validation Loss: 5.803244178726648e-05\n",
      "Epoch [18/25], Train Loss: 5.593582318397239e-05, Validation Loss: 5.8021248211540906e-05\n",
      "Epoch [18/25], Train Loss: 5.802150189992972e-05, Validation Loss: 5.800518265459686e-05\n",
      "Epoch [18/25], Train Loss: 5.870411405339837e-05, Validation Loss: 5.799146650436645e-05\n",
      "Epoch [18/25], Train Loss: 7.527506386395544e-05, Validation Loss: 5.7983564814397445e-05\n",
      "Epoch [18/25], Train Loss: 4.270757926860824e-05, Validation Loss: 5.7972968109728146e-05\n",
      "Epoch [18/25], Train Loss: 5.584443351835944e-05, Validation Loss: 5.7962241165417557e-05\n",
      "Epoch [18/25], Train Loss: 5.050887193647213e-05, Validation Loss: 5.7960823323810476e-05\n",
      "Epoch [18/25], Train Loss: 4.630511102732271e-05, Validation Loss: 5.7961337491481874e-05\n",
      "Epoch [18/25], Train Loss: 4.929152419208549e-05, Validation Loss: 5.795727508181396e-05\n",
      "Epoch [18/25], Train Loss: 7.186276343418285e-05, Validation Loss: 5.7944229047279806e-05\n",
      "Epoch [18/25], Train Loss: 7.007148815318942e-05, Validation Loss: 5.794442307281618e-05\n",
      "Epoch [18/25], Train Loss: 4.7069130232557654e-05, Validation Loss: 5.7927178568206726e-05\n",
      "Epoch [18/25], Train Loss: 6.686284905299544e-05, Validation Loss: 5.791752652536767e-05\n",
      "Epoch [18/25], Train Loss: 6.499383016489446e-05, Validation Loss: 5.789403464101876e-05\n",
      "Epoch [18/25], Train Loss: 5.383320603868924e-05, Validation Loss: 5.788396350302112e-05\n",
      "Epoch [18/25], Train Loss: 6.065533307264559e-05, Validation Loss: 5.7880566115879145e-05\n",
      "Epoch [18/25], Train Loss: 6.166787352412939e-05, Validation Loss: 5.7879396626958625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Train Loss: 5.936697925790213e-05, Validation Loss: 5.787859457389762e-05\n",
      "Epoch [18/25], Train Loss: 5.1120645366609097e-05, Validation Loss: 5.788897494009386e-05\n",
      "Epoch [18/25], Train Loss: 5.159479405847378e-05, Validation Loss: 5.7893499373070276e-05\n",
      "Epoch [18/25], Train Loss: 4.9407502956455573e-05, Validation Loss: 5.788343890647714e-05\n",
      "Epoch [18/25], Train Loss: 6.083631160436198e-05, Validation Loss: 5.787643070410316e-05\n",
      "Epoch [18/25], Train Loss: 6.981030310271308e-05, Validation Loss: 5.787318295915611e-05\n",
      "Epoch [18/25], Train Loss: 5.848983346368186e-05, Validation Loss: 5.7859924709191546e-05\n",
      "Epoch [18/25], Train Loss: 4.472394357435405e-05, Validation Loss: 5.783842789242044e-05\n",
      "Epoch [18/25], Train Loss: 5.634738408843987e-05, Validation Loss: 5.781698613039528e-05\n",
      "Epoch [18/25], Train Loss: 6.314850907074288e-05, Validation Loss: 5.7818890248502915e-05\n",
      "Epoch [18/25], Train Loss: 5.020709795644507e-05, Validation Loss: 5.7813431097504994e-05\n",
      "Epoch [18/25], Train Loss: 6.350432522594929e-05, Validation Loss: 5.77978506044019e-05\n",
      "Epoch [18/25], Train Loss: 4.764026016346179e-05, Validation Loss: 5.780891636580539e-05\n",
      "Epoch [18/25], Train Loss: 4.9136957386508584e-05, Validation Loss: 5.7827891578199345e-05\n",
      "Epoch [18/25], Train Loss: 4.8462858103448525e-05, Validation Loss: 5.7814140988436216e-05\n",
      "Epoch [18/25], Train Loss: 6.511892570415512e-05, Validation Loss: 5.7789937515432635e-05\n",
      "Epoch [18/25], Train Loss: 5.696943117072806e-05, Validation Loss: 5.778949707746506e-05\n",
      "Epoch [18/25], Train Loss: 5.192559547140263e-05, Validation Loss: 5.7798505198055256e-05\n",
      "Epoch [18/25], Train Loss: 4.409891334944405e-05, Validation Loss: 5.778810348905002e-05\n",
      "Epoch [18/25], Train Loss: 5.0741473387461156e-05, Validation Loss: 5.7761162315728144e-05\n",
      "Epoch [18/25], Train Loss: 6.0080274124629796e-05, Validation Loss: 5.7756608536389344e-05\n",
      "Epoch [18/25], Train Loss: 5.9967616834910586e-05, Validation Loss: 5.7770197599893436e-05\n",
      "Epoch [18/25], Train Loss: 6.22411462245509e-05, Validation Loss: 5.778309617501994e-05\n",
      "Epoch [18/25], Train Loss: 5.454869824461639e-05, Validation Loss: 5.77861935501763e-05\n",
      "Epoch [18/25], Train Loss: 5.9683512517949566e-05, Validation Loss: 5.780036008218303e-05\n",
      "Epoch [18/25], Train Loss: 5.6202370615210384e-05, Validation Loss: 5.780966481931197e-05\n",
      "Epoch [18/25], Train Loss: 6.903218309162185e-05, Validation Loss: 5.7837372636034465e-05\n",
      "Epoch [18/25], Train Loss: 5.884085112484172e-05, Validation Loss: 5.78551725387418e-05\n",
      "Epoch [18/25], Train Loss: 6.539543392136693e-05, Validation Loss: 5.7873281184583904e-05\n",
      "Epoch [18/25], Train Loss: 4.876372986473143e-05, Validation Loss: 5.788973552019646e-05\n",
      "Epoch [18/25], Train Loss: 4.137225550948642e-05, Validation Loss: 5.7939227311483894e-05\n",
      "Epoch [18/25], Train Loss: 8.246559445979074e-05, Validation Loss: 5.799247276930449e-05\n",
      "Epoch [18/25], Train Loss: 7.531517621828243e-05, Validation Loss: 5.8100624301005155e-05\n",
      "Epoch [18/25], Train Loss: 6.596758612431586e-05, Validation Loss: 5.821849408675917e-05\n",
      "Epoch [18/25], Train Loss: 4.3865398765774444e-05, Validation Loss: 5.8445886679692194e-05\n",
      "Epoch [18/25], Train Loss: 4.5373984903562814e-05, Validation Loss: 5.875487865220445e-05\n",
      "Epoch [18/25], Train Loss: 5.8062760217580944e-05, Validation Loss: 5.9310123954977216e-05\n",
      "Epoch [18/25], Train Loss: 5.7633864344097674e-05, Validation Loss: 6.011332952766679e-05\n",
      "Epoch [18/25], Train Loss: 5.7359979109605774e-05, Validation Loss: 6.129323058606436e-05\n",
      "Epoch [18/25], Train Loss: 7.40354516892694e-05, Validation Loss: 6.273154867812991e-05\n",
      "Epoch [18/25], Train Loss: 5.544609302887693e-05, Validation Loss: 6.48089674844717e-05\n",
      "Epoch [18/25], Train Loss: 7.600315439049155e-05, Validation Loss: 6.746006814258483e-05\n",
      "Epoch [18/25], Train Loss: 7.468994590453804e-05, Validation Loss: 7.057015488195853e-05\n",
      "Epoch [18/25], Train Loss: 7.932385051390156e-05, Validation Loss: 7.304670507437549e-05\n",
      "Epoch [18/25], Train Loss: 7.371057290583849e-05, Validation Loss: 7.460540340010387e-05\n",
      "Epoch [18/25], Train Loss: 7.162624388001859e-05, Validation Loss: 7.364039896250082e-05\n",
      "Epoch [18/25], Train Loss: 7.681371062062681e-05, Validation Loss: 6.992685763786236e-05\n",
      "Epoch [18/25], Train Loss: 7.322160672629252e-05, Validation Loss: 6.422379592549988e-05\n",
      "Epoch [18/25], Train Loss: 6.157809548312798e-05, Validation Loss: 5.951340863248333e-05\n",
      "Epoch [18/25], Train Loss: 5.0735918193822727e-05, Validation Loss: 5.769748604507185e-05\n",
      "Epoch [18/25], Train Loss: 6.632643635384738e-05, Validation Loss: 5.908233336716269e-05\n",
      "Epoch [18/25], Train Loss: 5.490768307936378e-05, Validation Loss: 6.169769937211337e-05\n",
      "Epoch [18/25], Train Loss: 6.797644164180383e-05, Validation Loss: 6.279238150455057e-05\n",
      "Epoch [18/25], Train Loss: 7.59947215556167e-05, Validation Loss: 6.158166943350806e-05\n",
      "Epoch [18/25], Train Loss: 5.786430847365409e-05, Validation Loss: 5.9174905860951794e-05\n",
      "Epoch [18/25], Train Loss: 6.44898900645785e-05, Validation Loss: 5.773393083169746e-05\n",
      "Epoch [18/25], Train Loss: 5.689238605555147e-05, Validation Loss: 5.8212297638723005e-05\n",
      "Epoch [18/25], Train Loss: 7.189108146121725e-05, Validation Loss: 5.963409154598291e-05\n",
      "Epoch [18/25], Train Loss: 4.957971032126807e-05, Validation Loss: 6.033051856017361e-05\n",
      "Epoch [18/25], Train Loss: 7.600719982292503e-05, Validation Loss: 5.9477740433067086e-05\n",
      "Epoch [18/25], Train Loss: 6.438317359425128e-05, Validation Loss: 5.8131496916757894e-05\n",
      "Epoch [18/25], Train Loss: 5.477115337271243e-05, Validation Loss: 5.762255750596523e-05\n",
      "Epoch [18/25], Train Loss: 6.171677523525432e-05, Validation Loss: 5.8255435578757894e-05\n",
      "Epoch [18/25], Train Loss: 5.2983901696279645e-05, Validation Loss: 5.910503605264239e-05\n",
      "Epoch [18/25], Train Loss: 5.22124428243842e-05, Validation Loss: 5.9094952302984896e-05\n",
      "Epoch [18/25], Train Loss: 5.828842768096365e-05, Validation Loss: 5.828951301130777e-05\n",
      "Epoch [18/25], Train Loss: 5.888807208975777e-05, Validation Loss: 5.762353903264739e-05\n",
      "Epoch [18/25], Train Loss: 5.900195174035616e-05, Validation Loss: 5.7759296760195865e-05\n",
      "Epoch [18/25], Train Loss: 6.293285696301609e-05, Validation Loss: 5.831391802833726e-05\n",
      "Epoch [18/25], Train Loss: 5.388005592976697e-05, Validation Loss: 5.847090093690592e-05\n",
      "Epoch [18/25], Train Loss: 6.522814510390162e-05, Validation Loss: 5.892050855133372e-05\n",
      "Epoch [18/25], Train Loss: 6.62051243125461e-05, Validation Loss: 6.504544629327332e-05\n",
      "Epoch [18/25], Train Loss: 7.157668733270839e-05, Validation Loss: 7.596148692149049e-05\n",
      "Epoch [18/25], Train Loss: 6.299409869825467e-05, Validation Loss: 8.40831499469156e-05\n",
      "Epoch [18/25], Train Loss: 7.930262654554099e-05, Validation Loss: 8.307144841334472e-05\n",
      "Epoch [18/25], Train Loss: 7.945666584419087e-05, Validation Loss: 7.743627720628865e-05\n",
      "Epoch [18/25], Train Loss: 8.094087388599291e-05, Validation Loss: 7.150978247712676e-05\n",
      "Epoch [18/25], Train Loss: 7.366889622062445e-05, Validation Loss: 6.880035750024641e-05\n",
      "Epoch [18/25], Train Loss: 8.328996773343533e-05, Validation Loss: 6.672951882743897e-05\n",
      "Epoch [18/25], Train Loss: 7.92819046182558e-05, Validation Loss: 6.45111877626429e-05\n",
      "Epoch [18/25], Train Loss: 7.975962944328785e-05, Validation Loss: 6.379569385899231e-05\n",
      "Epoch [18/25], Train Loss: 5.785224129795097e-05, Validation Loss: 6.467618053041709e-05\n",
      "Epoch [18/25], Train Loss: 5.997241532895714e-05, Validation Loss: 6.508848794813578e-05\n",
      "Epoch [18/25], Train Loss: 6.639350613113493e-05, Validation Loss: 6.350052960139389e-05\n",
      "Epoch [18/25], Train Loss: 7.051899592624977e-05, Validation Loss: 6.182224436391455e-05\n",
      "Epoch [18/25], Train Loss: 5.588624480878934e-05, Validation Loss: 6.157051102491095e-05\n",
      "Epoch [18/25], Train Loss: 5.180708467378281e-05, Validation Loss: 6.210053567580568e-05\n",
      "Epoch [18/25], Train Loss: 6.768907769583166e-05, Validation Loss: 6.092526212645074e-05\n",
      "Epoch [18/25], Train Loss: 6.474574911408126e-05, Validation Loss: 5.9509288985282185e-05\n",
      "Epoch [18/25], Train Loss: 6.345348811009899e-05, Validation Loss: 5.957122436181332e-05\n",
      "Epoch [18/25], Train Loss: 5.809973299619742e-05, Validation Loss: 6.118215848497736e-05\n",
      "Epoch [19/25], Train Loss: 6.475015834439546e-05, Validation Loss: 6.117453667684459e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Train Loss: 5.762761065852828e-05, Validation Loss: 5.928188523588081e-05\n",
      "Epoch [19/25], Train Loss: 6.428759661503136e-05, Validation Loss: 5.784633904113434e-05\n",
      "Epoch [19/25], Train Loss: 6.338679668260738e-05, Validation Loss: 5.8770433679455894e-05\n",
      "Epoch [19/25], Train Loss: 5.181457891012542e-05, Validation Loss: 5.9934888607434304e-05\n",
      "Epoch [19/25], Train Loss: 6.603538349736482e-05, Validation Loss: 5.959673023122984e-05\n",
      "Epoch [19/25], Train Loss: 6.477245187852532e-05, Validation Loss: 5.8264816955973706e-05\n",
      "Epoch [19/25], Train Loss: 5.6833538110367954e-05, Validation Loss: 5.800891788870407e-05\n",
      "Epoch [19/25], Train Loss: 6.717177893733606e-05, Validation Loss: 5.8654011081671345e-05\n",
      "Epoch [19/25], Train Loss: 6.659046630375087e-05, Validation Loss: 5.88209700557248e-05\n",
      "Epoch [19/25], Train Loss: 5.650113234878518e-05, Validation Loss: 5.820401590123462e-05\n",
      "Epoch [19/25], Train Loss: 7.53444546717219e-05, Validation Loss: 5.795102382156377e-05\n",
      "Epoch [19/25], Train Loss: 5.5915887060109526e-05, Validation Loss: 5.837769543480438e-05\n",
      "Epoch [19/25], Train Loss: 6.61333033349365e-05, Validation Loss: 5.85242007218767e-05\n",
      "Epoch [19/25], Train Loss: 6.932562973815948e-05, Validation Loss: 5.796913222487395e-05\n",
      "Epoch [19/25], Train Loss: 5.568625056184828e-05, Validation Loss: 5.757222097599879e-05\n",
      "Epoch [19/25], Train Loss: 4.92325852974318e-05, Validation Loss: 5.785957764601335e-05\n",
      "Epoch [19/25], Train Loss: 5.716312807635404e-05, Validation Loss: 5.824839002646816e-05\n",
      "Epoch [19/25], Train Loss: 6.323726120172068e-05, Validation Loss: 5.807578830475298e-05\n",
      "Epoch [19/25], Train Loss: 4.6026314521441236e-05, Validation Loss: 5.764869347331114e-05\n",
      "Epoch [19/25], Train Loss: 5.663653428200632e-05, Validation Loss: 5.7573687566521885e-05\n",
      "Epoch [19/25], Train Loss: 7.073683082126081e-05, Validation Loss: 5.780914070783183e-05\n",
      "Epoch [19/25], Train Loss: 5.281595804262906e-05, Validation Loss: 5.788426327247483e-05\n",
      "Epoch [19/25], Train Loss: 6.270756421145052e-05, Validation Loss: 5.7641842189089706e-05\n",
      "Epoch [19/25], Train Loss: 5.880280150449835e-05, Validation Loss: 5.75002758220459e-05\n",
      "Epoch [19/25], Train Loss: 6.073320037103258e-05, Validation Loss: 5.7596163242124024e-05\n",
      "Epoch [19/25], Train Loss: 6.073796612326987e-05, Validation Loss: 5.772009026259184e-05\n",
      "Epoch [19/25], Train Loss: 6.0902417317265645e-05, Validation Loss: 5.764599385050436e-05\n",
      "Epoch [19/25], Train Loss: 5.197793143452145e-05, Validation Loss: 5.751427355183599e-05\n",
      "Epoch [19/25], Train Loss: 6.388259498635307e-05, Validation Loss: 5.7491817278787495e-05\n",
      "Epoch [19/25], Train Loss: 4.679442281485535e-05, Validation Loss: 5.755619761960891e-05\n",
      "Epoch [19/25], Train Loss: 6.0872494941577315e-05, Validation Loss: 5.753603254561312e-05\n",
      "Epoch [19/25], Train Loss: 5.898538074688986e-05, Validation Loss: 5.744147589818264e-05\n",
      "Epoch [19/25], Train Loss: 5.17037624376826e-05, Validation Loss: 5.7430022085706396e-05\n",
      "Epoch [19/25], Train Loss: 6.241534720174968e-05, Validation Loss: 5.755622890622665e-05\n",
      "Epoch [19/25], Train Loss: 4.426289888215251e-05, Validation Loss: 5.75922667242897e-05\n",
      "Epoch [19/25], Train Loss: 7.508693670388311e-05, Validation Loss: 5.7495142633949096e-05\n",
      "Epoch [19/25], Train Loss: 6.552567356266081e-05, Validation Loss: 5.736666862503626e-05\n",
      "Epoch [19/25], Train Loss: 4.6853852836648e-05, Validation Loss: 5.737344690714963e-05\n",
      "Epoch [19/25], Train Loss: 7.425960939144716e-05, Validation Loss: 5.749884512624703e-05\n",
      "Epoch [19/25], Train Loss: 5.351821528165601e-05, Validation Loss: 5.754625793391218e-05\n",
      "Epoch [19/25], Train Loss: 7.064235978759825e-05, Validation Loss: 5.745564606816818e-05\n",
      "Epoch [19/25], Train Loss: 5.478298044181429e-05, Validation Loss: 5.7365573350883396e-05\n",
      "Epoch [19/25], Train Loss: 6.849438796052709e-05, Validation Loss: 5.73726729877914e-05\n",
      "Epoch [19/25], Train Loss: 4.7903857193887234e-05, Validation Loss: 5.744868685724214e-05\n",
      "Epoch [19/25], Train Loss: 6.110216054366902e-05, Validation Loss: 5.746085662394762e-05\n",
      "Epoch [19/25], Train Loss: 5.668681114912033e-05, Validation Loss: 5.7370059706348306e-05\n",
      "Epoch [19/25], Train Loss: 6.751764158252627e-05, Validation Loss: 5.728813800184677e-05\n",
      "Epoch [19/25], Train Loss: 6.606786337215453e-05, Validation Loss: 5.732685773788641e-05\n",
      "Epoch [19/25], Train Loss: 7.705394818913192e-05, Validation Loss: 5.743399475856374e-05\n",
      "Epoch [19/25], Train Loss: 6.330109317786992e-05, Validation Loss: 5.747446048189886e-05\n",
      "Epoch [19/25], Train Loss: 5.994971434120089e-05, Validation Loss: 5.739332991652191e-05\n",
      "Epoch [19/25], Train Loss: 5.96337704337202e-05, Validation Loss: 5.7305914378957826e-05\n",
      "Epoch [19/25], Train Loss: 5.89587762078736e-05, Validation Loss: 5.7333401734164606e-05\n",
      "Epoch [19/25], Train Loss: 6.67152417008765e-05, Validation Loss: 5.745080658622707e-05\n",
      "Epoch [19/25], Train Loss: 5.8226927649229765e-05, Validation Loss: 5.747238634891498e-05\n",
      "Epoch [19/25], Train Loss: 5.689340832759626e-05, Validation Loss: 5.73955522365092e-05\n",
      "Epoch [19/25], Train Loss: 4.9749447498470545e-05, Validation Loss: 5.729357508243993e-05\n",
      "Epoch [19/25], Train Loss: 4.901745342067443e-05, Validation Loss: 5.724976629911301e-05\n",
      "Epoch [19/25], Train Loss: 5.045957368565723e-05, Validation Loss: 5.72472665226087e-05\n",
      "Epoch [19/25], Train Loss: 4.5816188503522426e-05, Validation Loss: 5.7266573761201775e-05\n",
      "Epoch [19/25], Train Loss: 6.686247797915712e-05, Validation Loss: 5.726071249227971e-05\n",
      "Epoch [19/25], Train Loss: 6.885059701744467e-05, Validation Loss: 5.724374762697456e-05\n",
      "Epoch [19/25], Train Loss: 5.003077967558056e-05, Validation Loss: 5.724358488805592e-05\n",
      "Epoch [19/25], Train Loss: 6.712749018333852e-05, Validation Loss: 5.7239351735915986e-05\n",
      "Epoch [19/25], Train Loss: 5.9265774325467646e-05, Validation Loss: 5.724922739318572e-05\n",
      "Epoch [19/25], Train Loss: 5.2039871661690995e-05, Validation Loss: 5.727002887094083e-05\n",
      "Epoch [19/25], Train Loss: 6.557131564477459e-05, Validation Loss: 5.7257078636515266e-05\n",
      "Epoch [19/25], Train Loss: 5.692835838999599e-05, Validation Loss: 5.723236996952134e-05\n",
      "Epoch [19/25], Train Loss: 4.8098681872943416e-05, Validation Loss: 5.721320558222942e-05\n",
      "Epoch [19/25], Train Loss: 6.483311153715476e-05, Validation Loss: 5.722701534978114e-05\n",
      "Epoch [19/25], Train Loss: 5.35353428858798e-05, Validation Loss: 5.725373775931075e-05\n",
      "Epoch [19/25], Train Loss: 5.9598303778329864e-05, Validation Loss: 5.731413402827456e-05\n",
      "Epoch [19/25], Train Loss: 4.616019577952102e-05, Validation Loss: 5.7288216097125164e-05\n",
      "Epoch [19/25], Train Loss: 6.07650144957006e-05, Validation Loss: 5.724361035390757e-05\n",
      "Epoch [19/25], Train Loss: 5.17196131113451e-05, Validation Loss: 5.7213008888841915e-05\n",
      "Epoch [19/25], Train Loss: 6.113368726801127e-05, Validation Loss: 5.723551754878524e-05\n",
      "Epoch [19/25], Train Loss: 6.149132968857884e-05, Validation Loss: 5.729149415856227e-05\n",
      "Epoch [19/25], Train Loss: 5.686628719558939e-05, Validation Loss: 5.7338187131487456e-05\n",
      "Epoch [19/25], Train Loss: 6.12045478192158e-05, Validation Loss: 5.738462035272581e-05\n",
      "Epoch [19/25], Train Loss: 6.300517998170108e-05, Validation Loss: 5.748032247841668e-05\n",
      "Epoch [19/25], Train Loss: 6.094116179156117e-05, Validation Loss: 5.7648428870985906e-05\n",
      "Epoch [19/25], Train Loss: 4.9767273594625294e-05, Validation Loss: 5.7948552906357995e-05\n",
      "Epoch [19/25], Train Loss: 5.61856031708885e-05, Validation Loss: 5.8341492695035414e-05\n",
      "Epoch [19/25], Train Loss: 5.261426485958509e-05, Validation Loss: 5.8977869048248974e-05\n",
      "Epoch [19/25], Train Loss: 6.103156920289621e-05, Validation Loss: 5.9917539086503284e-05\n",
      "Epoch [19/25], Train Loss: 6.122598279034719e-05, Validation Loss: 6.145702354842797e-05\n",
      "Epoch [19/25], Train Loss: 7.505528628826141e-05, Validation Loss: 6.37018572888337e-05\n",
      "Epoch [19/25], Train Loss: 6.841730646556243e-05, Validation Loss: 6.707158318022265e-05\n",
      "Epoch [19/25], Train Loss: 6.999629113124683e-05, Validation Loss: 7.17236534304296e-05\n",
      "Epoch [19/25], Train Loss: 7.008628017501906e-05, Validation Loss: 7.782667186499263e-05\n",
      "Epoch [19/25], Train Loss: 8.019502274692059e-05, Validation Loss: 8.396355600173896e-05\n",
      "Epoch [19/25], Train Loss: 8.056524529820308e-05, Validation Loss: 8.791307579182709e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Train Loss: 8.139984856825322e-05, Validation Loss: 8.626948450303946e-05\n",
      "Epoch [19/25], Train Loss: 8.211240492528304e-05, Validation Loss: 7.769926863450867e-05\n",
      "Epoch [19/25], Train Loss: 7.267093315022066e-05, Validation Loss: 6.564762249278525e-05\n",
      "Epoch [19/25], Train Loss: 6.992190901655704e-05, Validation Loss: 5.8083776336085674e-05\n",
      "Epoch [19/25], Train Loss: 5.579050775850192e-05, Validation Loss: 5.893309814079354e-05\n",
      "Epoch [19/25], Train Loss: 5.8926867495756596e-05, Validation Loss: 6.462677605062102e-05\n",
      "Epoch [19/25], Train Loss: 6.964668864384294e-05, Validation Loss: 6.761809806145417e-05\n",
      "Epoch [19/25], Train Loss: 7.238565740408376e-05, Validation Loss: 6.41889081938037e-05\n",
      "Epoch [19/25], Train Loss: 6.157890311442316e-05, Validation Loss: 5.888757829476769e-05\n",
      "Epoch [19/25], Train Loss: 5.596181654254906e-05, Validation Loss: 5.775193252096263e-05\n",
      "Epoch [19/25], Train Loss: 5.294923539622687e-05, Validation Loss: 6.087293271169377e-05\n",
      "Epoch [19/25], Train Loss: 6.0945098084630445e-05, Validation Loss: 6.295073981164024e-05\n",
      "Epoch [19/25], Train Loss: 5.395664265961386e-05, Validation Loss: 6.0770471948975074e-05\n",
      "Epoch [19/25], Train Loss: 6.195779133122414e-05, Validation Loss: 5.7750790438149126e-05\n",
      "Epoch [19/25], Train Loss: 6.582021887879819e-05, Validation Loss: 5.788500614774724e-05\n",
      "Epoch [19/25], Train Loss: 6.0774873418267816e-05, Validation Loss: 6.0039267555112016e-05\n",
      "Epoch [19/25], Train Loss: 6.392454088199884e-05, Validation Loss: 6.033500685589388e-05\n",
      "Epoch [19/25], Train Loss: 4.92842955281958e-05, Validation Loss: 5.837168452368739e-05\n",
      "Epoch [19/25], Train Loss: 6.284248956944793e-05, Validation Loss: 5.741135270606416e-05\n",
      "Epoch [19/25], Train Loss: 6.40312719042413e-05, Validation Loss: 5.8476377792734034e-05\n",
      "Epoch [19/25], Train Loss: 4.782812902703881e-05, Validation Loss: 5.9233132924418895e-05\n",
      "Epoch [19/25], Train Loss: 6.0227404901525006e-05, Validation Loss: 5.826828807281951e-05\n",
      "Epoch [19/25], Train Loss: 8.407996938331053e-05, Validation Loss: 5.723959208504918e-05\n",
      "Epoch [19/25], Train Loss: 4.856028681388125e-05, Validation Loss: 5.768643362292399e-05\n",
      "Epoch [19/25], Train Loss: 7.011271372903138e-05, Validation Loss: 5.8506060789416854e-05\n",
      "Epoch [19/25], Train Loss: 5.0246344471815974e-05, Validation Loss: 5.821248875387634e-05\n",
      "Epoch [19/25], Train Loss: 5.362032970879227e-05, Validation Loss: 5.7315846546165025e-05\n",
      "Epoch [19/25], Train Loss: 6.0764690715586767e-05, Validation Loss: 5.724278574537796e-05\n",
      "Epoch [19/25], Train Loss: 6.177410978125408e-05, Validation Loss: 5.786168136789153e-05\n",
      "Epoch [19/25], Train Loss: 5.627549398923293e-05, Validation Loss: 5.8001706687112646e-05\n",
      "Epoch [19/25], Train Loss: 6.575417501153424e-05, Validation Loss: 5.746423776145093e-05\n",
      "Epoch [19/25], Train Loss: 5.819943544338457e-05, Validation Loss: 5.71776040790913e-05\n",
      "Epoch [19/25], Train Loss: 4.4518168579088524e-05, Validation Loss: 5.74491188065925e-05\n",
      "Epoch [19/25], Train Loss: 4.94641499244608e-05, Validation Loss: 5.7674433143499e-05\n",
      "Epoch [19/25], Train Loss: 5.274038267089054e-05, Validation Loss: 5.743599297905651e-05\n",
      "Epoch [19/25], Train Loss: 5.892807894269936e-05, Validation Loss: 5.714181243092753e-05\n",
      "Epoch [19/25], Train Loss: 6.48660643491894e-05, Validation Loss: 5.7216055332294975e-05\n",
      "Epoch [19/25], Train Loss: 5.529066766030155e-05, Validation Loss: 5.7409665896557274e-05\n",
      "Epoch [19/25], Train Loss: 4.861163688474335e-05, Validation Loss: 5.734951312964161e-05\n",
      "Epoch [19/25], Train Loss: 5.703280112356879e-05, Validation Loss: 5.7168064085999506e-05\n",
      "Epoch [19/25], Train Loss: 4.765885751112364e-05, Validation Loss: 5.71154060404903e-05\n",
      "Epoch [20/25], Train Loss: 6.0360900533851236e-05, Validation Loss: 5.721670944088449e-05\n",
      "Epoch [20/25], Train Loss: 5.9516918554436415e-05, Validation Loss: 5.724705236692292e-05\n",
      "Epoch [20/25], Train Loss: 4.5759086788166314e-05, Validation Loss: 5.714427655523953e-05\n",
      "Epoch [20/25], Train Loss: 5.7686127547640353e-05, Validation Loss: 5.706498559447937e-05\n",
      "Epoch [20/25], Train Loss: 4.9693295295583084e-05, Validation Loss: 5.710091087773132e-05\n",
      "Epoch [20/25], Train Loss: 6.149373075459152e-05, Validation Loss: 5.7150757250686486e-05\n",
      "Epoch [20/25], Train Loss: 5.1177845307393e-05, Validation Loss: 5.712564428298113e-05\n",
      "Epoch [20/25], Train Loss: 5.803480598842725e-05, Validation Loss: 5.7076474816616005e-05\n",
      "Epoch [20/25], Train Loss: 5.596390474238433e-05, Validation Loss: 5.7050224616735555e-05\n",
      "Epoch [20/25], Train Loss: 6.010061770211905e-05, Validation Loss: 5.7071759996082014e-05\n",
      "Epoch [20/25], Train Loss: 5.2026585763087496e-05, Validation Loss: 5.7086237696542715e-05\n",
      "Epoch [20/25], Train Loss: 5.673290434060618e-05, Validation Loss: 5.706824449589476e-05\n",
      "Epoch [20/25], Train Loss: 5.7189543440472335e-05, Validation Loss: 5.7046977841916185e-05\n",
      "Epoch [20/25], Train Loss: 7.542184175690636e-05, Validation Loss: 5.7057011629998064e-05\n",
      "Epoch [20/25], Train Loss: 6.180251511977986e-05, Validation Loss: 5.7073958305409175e-05\n",
      "Epoch [20/25], Train Loss: 5.3828422096557915e-05, Validation Loss: 5.7051910456114756e-05\n",
      "Epoch [20/25], Train Loss: 5.853261245647445e-05, Validation Loss: 5.703009859037896e-05\n",
      "Epoch [20/25], Train Loss: 5.9068697737529874e-05, Validation Loss: 5.702546695829369e-05\n",
      "Epoch [20/25], Train Loss: 5.574560054810718e-05, Validation Loss: 5.7024330938778194e-05\n",
      "Epoch [20/25], Train Loss: 6.218049384187907e-05, Validation Loss: 5.7019039619869245e-05\n",
      "Epoch [20/25], Train Loss: 5.8736568462336436e-05, Validation Loss: 5.6993906522014486e-05\n",
      "Epoch [20/25], Train Loss: 6.145255611045286e-05, Validation Loss: 5.6984425706711285e-05\n",
      "Epoch [20/25], Train Loss: 5.899707321077585e-05, Validation Loss: 5.698576545303998e-05\n",
      "Epoch [20/25], Train Loss: 6.850074714748189e-05, Validation Loss: 5.6987708376254886e-05\n",
      "Epoch [20/25], Train Loss: 5.194536061026156e-05, Validation Loss: 5.700085215115299e-05\n",
      "Epoch [20/25], Train Loss: 5.5305099522229284e-05, Validation Loss: 5.701924237655476e-05\n",
      "Epoch [20/25], Train Loss: 5.879787204321474e-05, Validation Loss: 5.704409632016905e-05\n",
      "Epoch [20/25], Train Loss: 6.0194364777999e-05, Validation Loss: 5.704338279125901e-05\n",
      "Epoch [20/25], Train Loss: 5.644997509079985e-05, Validation Loss: 5.706321777931104e-05\n",
      "Epoch [20/25], Train Loss: 5.945071461610496e-05, Validation Loss: 5.706552692572586e-05\n",
      "Epoch [20/25], Train Loss: 6.37511839158833e-05, Validation Loss: 5.705458534066565e-05\n",
      "Epoch [20/25], Train Loss: 5.525833330466412e-05, Validation Loss: 5.7028368610190226e-05\n",
      "Epoch [20/25], Train Loss: 4.6277371438918635e-05, Validation Loss: 5.7007335514451066e-05\n",
      "Epoch [20/25], Train Loss: 5.6472599681001157e-05, Validation Loss: 5.6983845570357514e-05\n",
      "Epoch [20/25], Train Loss: 5.9143851103726774e-05, Validation Loss: 5.696931451287431e-05\n",
      "Epoch [20/25], Train Loss: 7.004164217505604e-05, Validation Loss: 5.6963986571645366e-05\n",
      "Epoch [20/25], Train Loss: 7.066282705636695e-05, Validation Loss: 5.695047972646231e-05\n",
      "Epoch [20/25], Train Loss: 5.190281444811262e-05, Validation Loss: 5.692777534325917e-05\n",
      "Epoch [20/25], Train Loss: 5.6491939176339656e-05, Validation Loss: 5.693007212054605e-05\n",
      "Epoch [20/25], Train Loss: 5.333567241905257e-05, Validation Loss: 5.694759117128948e-05\n",
      "Epoch [20/25], Train Loss: 6.1089223891031e-05, Validation Loss: 5.693493876606226e-05\n",
      "Epoch [20/25], Train Loss: 6.527868390548974e-05, Validation Loss: 5.692446769292777e-05\n",
      "Epoch [20/25], Train Loss: 5.648456863127649e-05, Validation Loss: 5.6922235914195576e-05\n",
      "Epoch [20/25], Train Loss: 7.097743218764663e-05, Validation Loss: 5.693154671462253e-05\n",
      "Epoch [20/25], Train Loss: 6.204141391208395e-05, Validation Loss: 5.692709019058384e-05\n",
      "Epoch [20/25], Train Loss: 5.798876009066589e-05, Validation Loss: 5.6912662209166835e-05\n",
      "Epoch [20/25], Train Loss: 6.215355097083375e-05, Validation Loss: 5.689294339390471e-05\n",
      "Epoch [20/25], Train Loss: 5.3396761359181255e-05, Validation Loss: 5.6893680690942955e-05\n",
      "Epoch [20/25], Train Loss: 5.9213489294052124e-05, Validation Loss: 5.688341407221742e-05\n",
      "Epoch [20/25], Train Loss: 6.665961700491607e-05, Validation Loss: 5.6876517677058774e-05\n",
      "Epoch [20/25], Train Loss: 6.241141090868041e-05, Validation Loss: 5.6897240574471654e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Train Loss: 5.427128780866042e-05, Validation Loss: 5.693127677659504e-05\n",
      "Epoch [20/25], Train Loss: 5.127452459419146e-05, Validation Loss: 5.695506212456773e-05\n",
      "Epoch [20/25], Train Loss: 5.9759655414381996e-05, Validation Loss: 5.699210038680273e-05\n",
      "Epoch [20/25], Train Loss: 6.429421773646027e-05, Validation Loss: 5.7027796234857915e-05\n",
      "Epoch [20/25], Train Loss: 5.6470926210749894e-05, Validation Loss: 5.705333145063681e-05\n",
      "Epoch [20/25], Train Loss: 5.99362792854663e-05, Validation Loss: 5.706994682744456e-05\n",
      "Epoch [20/25], Train Loss: 6.115542782936245e-05, Validation Loss: 5.710429541068151e-05\n",
      "Epoch [20/25], Train Loss: 4.3822779844049364e-05, Validation Loss: 5.716925588785671e-05\n",
      "Epoch [20/25], Train Loss: 6.177755130920559e-05, Validation Loss: 5.7232844119425864e-05\n",
      "Epoch [20/25], Train Loss: 5.446752766147256e-05, Validation Loss: 5.7298057557394105e-05\n",
      "Epoch [20/25], Train Loss: 5.8658602938521653e-05, Validation Loss: 5.7373569385769464e-05\n",
      "Epoch [20/25], Train Loss: 5.886470171390101e-05, Validation Loss: 5.745434027630836e-05\n",
      "Epoch [20/25], Train Loss: 5.638082802761346e-05, Validation Loss: 5.754103234115367e-05\n",
      "Epoch [20/25], Train Loss: 5.323281584423967e-05, Validation Loss: 5.767683372444784e-05\n",
      "Epoch [20/25], Train Loss: 7.740655564703047e-05, Validation Loss: 5.786541660199873e-05\n",
      "Epoch [20/25], Train Loss: 5.7982389989774674e-05, Validation Loss: 5.814729132301484e-05\n",
      "Epoch [20/25], Train Loss: 4.94512751174625e-05, Validation Loss: 5.857773940078914e-05\n",
      "Epoch [20/25], Train Loss: 5.5471093219239265e-05, Validation Loss: 5.914689875983943e-05\n",
      "Epoch [20/25], Train Loss: 5.855805648025125e-05, Validation Loss: 5.990047987628107e-05\n",
      "Epoch [20/25], Train Loss: 6.0288824897725135e-05, Validation Loss: 6.091023678891361e-05\n",
      "Epoch [20/25], Train Loss: 6.312546611297876e-05, Validation Loss: 6.212169149269661e-05\n",
      "Epoch [20/25], Train Loss: 6.345102156046778e-05, Validation Loss: 6.349638376074533e-05\n",
      "Epoch [20/25], Train Loss: 5.862833495484665e-05, Validation Loss: 6.497616996057332e-05\n",
      "Epoch [20/25], Train Loss: 7.019069016678259e-05, Validation Loss: 6.6240625892533e-05\n",
      "Epoch [20/25], Train Loss: 6.361355917761102e-05, Validation Loss: 6.722547235161376e-05\n",
      "Epoch [20/25], Train Loss: 7.95283485786058e-05, Validation Loss: 6.711524717199306e-05\n",
      "Epoch [20/25], Train Loss: 7.178751548053697e-05, Validation Loss: 6.58774568970936e-05\n",
      "Epoch [20/25], Train Loss: 7.275785901583731e-05, Validation Loss: 6.35485082360295e-05\n",
      "Epoch [20/25], Train Loss: 6.569134711753577e-05, Validation Loss: 6.078137157601304e-05\n",
      "Epoch [20/25], Train Loss: 5.895000867894851e-05, Validation Loss: 5.866181721406368e-05\n",
      "Epoch [20/25], Train Loss: 5.7595862017478794e-05, Validation Loss: 5.790036108616429e-05\n",
      "Epoch [20/25], Train Loss: 6.517572182929143e-05, Validation Loss: 5.844615758784736e-05\n",
      "Epoch [20/25], Train Loss: 4.099339639651589e-05, Validation Loss: 5.985815490324361e-05\n",
      "Epoch [20/25], Train Loss: 6.487490463769063e-05, Validation Loss: 6.129744094020376e-05\n",
      "Epoch [20/25], Train Loss: 5.136207619216293e-05, Validation Loss: 6.208856939338148e-05\n",
      "Epoch [20/25], Train Loss: 6.589096301468089e-05, Validation Loss: 6.198902095396382e-05\n",
      "Epoch [20/25], Train Loss: 6.524477794300765e-05, Validation Loss: 6.149496111902408e-05\n",
      "Epoch [20/25], Train Loss: 5.816535485791974e-05, Validation Loss: 6.123008909829272e-05\n",
      "Epoch [20/25], Train Loss: 6.439270509872586e-05, Validation Loss: 6.157273722540897e-05\n",
      "Epoch [20/25], Train Loss: 7.791317329974845e-05, Validation Loss: 6.25901125507274e-05\n",
      "Epoch [20/25], Train Loss: 7.663079304620624e-05, Validation Loss: 6.40499480747773e-05\n",
      "Epoch [20/25], Train Loss: 5.9424677601782605e-05, Validation Loss: 6.47770386422053e-05\n",
      "Epoch [20/25], Train Loss: 6.309290620265529e-05, Validation Loss: 6.446104598580859e-05\n",
      "Epoch [20/25], Train Loss: 5.918727401876822e-05, Validation Loss: 6.280668070151781e-05\n",
      "Epoch [20/25], Train Loss: 6.33422750979662e-05, Validation Loss: 6.07157174575453e-05\n",
      "Epoch [20/25], Train Loss: 7.244906737469137e-05, Validation Loss: 5.879962821685088e-05\n",
      "Epoch [20/25], Train Loss: 5.237355435383506e-05, Validation Loss: 5.779501492118773e-05\n",
      "Epoch [20/25], Train Loss: 5.08045413880609e-05, Validation Loss: 5.760340209235437e-05\n",
      "Epoch [20/25], Train Loss: 5.86309761274606e-05, Validation Loss: 5.7898228745519495e-05\n",
      "Epoch [20/25], Train Loss: 5.986876567476429e-05, Validation Loss: 5.8303434101010984e-05\n",
      "Epoch [20/25], Train Loss: 5.14776875206735e-05, Validation Loss: 5.84770869560695e-05\n",
      "Epoch [20/25], Train Loss: 6.466743798227981e-05, Validation Loss: 5.844668752009359e-05\n",
      "Epoch [20/25], Train Loss: 5.638234142679721e-05, Validation Loss: 5.835494691079172e-05\n",
      "Epoch [20/25], Train Loss: 5.929159669904038e-05, Validation Loss: 5.822949970024638e-05\n",
      "Epoch [20/25], Train Loss: 5.323722871253267e-05, Validation Loss: 5.797840300753402e-05\n",
      "Epoch [20/25], Train Loss: 6.055517224012874e-05, Validation Loss: 5.766149964377595e-05\n",
      "Epoch [20/25], Train Loss: 5.047221202403307e-05, Validation Loss: 5.734489071376932e-05\n",
      "Epoch [20/25], Train Loss: 5.55244623683393e-05, Validation Loss: 5.7188861683243884e-05\n",
      "Epoch [20/25], Train Loss: 6.870565266581252e-05, Validation Loss: 5.729257657852334e-05\n",
      "Epoch [20/25], Train Loss: 5.4958698456175625e-05, Validation Loss: 5.752676855384682e-05\n",
      "Epoch [20/25], Train Loss: 6.256943015614524e-05, Validation Loss: 5.767493397191477e-05\n",
      "Epoch [20/25], Train Loss: 6.152022979222238e-05, Validation Loss: 5.7569606481896093e-05\n",
      "Epoch [20/25], Train Loss: 5.3684107115259394e-05, Validation Loss: 5.7328780045888075e-05\n",
      "Epoch [20/25], Train Loss: 6.804030999774113e-05, Validation Loss: 5.697331944247708e-05\n",
      "Epoch [20/25], Train Loss: 5.2587693062378094e-05, Validation Loss: 5.678055943765988e-05\n",
      "Epoch [20/25], Train Loss: 5.40342771273572e-05, Validation Loss: 5.681317488779314e-05\n",
      "Epoch [20/25], Train Loss: 4.4611748307943344e-05, Validation Loss: 5.698823952116072e-05\n",
      "Epoch [20/25], Train Loss: 5.316410170053132e-05, Validation Loss: 5.715946729954642e-05\n",
      "Epoch [20/25], Train Loss: 4.8269532271660864e-05, Validation Loss: 5.716111287862683e-05\n",
      "Epoch [20/25], Train Loss: 6.129300163593143e-05, Validation Loss: 5.707114056955712e-05\n",
      "Epoch [20/25], Train Loss: 6.274865154409781e-05, Validation Loss: 5.687601224053651e-05\n",
      "Epoch [20/25], Train Loss: 5.003529440728016e-05, Validation Loss: 5.673241200080762e-05\n",
      "Epoch [20/25], Train Loss: 5.766289905295707e-05, Validation Loss: 5.66921524296049e-05\n",
      "Epoch [20/25], Train Loss: 5.798954953206703e-05, Validation Loss: 5.675391973151515e-05\n",
      "Epoch [20/25], Train Loss: 5.28220298292581e-05, Validation Loss: 5.684420975740068e-05\n",
      "Epoch [20/25], Train Loss: 6.964767817407846e-05, Validation Loss: 5.6895140733104196e-05\n",
      "Epoch [20/25], Train Loss: 5.150135257281363e-05, Validation Loss: 5.68843189588127e-05\n",
      "Epoch [20/25], Train Loss: 7.471064600395039e-05, Validation Loss: 5.6801107712090014e-05\n",
      "Epoch [20/25], Train Loss: 6.374849908752367e-05, Validation Loss: 5.669552556355484e-05\n",
      "Epoch [20/25], Train Loss: 5.393991159508005e-05, Validation Loss: 5.661833104871524e-05\n",
      "Epoch [20/25], Train Loss: 4.996041388949379e-05, Validation Loss: 5.660885071847588e-05\n",
      "Epoch [20/25], Train Loss: 5.5111446272348985e-05, Validation Loss: 5.66513883920076e-05\n",
      "Epoch [20/25], Train Loss: 5.517125828191638e-05, Validation Loss: 5.671873708100368e-05\n",
      "Epoch [21/25], Train Loss: 6.554421270266175e-05, Validation Loss: 5.676956595076869e-05\n",
      "Epoch [21/25], Train Loss: 6.011657023918815e-05, Validation Loss: 5.677849985659122e-05\n",
      "Epoch [21/25], Train Loss: 4.8552548832958564e-05, Validation Loss: 5.675889915437438e-05\n",
      "Epoch [21/25], Train Loss: 6.290746387094259e-05, Validation Loss: 5.670228153273153e-05\n",
      "Epoch [21/25], Train Loss: 6.461446901084855e-05, Validation Loss: 5.6649478453133875e-05\n",
      "Epoch [21/25], Train Loss: 6.118665623944253e-05, Validation Loss: 5.662482799380086e-05\n",
      "Epoch [21/25], Train Loss: 6.354170182021335e-05, Validation Loss: 5.663954216288403e-05\n",
      "Epoch [21/25], Train Loss: 6.158050382509828e-05, Validation Loss: 5.667865213278371e-05\n",
      "Epoch [21/25], Train Loss: 6.751015462214127e-05, Validation Loss: 5.6710627541178836e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Train Loss: 5.211631651036441e-05, Validation Loss: 5.672879318202225e-05\n",
      "Epoch [21/25], Train Loss: 4.9829181079985574e-05, Validation Loss: 5.6701583525864406e-05\n",
      "Epoch [21/25], Train Loss: 4.710346183856018e-05, Validation Loss: 5.667163083368602e-05\n",
      "Epoch [21/25], Train Loss: 5.8164307120023295e-05, Validation Loss: 5.663203191943467e-05\n",
      "Epoch [21/25], Train Loss: 6.201080395840108e-05, Validation Loss: 5.661314911170242e-05\n",
      "Epoch [21/25], Train Loss: 6.705732812406495e-05, Validation Loss: 5.661738687194884e-05\n",
      "Epoch [21/25], Train Loss: 5.9432619309518486e-05, Validation Loss: 5.666747674695216e-05\n",
      "Epoch [21/25], Train Loss: 5.600712029263377e-05, Validation Loss: 5.6738605780992654e-05\n",
      "Epoch [21/25], Train Loss: 6.108180241426453e-05, Validation Loss: 5.684557860755982e-05\n",
      "Epoch [21/25], Train Loss: 5.5830765631981194e-05, Validation Loss: 5.699112080037594e-05\n",
      "Epoch [21/25], Train Loss: 4.9607806431595236e-05, Validation Loss: 5.7168385925857974e-05\n",
      "Epoch [21/25], Train Loss: 5.4914191423449665e-05, Validation Loss: 5.744649800665987e-05\n",
      "Epoch [21/25], Train Loss: 6.936207500984892e-05, Validation Loss: 5.785312411414149e-05\n",
      "Epoch [21/25], Train Loss: 4.0673359762877226e-05, Validation Loss: 5.845165093584607e-05\n",
      "Epoch [21/25], Train Loss: 4.989688750356436e-05, Validation Loss: 5.946952757464412e-05\n",
      "Epoch [21/25], Train Loss: 6.952974945306778e-05, Validation Loss: 6.100897347399344e-05\n",
      "Epoch [21/25], Train Loss: 5.376215267460793e-05, Validation Loss: 6.343534453966034e-05\n",
      "Epoch [21/25], Train Loss: 6.830134225310758e-05, Validation Loss: 6.714473711326719e-05\n",
      "Epoch [21/25], Train Loss: 8.976919343695045e-05, Validation Loss: 7.242415837633113e-05\n",
      "Epoch [21/25], Train Loss: 7.263265433721244e-05, Validation Loss: 7.871116637640323e-05\n",
      "Epoch [21/25], Train Loss: 7.53322456148453e-05, Validation Loss: 8.513452291178206e-05\n",
      "Epoch [21/25], Train Loss: 8.66926129674539e-05, Validation Loss: 8.822123587985213e-05\n",
      "Epoch [21/25], Train Loss: 9.140346082858741e-05, Validation Loss: 8.547596662538126e-05\n",
      "Epoch [21/25], Train Loss: 9.296549251303077e-05, Validation Loss: 7.586534848087467e-05\n",
      "Epoch [21/25], Train Loss: 7.449085387634113e-05, Validation Loss: 6.548258485660578e-05\n",
      "Epoch [21/25], Train Loss: 6.23743180767633e-05, Validation Loss: 6.0585377650568264e-05\n",
      "Epoch [21/25], Train Loss: 6.119911267887801e-05, Validation Loss: 6.314199490589089e-05\n",
      "Epoch [21/25], Train Loss: 7.359065057244152e-05, Validation Loss: 6.770168838556855e-05\n",
      "Epoch [21/25], Train Loss: 6.869027856737375e-05, Validation Loss: 6.718002623529173e-05\n",
      "Epoch [21/25], Train Loss: 7.540830119978637e-05, Validation Loss: 6.140876284916885e-05\n",
      "Epoch [21/25], Train Loss: 7.709609053563327e-05, Validation Loss: 5.702960139994199e-05\n",
      "Epoch [21/25], Train Loss: 6.132470298325643e-05, Validation Loss: 5.876270200436314e-05\n",
      "Epoch [21/25], Train Loss: 5.337591937859543e-05, Validation Loss: 6.301532606206214e-05\n",
      "Epoch [21/25], Train Loss: 6.982962077017874e-05, Validation Loss: 6.3253237506918e-05\n",
      "Epoch [21/25], Train Loss: 7.591639587190002e-05, Validation Loss: 5.9319933886096506e-05\n",
      "Epoch [21/25], Train Loss: 5.9181089454796165e-05, Validation Loss: 5.703652035056924e-05\n",
      "Epoch [21/25], Train Loss: 5.4918506066314876e-05, Validation Loss: 5.859707137763811e-05\n",
      "Epoch [21/25], Train Loss: 5.34050959686283e-05, Validation Loss: 6.017528333662388e-05\n",
      "Epoch [21/25], Train Loss: 6.782621494494379e-05, Validation Loss: 5.886142729044271e-05\n",
      "Epoch [21/25], Train Loss: 4.519946378422901e-05, Validation Loss: 5.712174218691265e-05\n",
      "Epoch [21/25], Train Loss: 6.439821299863979e-05, Validation Loss: 5.7740675401873887e-05\n",
      "Epoch [21/25], Train Loss: 6.324557034531608e-05, Validation Loss: 5.904020387485313e-05\n",
      "Epoch [21/25], Train Loss: 5.9328733186703175e-05, Validation Loss: 5.845703756979977e-05\n",
      "Epoch [21/25], Train Loss: 5.6546668929513544e-05, Validation Loss: 5.688738553241516e-05\n",
      "Epoch [21/25], Train Loss: 5.0135826313635334e-05, Validation Loss: 5.674283456755802e-05\n",
      "Epoch [21/25], Train Loss: 5.230892566032708e-05, Validation Loss: 5.771462820121087e-05\n",
      "Epoch [21/25], Train Loss: 6.802901771152392e-05, Validation Loss: 5.7781902675439294e-05\n",
      "Epoch [21/25], Train Loss: 5.5209115089382976e-05, Validation Loss: 5.698626700905152e-05\n",
      "Epoch [21/25], Train Loss: 5.305767263052985e-05, Validation Loss: 5.677424924215302e-05\n",
      "Epoch [21/25], Train Loss: 6.0090205806773156e-05, Validation Loss: 5.728141210662822e-05\n",
      "Epoch [21/25], Train Loss: 6.316175131360069e-05, Validation Loss: 5.735954158202124e-05\n",
      "Epoch [21/25], Train Loss: 5.551134381676093e-05, Validation Loss: 5.67966958139247e-05\n",
      "Epoch [21/25], Train Loss: 6.553209095727652e-05, Validation Loss: 5.653727857861668e-05\n",
      "Epoch [21/25], Train Loss: 6.52714297757484e-05, Validation Loss: 5.687004158971831e-05\n",
      "Epoch [21/25], Train Loss: 6.461476732511073e-05, Validation Loss: 5.7074997312156486e-05\n",
      "Epoch [21/25], Train Loss: 5.728437099605799e-05, Validation Loss: 5.679700843757019e-05\n",
      "Epoch [21/25], Train Loss: 5.1885912398574874e-05, Validation Loss: 5.6525950882739076e-05\n",
      "Epoch [21/25], Train Loss: 6.046277849236503e-05, Validation Loss: 5.6637872330611574e-05\n",
      "Epoch [21/25], Train Loss: 6.819492409704253e-05, Validation Loss: 5.680903122993186e-05\n",
      "Epoch [21/25], Train Loss: 6.691045564366505e-05, Validation Loss: 5.6709026587971796e-05\n",
      "Epoch [21/25], Train Loss: 6.873888924019411e-05, Validation Loss: 5.653434224465551e-05\n",
      "Epoch [21/25], Train Loss: 5.128502016304992e-05, Validation Loss: 5.65851318242494e-05\n",
      "Epoch [21/25], Train Loss: 5.048726234235801e-05, Validation Loss: 5.67017942861033e-05\n",
      "Epoch [21/25], Train Loss: 6.161305645946413e-05, Validation Loss: 5.666552654777964e-05\n",
      "Epoch [21/25], Train Loss: 5.353784581529908e-05, Validation Loss: 5.651640118837046e-05\n",
      "Epoch [21/25], Train Loss: 5.561620127991773e-05, Validation Loss: 5.648290583242973e-05\n",
      "Epoch [21/25], Train Loss: 5.015484566683881e-05, Validation Loss: 5.658869728601227e-05\n",
      "Epoch [21/25], Train Loss: 5.455200152937323e-05, Validation Loss: 5.6616647392123316e-05\n",
      "Epoch [21/25], Train Loss: 5.501149280462414e-05, Validation Loss: 5.654270741312454e-05\n",
      "Epoch [21/25], Train Loss: 5.6919299822766334e-05, Validation Loss: 5.6479662210525326e-05\n",
      "Epoch [21/25], Train Loss: 5.6094992032740265e-05, Validation Loss: 5.6510047094585995e-05\n",
      "Epoch [21/25], Train Loss: 5.058094393461943e-05, Validation Loss: 5.654014797376779e-05\n",
      "Epoch [21/25], Train Loss: 4.6761921112192795e-05, Validation Loss: 5.651398532791063e-05\n",
      "Epoch [21/25], Train Loss: 7.13382032699883e-05, Validation Loss: 5.647165744449012e-05\n",
      "Epoch [21/25], Train Loss: 6.285079871304333e-05, Validation Loss: 5.6458886683685704e-05\n",
      "Epoch [21/25], Train Loss: 6.113468407420442e-05, Validation Loss: 5.647732784079077e-05\n",
      "Epoch [21/25], Train Loss: 4.199640534352511e-05, Validation Loss: 5.647874155935521e-05\n",
      "Epoch [21/25], Train Loss: 5.4008090955903754e-05, Validation Loss: 5.644681126189729e-05\n",
      "Epoch [21/25], Train Loss: 5.824494655826129e-05, Validation Loss: 5.6415272653490925e-05\n",
      "Epoch [21/25], Train Loss: 6.325503636617213e-05, Validation Loss: 5.641932342162666e-05\n",
      "Epoch [21/25], Train Loss: 6.315328209893778e-05, Validation Loss: 5.6436319331017636e-05\n",
      "Epoch [21/25], Train Loss: 5.8555553550831974e-05, Validation Loss: 5.6432959778855246e-05\n",
      "Epoch [21/25], Train Loss: 5.9420348407002166e-05, Validation Loss: 5.64032646555764e-05\n",
      "Epoch [21/25], Train Loss: 6.136063893791288e-05, Validation Loss: 5.639222314736496e-05\n",
      "Epoch [21/25], Train Loss: 5.88304792472627e-05, Validation Loss: 5.640580760276256e-05\n",
      "Epoch [21/25], Train Loss: 5.6386652431683615e-05, Validation Loss: 5.641514750701996e-05\n",
      "Epoch [21/25], Train Loss: 7.020746124908328e-05, Validation Loss: 5.642348066127549e-05\n",
      "Epoch [21/25], Train Loss: 6.172549183247611e-05, Validation Loss: 5.6453525273051736e-05\n",
      "Epoch [21/25], Train Loss: 6.53166207484901e-05, Validation Loss: 5.651281414126667e-05\n",
      "Epoch [21/25], Train Loss: 6.229744758456945e-05, Validation Loss: 5.658208877624323e-05\n",
      "Epoch [21/25], Train Loss: 4.516251283348538e-05, Validation Loss: 5.667402971691141e-05\n",
      "Epoch [21/25], Train Loss: 4.9499765736982226e-05, Validation Loss: 5.674389055153976e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Train Loss: 5.922242417000234e-05, Validation Loss: 5.689830625973021e-05\n",
      "Epoch [21/25], Train Loss: 4.6831606596242636e-05, Validation Loss: 5.705291502332936e-05\n",
      "Epoch [21/25], Train Loss: 4.7755322157172486e-05, Validation Loss: 5.730965009812886e-05\n",
      "Epoch [21/25], Train Loss: 5.1896691729780287e-05, Validation Loss: 5.758436163887382e-05\n",
      "Epoch [21/25], Train Loss: 4.903720400761813e-05, Validation Loss: 5.804048923891969e-05\n",
      "Epoch [21/25], Train Loss: 4.651434937841259e-05, Validation Loss: 5.864472962760677e-05\n",
      "Epoch [21/25], Train Loss: 6.202301301527768e-05, Validation Loss: 5.9522654191823675e-05\n",
      "Epoch [21/25], Train Loss: 4.84140073240269e-05, Validation Loss: 6.0457338501388826e-05\n",
      "Epoch [21/25], Train Loss: 5.543052247958258e-05, Validation Loss: 6.173558043277201e-05\n",
      "Epoch [21/25], Train Loss: 5.927245001657866e-05, Validation Loss: 6.306767002873433e-05\n",
      "Epoch [21/25], Train Loss: 7.934918539831415e-05, Validation Loss: 6.434111928683705e-05\n",
      "Epoch [21/25], Train Loss: 7.057766924845055e-05, Validation Loss: 6.524519728069814e-05\n",
      "Epoch [21/25], Train Loss: 6.51344598736614e-05, Validation Loss: 6.568922011259322e-05\n",
      "Epoch [21/25], Train Loss: 7.096058106981218e-05, Validation Loss: 6.499177567699613e-05\n",
      "Epoch [21/25], Train Loss: 6.545999349327758e-05, Validation Loss: 6.334727756135786e-05\n",
      "Epoch [21/25], Train Loss: 6.893306272104383e-05, Validation Loss: 6.087305422018592e-05\n",
      "Epoch [21/25], Train Loss: 5.3344851039582863e-05, Validation Loss: 5.8490421361057086e-05\n",
      "Epoch [21/25], Train Loss: 5.341174255590886e-05, Validation Loss: 5.685496629060556e-05\n",
      "Epoch [21/25], Train Loss: 5.1071336201857775e-05, Validation Loss: 5.6497226614737885e-05\n",
      "Epoch [21/25], Train Loss: 4.971391535946168e-05, Validation Loss: 5.7337249745614824e-05\n",
      "Epoch [21/25], Train Loss: 5.611994492937811e-05, Validation Loss: 5.858354440230566e-05\n",
      "Epoch [21/25], Train Loss: 5.8960504247806966e-05, Validation Loss: 5.9527055903648336e-05\n",
      "Epoch [21/25], Train Loss: 6.444661994464695e-05, Validation Loss: 5.94416359187259e-05\n",
      "Epoch [21/25], Train Loss: 5.607405546470545e-05, Validation Loss: 5.851595099860181e-05\n",
      "Epoch [21/25], Train Loss: 5.5556378356413916e-05, Validation Loss: 5.7382700470043345e-05\n",
      "Epoch [21/25], Train Loss: 5.33425627509132e-05, Validation Loss: 5.67567066658133e-05\n",
      "Epoch [21/25], Train Loss: 6.578156171599403e-05, Validation Loss: 5.675154073590723e-05\n",
      "Epoch [21/25], Train Loss: 6.589497206732631e-05, Validation Loss: 5.724258250362861e-05\n",
      "Epoch [21/25], Train Loss: 5.634158878820017e-05, Validation Loss: 5.7792355558679746e-05\n",
      "Epoch [21/25], Train Loss: 6.073510303394869e-05, Validation Loss: 5.7923816833257054e-05\n",
      "Epoch [21/25], Train Loss: 4.517334309639409e-05, Validation Loss: 5.7641961514794575e-05\n",
      "Epoch [21/25], Train Loss: 5.642234464175999e-05, Validation Loss: 5.706971011629018e-05\n",
      "Epoch [21/25], Train Loss: 5.6034747103694826e-05, Validation Loss: 5.6591037719044834e-05\n",
      "Epoch [22/25], Train Loss: 7.806395296938717e-05, Validation Loss: 5.6494433859673636e-05\n",
      "Epoch [22/25], Train Loss: 5.8467561757424846e-05, Validation Loss: 5.670917186459216e-05\n",
      "Epoch [22/25], Train Loss: 6.2438593886327e-05, Validation Loss: 5.700563536568855e-05\n",
      "Epoch [22/25], Train Loss: 4.1345920180901885e-05, Validation Loss: 5.707662542893862e-05\n",
      "Epoch [22/25], Train Loss: 6.815960659878328e-05, Validation Loss: 5.689754567962761e-05\n",
      "Epoch [22/25], Train Loss: 5.57046769245062e-05, Validation Loss: 5.6580936022025226e-05\n",
      "Epoch [22/25], Train Loss: 5.770973439211957e-05, Validation Loss: 5.6410625256830825e-05\n",
      "Epoch [22/25], Train Loss: 6.405681779142469e-05, Validation Loss: 5.6431092040535684e-05\n",
      "Epoch [22/25], Train Loss: 5.5407934269169345e-05, Validation Loss: 5.6594227741394815e-05\n",
      "Epoch [22/25], Train Loss: 5.314053487381898e-05, Validation Loss: 5.680433120384502e-05\n",
      "Epoch [22/25], Train Loss: 5.8965695643564686e-05, Validation Loss: 5.687777520506643e-05\n",
      "Epoch [22/25], Train Loss: 5.7093835494015366e-05, Validation Loss: 5.686485019396059e-05\n",
      "Epoch [22/25], Train Loss: 6.098768062656745e-05, Validation Loss: 5.679302630596794e-05\n",
      "Epoch [22/25], Train Loss: 5.543859151657671e-05, Validation Loss: 5.6803012557793406e-05\n",
      "Epoch [22/25], Train Loss: 6.973440031288192e-05, Validation Loss: 5.691342424446096e-05\n",
      "Epoch [22/25], Train Loss: 6.272988684941083e-05, Validation Loss: 5.716659458509336e-05\n",
      "Epoch [22/25], Train Loss: 5.966207754681818e-05, Validation Loss: 5.754580415668897e-05\n",
      "Epoch [22/25], Train Loss: 6.969690730329603e-05, Validation Loss: 5.790706879148881e-05\n",
      "Epoch [22/25], Train Loss: 5.2106668590568006e-05, Validation Loss: 5.8388398125922926e-05\n",
      "Epoch [22/25], Train Loss: 5.1560487918322906e-05, Validation Loss: 5.884385779305982e-05\n",
      "Epoch [22/25], Train Loss: 6.275848863879219e-05, Validation Loss: 5.947142902490062e-05\n",
      "Epoch [22/25], Train Loss: 5.956089444225654e-05, Validation Loss: 6.029107219850023e-05\n",
      "Epoch [22/25], Train Loss: 6.358257087413222e-05, Validation Loss: 6.130928013590165e-05\n",
      "Epoch [22/25], Train Loss: 6.703053077217191e-05, Validation Loss: 6.258573921513744e-05\n",
      "Epoch [22/25], Train Loss: 6.0184513131389394e-05, Validation Loss: 6.40750792323767e-05\n",
      "Epoch [22/25], Train Loss: 6.372616189764813e-05, Validation Loss: 6.547871501728271e-05\n",
      "Epoch [22/25], Train Loss: 6.564986688317731e-05, Validation Loss: 6.659718225516068e-05\n",
      "Epoch [22/25], Train Loss: 6.751127511961386e-05, Validation Loss: 6.687408846725399e-05\n",
      "Epoch [22/25], Train Loss: 6.547175871673971e-05, Validation Loss: 6.62396569775107e-05\n",
      "Epoch [22/25], Train Loss: 6.82651370880194e-05, Validation Loss: 6.440740035031922e-05\n",
      "Epoch [22/25], Train Loss: 6.772440247004852e-05, Validation Loss: 6.188493668256949e-05\n",
      "Epoch [22/25], Train Loss: 6.144816870801151e-05, Validation Loss: 5.9523882616000874e-05\n",
      "Epoch [22/25], Train Loss: 5.938841059105471e-05, Validation Loss: 5.818076654880618e-05\n",
      "Epoch [22/25], Train Loss: 6.206708349054679e-05, Validation Loss: 5.817103495549721e-05\n",
      "Epoch [22/25], Train Loss: 6.130130350356922e-05, Validation Loss: 5.9158108585203686e-05\n",
      "Epoch [22/25], Train Loss: 5.264509309199639e-05, Validation Loss: 6.009057348516459e-05\n",
      "Epoch [22/25], Train Loss: 4.519016874837689e-05, Validation Loss: 6.010398719809018e-05\n",
      "Epoch [22/25], Train Loss: 4.8650479584466666e-05, Validation Loss: 5.9129032160853966e-05\n",
      "Epoch [22/25], Train Loss: 4.762594835483469e-05, Validation Loss: 5.763114628886494e-05\n",
      "Epoch [22/25], Train Loss: 5.320293712429702e-05, Validation Loss: 5.648747731659872e-05\n",
      "Epoch [22/25], Train Loss: 5.548220360651612e-05, Validation Loss: 5.635101624648087e-05\n",
      "Epoch [22/25], Train Loss: 5.90455238125287e-05, Validation Loss: 5.705596850020811e-05\n",
      "Epoch [22/25], Train Loss: 5.7198474678443745e-05, Validation Loss: 5.788483686046675e-05\n",
      "Epoch [22/25], Train Loss: 5.54181715415325e-05, Validation Loss: 5.811474305422356e-05\n",
      "Epoch [22/25], Train Loss: 7.345325138885528e-05, Validation Loss: 5.757213511969894e-05\n",
      "Epoch [22/25], Train Loss: 6.591573765035719e-05, Validation Loss: 5.677319689615009e-05\n",
      "Epoch [22/25], Train Loss: 6.173505244078115e-05, Validation Loss: 5.6275103027777125e-05\n",
      "Epoch [22/25], Train Loss: 5.2695129852509126e-05, Validation Loss: 5.631303113962834e-05\n",
      "Epoch [22/25], Train Loss: 5.257354132481851e-05, Validation Loss: 5.66853312193416e-05\n",
      "Epoch [22/25], Train Loss: 4.549188452074304e-05, Validation Loss: 5.700636465917341e-05\n",
      "Epoch [22/25], Train Loss: 6.620167550863698e-05, Validation Loss: 5.6967219522145265e-05\n",
      "Epoch [22/25], Train Loss: 6.431861402234063e-05, Validation Loss: 5.665409601836776e-05\n",
      "Epoch [22/25], Train Loss: 5.6686443713260815e-05, Validation Loss: 5.637943759211339e-05\n",
      "Epoch [22/25], Train Loss: 5.052632332080975e-05, Validation Loss: 5.631568007326375e-05\n",
      "Epoch [22/25], Train Loss: 6.0891172324772924e-05, Validation Loss: 5.646686937931615e-05\n",
      "Epoch [22/25], Train Loss: 5.3370255045592785e-05, Validation Loss: 5.6650518430008864e-05\n",
      "Epoch [22/25], Train Loss: 5.247399894869886e-05, Validation Loss: 5.671844677029488e-05\n",
      "Epoch [22/25], Train Loss: 7.096976332832128e-05, Validation Loss: 5.657385481754318e-05\n",
      "Epoch [22/25], Train Loss: 5.481990228872746e-05, Validation Loss: 5.635645599492515e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25], Train Loss: 5.314150621416047e-05, Validation Loss: 5.616470104238639e-05\n",
      "Epoch [22/25], Train Loss: 4.9865055189002305e-05, Validation Loss: 5.608648765094889e-05\n",
      "Epoch [22/25], Train Loss: 5.134781531523913e-05, Validation Loss: 5.612839013338089e-05\n",
      "Epoch [22/25], Train Loss: 5.096265158499591e-05, Validation Loss: 5.623487159027718e-05\n",
      "Epoch [22/25], Train Loss: 5.156159750185907e-05, Validation Loss: 5.631781556682351e-05\n",
      "Epoch [22/25], Train Loss: 5.848355431226082e-05, Validation Loss: 5.632748749728004e-05\n",
      "Epoch [22/25], Train Loss: 4.940255166729912e-05, Validation Loss: 5.62651184736751e-05\n",
      "Epoch [22/25], Train Loss: 7.318790449062362e-05, Validation Loss: 5.6187098137646294e-05\n",
      "Epoch [22/25], Train Loss: 6.168452091515064e-05, Validation Loss: 5.616146396884384e-05\n",
      "Epoch [22/25], Train Loss: 6.005328395985998e-05, Validation Loss: 5.618483531482828e-05\n",
      "Epoch [22/25], Train Loss: 5.8150686527369544e-05, Validation Loss: 5.6207155770001314e-05\n",
      "Epoch [22/25], Train Loss: 5.4524713050341234e-05, Validation Loss: 5.622178092986966e-05\n",
      "Epoch [22/25], Train Loss: 6.776575901312754e-05, Validation Loss: 5.620353088791793e-05\n",
      "Epoch [22/25], Train Loss: 4.970698864781298e-05, Validation Loss: 5.614796027657576e-05\n",
      "Epoch [22/25], Train Loss: 6.90975139150396e-05, Validation Loss: 5.608842863390843e-05\n",
      "Epoch [22/25], Train Loss: 5.762492583016865e-05, Validation Loss: 5.60668071557302e-05\n",
      "Epoch [22/25], Train Loss: 5.653408879879862e-05, Validation Loss: 5.609284902069097e-05\n",
      "Epoch [22/25], Train Loss: 5.9294208767823875e-05, Validation Loss: 5.615890355935941e-05\n",
      "Epoch [22/25], Train Loss: 5.317780960467644e-05, Validation Loss: 5.62293110609365e-05\n",
      "Epoch [22/25], Train Loss: 5.346673060557805e-05, Validation Loss: 5.627707626748209e-05\n",
      "Epoch [22/25], Train Loss: 6.260660302359611e-05, Validation Loss: 5.6278174452017995e-05\n",
      "Epoch [22/25], Train Loss: 4.906417598249391e-05, Validation Loss: 5.6284220045199616e-05\n",
      "Epoch [22/25], Train Loss: 5.4441363317891955e-05, Validation Loss: 5.6270905770361426e-05\n",
      "Epoch [22/25], Train Loss: 5.793425225419924e-05, Validation Loss: 5.626239168729323e-05\n",
      "Epoch [22/25], Train Loss: 6.524079071823508e-05, Validation Loss: 5.625781098691126e-05\n",
      "Epoch [22/25], Train Loss: 5.212454198044725e-05, Validation Loss: 5.627123706896479e-05\n",
      "Epoch [22/25], Train Loss: 7.020176417427137e-05, Validation Loss: 5.625521613789412e-05\n",
      "Epoch [22/25], Train Loss: 5.3728035709355026e-05, Validation Loss: 5.628215343070527e-05\n",
      "Epoch [22/25], Train Loss: 6.262108945520595e-05, Validation Loss: 5.629177467199042e-05\n",
      "Epoch [22/25], Train Loss: 5.908424282097258e-05, Validation Loss: 5.6303880652800825e-05\n",
      "Epoch [22/25], Train Loss: 4.5748303818982095e-05, Validation Loss: 5.631030144286342e-05\n",
      "Epoch [22/25], Train Loss: 6.399094127118587e-05, Validation Loss: 5.6316407911557086e-05\n",
      "Epoch [22/25], Train Loss: 6.791054329369217e-05, Validation Loss: 5.634921156646063e-05\n",
      "Epoch [22/25], Train Loss: 4.4998902012594044e-05, Validation Loss: 5.6389499513898043e-05\n",
      "Epoch [22/25], Train Loss: 5.295987648423761e-05, Validation Loss: 5.646686962184807e-05\n",
      "Epoch [22/25], Train Loss: 6.751351611455902e-05, Validation Loss: 5.6599631352582944e-05\n",
      "Epoch [22/25], Train Loss: 7.182643457781523e-05, Validation Loss: 5.6781877841179566e-05\n",
      "Epoch [22/25], Train Loss: 6.680037768092006e-05, Validation Loss: 5.6981434803068017e-05\n",
      "Epoch [22/25], Train Loss: 3.7185011024121195e-05, Validation Loss: 5.730006499409986e-05\n",
      "Epoch [22/25], Train Loss: 5.926105222897604e-05, Validation Loss: 5.773267451634941e-05\n",
      "Epoch [22/25], Train Loss: 6.449808279285207e-05, Validation Loss: 5.818628924316727e-05\n",
      "Epoch [22/25], Train Loss: 6.161317287478596e-05, Validation Loss: 5.8876901069500796e-05\n",
      "Epoch [22/25], Train Loss: 6.321533874142915e-05, Validation Loss: 5.961607797265363e-05\n",
      "Epoch [22/25], Train Loss: 5.642382166115567e-05, Validation Loss: 6.0659028774049756e-05\n",
      "Epoch [22/25], Train Loss: 6.680213118670508e-05, Validation Loss: 6.17572120972909e-05\n",
      "Epoch [22/25], Train Loss: 5.965635136817582e-05, Validation Loss: 6.298784428508953e-05\n",
      "Epoch [22/25], Train Loss: 5.6816785217961296e-05, Validation Loss: 6.38722662794559e-05\n",
      "Epoch [22/25], Train Loss: 7.413763523800299e-05, Validation Loss: 6.432943700929172e-05\n",
      "Epoch [22/25], Train Loss: 6.254053732845932e-05, Validation Loss: 6.411131350129533e-05\n",
      "Epoch [22/25], Train Loss: 6.996516458457336e-05, Validation Loss: 6.316110423843687e-05\n",
      "Epoch [22/25], Train Loss: 7.133534381864592e-05, Validation Loss: 6.118955934653059e-05\n",
      "Epoch [22/25], Train Loss: 6.460391887230799e-05, Validation Loss: 5.919863469898701e-05\n",
      "Epoch [22/25], Train Loss: 5.091464481665753e-05, Validation Loss: 5.7829269887103386e-05\n",
      "Epoch [22/25], Train Loss: 7.032928260741755e-05, Validation Loss: 5.745012822444551e-05\n",
      "Epoch [22/25], Train Loss: 6.227521225810051e-05, Validation Loss: 5.81084886410584e-05\n",
      "Epoch [22/25], Train Loss: 5.6284367019543424e-05, Validation Loss: 5.92379248701036e-05\n",
      "Epoch [22/25], Train Loss: 6.635064346482977e-05, Validation Loss: 6.0175392233456176e-05\n",
      "Epoch [22/25], Train Loss: 6.046731868991628e-05, Validation Loss: 6.026126478294221e-05\n",
      "Epoch [22/25], Train Loss: 5.093583604320884e-05, Validation Loss: 5.9958075144095344e-05\n",
      "Epoch [22/25], Train Loss: 6.003677117405459e-05, Validation Loss: 5.9331836382625625e-05\n",
      "Epoch [22/25], Train Loss: 6.0211445088498294e-05, Validation Loss: 5.906118773661243e-05\n",
      "Epoch [22/25], Train Loss: 5.14161292812787e-05, Validation Loss: 5.922032432863489e-05\n",
      "Epoch [22/25], Train Loss: 5.711034464184195e-05, Validation Loss: 5.9821543739720555e-05\n",
      "Epoch [22/25], Train Loss: 6.294385821092874e-05, Validation Loss: 6.0316033583755294e-05\n",
      "Epoch [22/25], Train Loss: 5.2874460379825905e-05, Validation Loss: 6.035052574588917e-05\n",
      "Epoch [22/25], Train Loss: 5.991537182126194e-05, Validation Loss: 5.972731378278695e-05\n",
      "Epoch [22/25], Train Loss: 5.4627485951641575e-05, Validation Loss: 5.8740098029375074e-05\n",
      "Epoch [22/25], Train Loss: 6.231278530322015e-05, Validation Loss: 5.772956671232047e-05\n",
      "Epoch [22/25], Train Loss: 6.782159471185878e-05, Validation Loss: 5.7000354718184096e-05\n",
      "Epoch [22/25], Train Loss: 4.740278018289246e-05, Validation Loss: 5.669951012047628e-05\n",
      "Epoch [22/25], Train Loss: 6.329391180770472e-05, Validation Loss: 5.667816731147468e-05\n",
      "Epoch [22/25], Train Loss: 5.805973705719225e-05, Validation Loss: 5.6659137286866704e-05\n",
      "Epoch [22/25], Train Loss: 5.371503357309848e-05, Validation Loss: 5.657199265745779e-05\n",
      "Epoch [22/25], Train Loss: 5.4641681344946846e-05, Validation Loss: 5.645026612910442e-05\n",
      "Epoch [22/25], Train Loss: 4.899324267171323e-05, Validation Loss: 5.635132547467947e-05\n",
      "Epoch [23/25], Train Loss: 6.314791971817613e-05, Validation Loss: 5.64069062723623e-05\n",
      "Epoch [23/25], Train Loss: 6.384189327945933e-05, Validation Loss: 5.655983501734833e-05\n",
      "Epoch [23/25], Train Loss: 5.5057818826753646e-05, Validation Loss: 5.6775130360620096e-05\n",
      "Epoch [23/25], Train Loss: 6.615752499783412e-05, Validation Loss: 5.683877922516937e-05\n",
      "Epoch [23/25], Train Loss: 4.8365287511842325e-05, Validation Loss: 5.670111956230054e-05\n",
      "Epoch [23/25], Train Loss: 5.2041134040337056e-05, Validation Loss: 5.640072631649673e-05\n",
      "Epoch [23/25], Train Loss: 5.408030847320333e-05, Validation Loss: 5.613915224481995e-05\n",
      "Epoch [23/25], Train Loss: 5.072884960100055e-05, Validation Loss: 5.599109402586085e-05\n",
      "Epoch [23/25], Train Loss: 5.057387170381844e-05, Validation Loss: 5.597893687081523e-05\n",
      "Epoch [23/25], Train Loss: 4.9220765504287556e-05, Validation Loss: 5.605051240612132e-05\n",
      "Epoch [23/25], Train Loss: 5.9833382692886516e-05, Validation Loss: 5.612116801785305e-05\n",
      "Epoch [23/25], Train Loss: 6.46170083200559e-05, Validation Loss: 5.616713751805946e-05\n",
      "Epoch [23/25], Train Loss: 4.559776061796583e-05, Validation Loss: 5.614842787811843e-05\n",
      "Epoch [23/25], Train Loss: 5.6539523939136416e-05, Validation Loss: 5.612046322009216e-05\n",
      "Epoch [23/25], Train Loss: 5.456729559227824e-05, Validation Loss: 5.612541523684437e-05\n",
      "Epoch [23/25], Train Loss: 4.81576171296183e-05, Validation Loss: 5.619201959537652e-05\n",
      "Epoch [23/25], Train Loss: 5.207184949540533e-05, Validation Loss: 5.627880139703241e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Train Loss: 5.831519956700504e-05, Validation Loss: 5.6368719621483855e-05\n",
      "Epoch [23/25], Train Loss: 6.211028812685981e-05, Validation Loss: 5.641555253532715e-05\n",
      "Epoch [23/25], Train Loss: 5.7285713410237804e-05, Validation Loss: 5.642435086580614e-05\n",
      "Epoch [23/25], Train Loss: 5.0128321163356304e-05, Validation Loss: 5.642612134882559e-05\n",
      "Epoch [23/25], Train Loss: 6.285143172135577e-05, Validation Loss: 5.644552802550606e-05\n",
      "Epoch [23/25], Train Loss: 5.7881490647559986e-05, Validation Loss: 5.649311909413276e-05\n",
      "Epoch [23/25], Train Loss: 5.897306255064905e-05, Validation Loss: 5.6619812676217406e-05\n",
      "Epoch [23/25], Train Loss: 6.208736886037514e-05, Validation Loss: 5.6854742918706806e-05\n",
      "Epoch [23/25], Train Loss: 6.551487604156137e-05, Validation Loss: 5.708791747262391e-05\n",
      "Epoch [23/25], Train Loss: 5.011964094592258e-05, Validation Loss: 5.737235599857134e-05\n",
      "Epoch [23/25], Train Loss: 4.614489444065839e-05, Validation Loss: 5.7786161293430874e-05\n",
      "Epoch [23/25], Train Loss: 6.28547859378159e-05, Validation Loss: 5.824337737673583e-05\n",
      "Epoch [23/25], Train Loss: 6.585631490452215e-05, Validation Loss: 5.885818488119791e-05\n",
      "Epoch [23/25], Train Loss: 6.177291652420536e-05, Validation Loss: 5.958321974806798e-05\n",
      "Epoch [23/25], Train Loss: 6.487193604698405e-05, Validation Loss: 6.050233811644527e-05\n",
      "Epoch [23/25], Train Loss: 5.762441287515685e-05, Validation Loss: 6.147985550342128e-05\n",
      "Epoch [23/25], Train Loss: 5.856662755832076e-05, Validation Loss: 6.252305490003588e-05\n",
      "Epoch [23/25], Train Loss: 5.1987921324325725e-05, Validation Loss: 6.350373344806333e-05\n",
      "Epoch [23/25], Train Loss: 6.976835720706731e-05, Validation Loss: 6.450067933959266e-05\n",
      "Epoch [23/25], Train Loss: 6.306134309852496e-05, Validation Loss: 6.526545403175987e-05\n",
      "Epoch [23/25], Train Loss: 5.8261775848222896e-05, Validation Loss: 6.546152168690848e-05\n",
      "Epoch [23/25], Train Loss: 6.288861914072186e-05, Validation Loss: 6.488143941775585e-05\n",
      "Epoch [23/25], Train Loss: 7.557338540209457e-05, Validation Loss: 6.341384893554884e-05\n",
      "Epoch [23/25], Train Loss: 7.186080620158464e-05, Validation Loss: 6.141298751269156e-05\n",
      "Epoch [23/25], Train Loss: 6.12706207903102e-05, Validation Loss: 5.94458188667583e-05\n",
      "Epoch [23/25], Train Loss: 7.090243889251724e-05, Validation Loss: 5.8145018798920015e-05\n",
      "Epoch [23/25], Train Loss: 5.301404598867521e-05, Validation Loss: 5.79439469826563e-05\n",
      "Epoch [23/25], Train Loss: 6.272671453189105e-05, Validation Loss: 5.8755411979897566e-05\n",
      "Epoch [23/25], Train Loss: 6.005372051731683e-05, Validation Loss: 5.989309574943036e-05\n",
      "Epoch [23/25], Train Loss: 6.115279393270612e-05, Validation Loss: 6.052120806998573e-05\n",
      "Epoch [23/25], Train Loss: 6.494963599834591e-05, Validation Loss: 6.0199271926345926e-05\n",
      "Epoch [23/25], Train Loss: 7.503211236326024e-05, Validation Loss: 5.90787771216128e-05\n",
      "Epoch [23/25], Train Loss: 6.286151619860902e-05, Validation Loss: 5.787871244441097e-05\n",
      "Epoch [23/25], Train Loss: 4.743777390103787e-05, Validation Loss: 5.7125285335738835e-05\n",
      "Epoch [23/25], Train Loss: 5.222889012657106e-05, Validation Loss: 5.711075912889404e-05\n",
      "Epoch [23/25], Train Loss: 5.074279761174694e-05, Validation Loss: 5.759740743087605e-05\n",
      "Epoch [23/25], Train Loss: 5.8521090977592394e-05, Validation Loss: 5.8010553038911895e-05\n",
      "Epoch [23/25], Train Loss: 6.362445128615946e-05, Validation Loss: 5.79962116413905e-05\n",
      "Epoch [23/25], Train Loss: 5.428145232144743e-05, Validation Loss: 5.745163459020356e-05\n",
      "Epoch [23/25], Train Loss: 5.8843332226388156e-05, Validation Loss: 5.670493434687766e-05\n",
      "Epoch [23/25], Train Loss: 5.672929182765074e-05, Validation Loss: 5.614551967786004e-05\n",
      "Epoch [23/25], Train Loss: 4.378513040137477e-05, Validation Loss: 5.594010848047522e-05\n",
      "Epoch [23/25], Train Loss: 5.2655890613095835e-05, Validation Loss: 5.6040004225602993e-05\n",
      "Epoch [23/25], Train Loss: 6.191682041389868e-05, Validation Loss: 5.62248792751537e-05\n",
      "Epoch [23/25], Train Loss: 5.8427285694051534e-05, Validation Loss: 5.6308196265793714e-05\n",
      "Epoch [23/25], Train Loss: 5.784387394669466e-05, Validation Loss: 5.620866286335513e-05\n",
      "Epoch [23/25], Train Loss: 6.203808152349666e-05, Validation Loss: 5.605314436252229e-05\n",
      "Epoch [23/25], Train Loss: 6.540691538248211e-05, Validation Loss: 5.595921247731894e-05\n",
      "Epoch [23/25], Train Loss: 6.12448129686527e-05, Validation Loss: 5.596762760736359e-05\n",
      "Epoch [23/25], Train Loss: 6.388406472979113e-05, Validation Loss: 5.609585229346218e-05\n",
      "Epoch [23/25], Train Loss: 5.9498244809219614e-05, Validation Loss: 5.6228493970896425e-05\n",
      "Epoch [23/25], Train Loss: 5.170428994460963e-05, Validation Loss: 5.6242416273259245e-05\n",
      "Epoch [23/25], Train Loss: 6.0705486248480156e-05, Validation Loss: 5.6164888277029e-05\n",
      "Epoch [23/25], Train Loss: 5.9664049331331626e-05, Validation Loss: 5.6050947750918564e-05\n",
      "Epoch [23/25], Train Loss: 5.624055120279081e-05, Validation Loss: 5.5934350045087436e-05\n",
      "Epoch [23/25], Train Loss: 5.843699545948766e-05, Validation Loss: 5.5927957873791456e-05\n",
      "Epoch [23/25], Train Loss: 5.9885507653234527e-05, Validation Loss: 5.5977646115934474e-05\n",
      "Epoch [23/25], Train Loss: 6.249827129067853e-05, Validation Loss: 5.6008255099489665e-05\n",
      "Epoch [23/25], Train Loss: 6.423243758035824e-05, Validation Loss: 5.6008159299381076e-05\n",
      "Epoch [23/25], Train Loss: 6.290587043622509e-05, Validation Loss: 5.59888011290847e-05\n",
      "Epoch [23/25], Train Loss: 5.741739005316049e-05, Validation Loss: 5.596316550509073e-05\n",
      "Epoch [23/25], Train Loss: 4.8381276428699493e-05, Validation Loss: 5.596890744830792e-05\n",
      "Epoch [23/25], Train Loss: 6.0968388424953446e-05, Validation Loss: 5.600512255720484e-05\n",
      "Epoch [23/25], Train Loss: 5.363968011806719e-05, Validation Loss: 5.605594487860799e-05\n",
      "Epoch [23/25], Train Loss: 6.386769382515922e-05, Validation Loss: 5.6093540721728155e-05\n",
      "Epoch [23/25], Train Loss: 6.520625174744055e-05, Validation Loss: 5.612675910621571e-05\n",
      "Epoch [23/25], Train Loss: 6.566762749571353e-05, Validation Loss: 5.615281115751713e-05\n",
      "Epoch [23/25], Train Loss: 5.504167347680777e-05, Validation Loss: 5.619681978714652e-05\n",
      "Epoch [23/25], Train Loss: 6.138338358141482e-05, Validation Loss: 5.6296736147487536e-05\n",
      "Epoch [23/25], Train Loss: 6.702659447910264e-05, Validation Loss: 5.645548080792651e-05\n",
      "Epoch [23/25], Train Loss: 6.118750025052577e-05, Validation Loss: 5.66388322719528e-05\n",
      "Epoch [23/25], Train Loss: 6.31223592790775e-05, Validation Loss: 5.698339543111312e-05\n",
      "Epoch [23/25], Train Loss: 5.7823224778985605e-05, Validation Loss: 5.7360508556788166e-05\n",
      "Epoch [23/25], Train Loss: 5.322289143805392e-05, Validation Loss: 5.784794921055436e-05\n",
      "Epoch [23/25], Train Loss: 5.2081002650083974e-05, Validation Loss: 5.8454423075697075e-05\n",
      "Epoch [23/25], Train Loss: 4.96707325510215e-05, Validation Loss: 5.9295423125149685e-05\n",
      "Epoch [23/25], Train Loss: 5.20001703989692e-05, Validation Loss: 6.034352336428128e-05\n",
      "Epoch [23/25], Train Loss: 4.391771653899923e-05, Validation Loss: 6.159967912632662e-05\n",
      "Epoch [23/25], Train Loss: 5.2426614274736494e-05, Validation Loss: 6.291356476140209e-05\n",
      "Epoch [23/25], Train Loss: 5.797682752017863e-05, Validation Loss: 6.412130533135496e-05\n",
      "Epoch [23/25], Train Loss: 7.573331822641194e-05, Validation Loss: 6.484093391918577e-05\n",
      "Epoch [23/25], Train Loss: 6.884828326292336e-05, Validation Loss: 6.47869885142427e-05\n",
      "Epoch [23/25], Train Loss: 6.179799675010145e-05, Validation Loss: 6.369705491427642e-05\n",
      "Epoch [23/25], Train Loss: 6.066116475267336e-05, Validation Loss: 6.18001746867473e-05\n",
      "Epoch [23/25], Train Loss: 6.476545240730047e-05, Validation Loss: 5.938351144626116e-05\n",
      "Epoch [23/25], Train Loss: 5.462725675897673e-05, Validation Loss: 5.7323121048587684e-05\n",
      "Epoch [23/25], Train Loss: 5.7762892538448796e-05, Validation Loss: 5.630022642435506e-05\n",
      "Epoch [23/25], Train Loss: 6.489437510026619e-05, Validation Loss: 5.639584681678874e-05\n",
      "Epoch [23/25], Train Loss: 5.4332973377313465e-05, Validation Loss: 5.74065399026343e-05\n",
      "Epoch [23/25], Train Loss: 5.9144826082047075e-05, Validation Loss: 5.847602927436431e-05\n",
      "Epoch [23/25], Train Loss: 6.382678111549467e-05, Validation Loss: 5.908494689113771e-05\n",
      "Epoch [23/25], Train Loss: 7.095102046150714e-05, Validation Loss: 5.8922377502312886e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Train Loss: 5.6327811762457713e-05, Validation Loss: 5.824343000616257e-05\n",
      "Epoch [23/25], Train Loss: 6.78987562423572e-05, Validation Loss: 5.732970482010084e-05\n",
      "Epoch [23/25], Train Loss: 6.275223131524399e-05, Validation Loss: 5.675878613449944e-05\n",
      "Epoch [23/25], Train Loss: 5.869293454452418e-05, Validation Loss: 5.677165706098701e-05\n",
      "Epoch [23/25], Train Loss: 5.3720457799499854e-05, Validation Loss: 5.72042884111094e-05\n",
      "Epoch [23/25], Train Loss: 5.9006437368225306e-05, Validation Loss: 5.762322810672534e-05\n",
      "Epoch [23/25], Train Loss: 4.901441570837051e-05, Validation Loss: 5.7747521592924994e-05\n",
      "Epoch [23/25], Train Loss: 6.0215072153368965e-05, Validation Loss: 5.746435417677276e-05\n",
      "Epoch [23/25], Train Loss: 6.239394133444875e-05, Validation Loss: 5.695621463625381e-05\n",
      "Epoch [23/25], Train Loss: 6.823435251135379e-05, Validation Loss: 5.650981135355929e-05\n",
      "Epoch [23/25], Train Loss: 5.762502405559644e-05, Validation Loss: 5.6401642602092276e-05\n",
      "Epoch [23/25], Train Loss: 6.428499182220548e-05, Validation Loss: 5.65023966676866e-05\n",
      "Epoch [23/25], Train Loss: 4.515000182436779e-05, Validation Loss: 5.671148367885811e-05\n",
      "Epoch [23/25], Train Loss: 6.366756133502349e-05, Validation Loss: 5.67786606552545e-05\n",
      "Epoch [23/25], Train Loss: 4.584764610626735e-05, Validation Loss: 5.66644373369248e-05\n",
      "Epoch [23/25], Train Loss: 4.8167872591875494e-05, Validation Loss: 5.638798174913973e-05\n",
      "Epoch [23/25], Train Loss: 5.5895561672514305e-05, Validation Loss: 5.6100346409948545e-05\n",
      "Epoch [23/25], Train Loss: 6.26972469035536e-05, Validation Loss: 5.592419499104532e-05\n",
      "Epoch [23/25], Train Loss: 4.754805195261724e-05, Validation Loss: 5.5926935116682824e-05\n",
      "Epoch [23/25], Train Loss: 4.6240409574238583e-05, Validation Loss: 5.6030627213961755e-05\n",
      "Epoch [23/25], Train Loss: 5.6754706747597083e-05, Validation Loss: 5.612211486247058e-05\n",
      "Epoch [23/25], Train Loss: 7.804478809703141e-05, Validation Loss: 5.614863985101692e-05\n",
      "Epoch [23/25], Train Loss: 6.393802323145792e-05, Validation Loss: 5.613934627035633e-05\n",
      "Epoch [23/25], Train Loss: 5.706558295059949e-05, Validation Loss: 5.608071078313515e-05\n",
      "Epoch [23/25], Train Loss: 4.8666941438568756e-05, Validation Loss: 5.5990792801215625e-05\n",
      "Epoch [24/25], Train Loss: 5.700877227354795e-05, Validation Loss: 5.598615995647075e-05\n",
      "Epoch [24/25], Train Loss: 6.140796176623553e-05, Validation Loss: 5.603281776226746e-05\n",
      "Epoch [24/25], Train Loss: 6.563453644048423e-05, Validation Loss: 5.612075013535408e-05\n",
      "Epoch [24/25], Train Loss: 4.448239633347839e-05, Validation Loss: 5.622464765716965e-05\n",
      "Epoch [24/25], Train Loss: 4.352962059783749e-05, Validation Loss: 5.6310709624085575e-05\n",
      "Epoch [24/25], Train Loss: 5.5870055803097785e-05, Validation Loss: 5.6348117262435456e-05\n",
      "Epoch [24/25], Train Loss: 5.936427623964846e-05, Validation Loss: 5.638683360302821e-05\n",
      "Epoch [24/25], Train Loss: 5.200328087084927e-05, Validation Loss: 5.639908849843778e-05\n",
      "Epoch [24/25], Train Loss: 5.9808466176036745e-05, Validation Loss: 5.647081779898144e-05\n",
      "Epoch [24/25], Train Loss: 6.163291982375085e-05, Validation Loss: 5.6579084533344336e-05\n",
      "Epoch [24/25], Train Loss: 5.884423808311112e-05, Validation Loss: 5.671012550010346e-05\n",
      "Epoch [24/25], Train Loss: 6.41651131445542e-05, Validation Loss: 5.6821508527112506e-05\n",
      "Epoch [24/25], Train Loss: 5.906639853492379e-05, Validation Loss: 5.7070043597680825e-05\n",
      "Epoch [24/25], Train Loss: 5.357255940907635e-05, Validation Loss: 5.7266122894361615e-05\n",
      "Epoch [24/25], Train Loss: 5.40562832611613e-05, Validation Loss: 5.747386991667251e-05\n",
      "Epoch [24/25], Train Loss: 7.833870040485635e-05, Validation Loss: 5.763791802261646e-05\n",
      "Epoch [24/25], Train Loss: 5.02486145705916e-05, Validation Loss: 5.777220091355654e-05\n",
      "Epoch [24/25], Train Loss: 5.4781885410193354e-05, Validation Loss: 5.784797346374641e-05\n",
      "Epoch [24/25], Train Loss: 4.810581594938412e-05, Validation Loss: 5.799599190747055e-05\n",
      "Epoch [24/25], Train Loss: 5.619619332719594e-05, Validation Loss: 5.808112036902458e-05\n",
      "Epoch [24/25], Train Loss: 4.356831414042972e-05, Validation Loss: 5.810169629209364e-05\n",
      "Epoch [24/25], Train Loss: 5.282887286739424e-05, Validation Loss: 5.801342849736102e-05\n",
      "Epoch [24/25], Train Loss: 7.324034231714904e-05, Validation Loss: 5.787094050901942e-05\n",
      "Epoch [24/25], Train Loss: 7.111388549674302e-05, Validation Loss: 5.76018161761264e-05\n",
      "Epoch [24/25], Train Loss: 5.5252174206543714e-05, Validation Loss: 5.7330707689591995e-05\n",
      "Epoch [24/25], Train Loss: 4.6602279326179996e-05, Validation Loss: 5.703833642958974e-05\n",
      "Epoch [24/25], Train Loss: 6.73342146910727e-05, Validation Loss: 5.680674245619836e-05\n",
      "Epoch [24/25], Train Loss: 5.386109842220321e-05, Validation Loss: 5.657524767836245e-05\n",
      "Epoch [24/25], Train Loss: 4.5981032599229366e-05, Validation Loss: 5.640369078416067e-05\n",
      "Epoch [24/25], Train Loss: 6.333182682283223e-05, Validation Loss: 5.631860258290544e-05\n",
      "Epoch [24/25], Train Loss: 6.326292350422591e-05, Validation Loss: 5.636861654541766e-05\n",
      "Epoch [24/25], Train Loss: 4.732668094220571e-05, Validation Loss: 5.650815098003174e-05\n",
      "Epoch [24/25], Train Loss: 6.115152791608125e-05, Validation Loss: 5.673632986145094e-05\n",
      "Epoch [24/25], Train Loss: 7.247328176163137e-05, Validation Loss: 5.702130583813414e-05\n",
      "Epoch [24/25], Train Loss: 6.710769230267033e-05, Validation Loss: 5.7301749863351384e-05\n",
      "Epoch [24/25], Train Loss: 4.5514872908825055e-05, Validation Loss: 5.765883421796995e-05\n",
      "Epoch [24/25], Train Loss: 6.414351082639769e-05, Validation Loss: 5.8144761472552396e-05\n",
      "Epoch [24/25], Train Loss: 5.4391515732277185e-05, Validation Loss: 5.8815182516506566e-05\n",
      "Epoch [24/25], Train Loss: 5.704663271899335e-05, Validation Loss: 5.9520334131472435e-05\n",
      "Epoch [24/25], Train Loss: 5.7301123888464645e-05, Validation Loss: 6.041226151864976e-05\n",
      "Epoch [24/25], Train Loss: 6.250930891837925e-05, Validation Loss: 6.156978391421337e-05\n",
      "Epoch [24/25], Train Loss: 6.413702067220584e-05, Validation Loss: 6.280693511750239e-05\n",
      "Epoch [24/25], Train Loss: 7.512458978453651e-05, Validation Loss: 6.414897676828938e-05\n",
      "Epoch [24/25], Train Loss: 5.638607399305329e-05, Validation Loss: 6.546676134651837e-05\n",
      "Epoch [24/25], Train Loss: 7.604351412737742e-05, Validation Loss: 6.674089575729644e-05\n",
      "Epoch [24/25], Train Loss: 7.533530879300088e-05, Validation Loss: 6.788818233568842e-05\n",
      "Epoch [24/25], Train Loss: 5.699234316125512e-05, Validation Loss: 6.877297128085046e-05\n",
      "Epoch [24/25], Train Loss: 7.429592369589955e-05, Validation Loss: 6.883634487167e-05\n",
      "Epoch [24/25], Train Loss: 7.34138666302897e-05, Validation Loss: 6.797415359566609e-05\n",
      "Epoch [24/25], Train Loss: 6.864436727482826e-05, Validation Loss: 6.601696513826027e-05\n",
      "Epoch [24/25], Train Loss: 6.767771992599592e-05, Validation Loss: 6.352734174773408e-05\n",
      "Epoch [24/25], Train Loss: 5.984980452922173e-05, Validation Loss: 6.127530893233295e-05\n",
      "Epoch [24/25], Train Loss: 4.571113095153123e-05, Validation Loss: 5.961033069373419e-05\n",
      "Epoch [24/25], Train Loss: 5.0063925300491974e-05, Validation Loss: 5.882701977194908e-05\n",
      "Epoch [24/25], Train Loss: 5.6911703723017126e-05, Validation Loss: 5.8646672550821675e-05\n",
      "Epoch [24/25], Train Loss: 6.033942190697417e-05, Validation Loss: 5.884938533805932e-05\n",
      "Epoch [24/25], Train Loss: 5.3292398661142215e-05, Validation Loss: 5.8874858708198494e-05\n",
      "Epoch [24/25], Train Loss: 6.970363028813154e-05, Validation Loss: 5.8391791632554184e-05\n",
      "Epoch [24/25], Train Loss: 5.2478852012427524e-05, Validation Loss: 5.780191980496359e-05\n",
      "Epoch [24/25], Train Loss: 6.606130045838654e-05, Validation Loss: 5.7394035441878564e-05\n",
      "Epoch [24/25], Train Loss: 7.054959860397503e-05, Validation Loss: 5.7190766286415357e-05\n",
      "Epoch [24/25], Train Loss: 4.70712038804777e-05, Validation Loss: 5.715454559928427e-05\n",
      "Epoch [24/25], Train Loss: 6.808832404203713e-05, Validation Loss: 5.698304764033916e-05\n",
      "Epoch [24/25], Train Loss: 5.93636796111241e-05, Validation Loss: 5.6728929970025395e-05\n",
      "Epoch [24/25], Train Loss: 4.599337262334302e-05, Validation Loss: 5.6658091731757544e-05\n",
      "Epoch [24/25], Train Loss: 5.339807103155181e-05, Validation Loss: 5.6795980587291224e-05\n",
      "Epoch [24/25], Train Loss: 7.397788431262597e-05, Validation Loss: 5.6839839817257595e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Train Loss: 6.850996578577906e-05, Validation Loss: 5.669467524664166e-05\n",
      "Epoch [24/25], Train Loss: 4.463081495487131e-05, Validation Loss: 5.633985468496879e-05\n",
      "Epoch [24/25], Train Loss: 6.012902667862363e-05, Validation Loss: 5.5985793490738915e-05\n",
      "Epoch [24/25], Train Loss: 5.7602515880716965e-05, Validation Loss: 5.5777588810694095e-05\n",
      "Epoch [24/25], Train Loss: 5.094773223390803e-05, Validation Loss: 5.5847700908392045e-05\n",
      "Epoch [24/25], Train Loss: 5.445746501209214e-05, Validation Loss: 5.6084516836563124e-05\n",
      "Epoch [24/25], Train Loss: 4.910232746624388e-05, Validation Loss: 5.624193217954598e-05\n",
      "Epoch [24/25], Train Loss: 5.459988096845336e-05, Validation Loss: 5.6124931385663025e-05\n",
      "Epoch [24/25], Train Loss: 6.546824442921206e-05, Validation Loss: 5.580195938819088e-05\n",
      "Epoch [24/25], Train Loss: 5.223585321800783e-05, Validation Loss: 5.552856091526337e-05\n",
      "Epoch [24/25], Train Loss: 6.24274616711773e-05, Validation Loss: 5.549628379715917e-05\n",
      "Epoch [24/25], Train Loss: 6.323818524833769e-05, Validation Loss: 5.5649746597434085e-05\n",
      "Epoch [24/25], Train Loss: 7.06680366420187e-05, Validation Loss: 5.578052465959142e-05\n",
      "Epoch [24/25], Train Loss: 6.364005821524188e-05, Validation Loss: 5.5785658090220144e-05\n",
      "Epoch [24/25], Train Loss: 6.617738836212084e-05, Validation Loss: 5.5600573250558225e-05\n",
      "Epoch [24/25], Train Loss: 3.573269714252092e-05, Validation Loss: 5.541318896575831e-05\n",
      "Epoch [24/25], Train Loss: 5.513072756002657e-05, Validation Loss: 5.534383017220534e-05\n",
      "Epoch [24/25], Train Loss: 4.920981882605702e-05, Validation Loss: 5.540143344357299e-05\n",
      "Epoch [24/25], Train Loss: 5.4959939006948844e-05, Validation Loss: 5.550754891980129e-05\n",
      "Epoch [24/25], Train Loss: 4.5140128349885345e-05, Validation Loss: 5.557627810048871e-05\n",
      "Epoch [24/25], Train Loss: 5.9832171245943755e-05, Validation Loss: 5.5590934304442875e-05\n",
      "Epoch [24/25], Train Loss: 5.78001890971791e-05, Validation Loss: 5.550135513961626e-05\n",
      "Epoch [24/25], Train Loss: 5.6053726439131424e-05, Validation Loss: 5.539328364344935e-05\n",
      "Epoch [24/25], Train Loss: 6.614324229303747e-05, Validation Loss: 5.534986630664207e-05\n",
      "Epoch [24/25], Train Loss: 6.551485421368852e-05, Validation Loss: 5.534785401929791e-05\n",
      "Epoch [24/25], Train Loss: 6.0124431911390275e-05, Validation Loss: 5.536875542020425e-05\n",
      "Epoch [24/25], Train Loss: 6.045571717550047e-05, Validation Loss: 5.539602231389532e-05\n",
      "Epoch [24/25], Train Loss: 6.336825754260644e-05, Validation Loss: 5.539760507720833e-05\n",
      "Epoch [24/25], Train Loss: 5.7911824114853516e-05, Validation Loss: 5.5371915853659935e-05\n",
      "Epoch [24/25], Train Loss: 7.616119546582922e-05, Validation Loss: 5.533157697451922e-05\n",
      "Epoch [24/25], Train Loss: 6.629392737522721e-05, Validation Loss: 5.529049861555298e-05\n",
      "Epoch [24/25], Train Loss: 5.888856321689673e-05, Validation Loss: 5.528397329423266e-05\n",
      "Epoch [24/25], Train Loss: 5.060750481789e-05, Validation Loss: 5.531198621611111e-05\n",
      "Epoch [24/25], Train Loss: 4.765971243614331e-05, Validation Loss: 5.53612393559888e-05\n",
      "Epoch [24/25], Train Loss: 5.715054430766031e-05, Validation Loss: 5.54374802353171e-05\n",
      "Epoch [24/25], Train Loss: 5.70438351132907e-05, Validation Loss: 5.549724592128769e-05\n",
      "Epoch [24/25], Train Loss: 6.0239202866796404e-05, Validation Loss: 5.554077724809758e-05\n",
      "Epoch [24/25], Train Loss: 5.481185871758498e-05, Validation Loss: 5.555934985750355e-05\n",
      "Epoch [24/25], Train Loss: 4.243643343215808e-05, Validation Loss: 5.555960427348812e-05\n",
      "Epoch [24/25], Train Loss: 6.4845648012124e-05, Validation Loss: 5.558990766682352e-05\n",
      "Epoch [24/25], Train Loss: 5.390956357587129e-05, Validation Loss: 5.5650139014081405e-05\n",
      "Epoch [24/25], Train Loss: 5.329253326635808e-05, Validation Loss: 5.5759413711105785e-05\n",
      "Epoch [24/25], Train Loss: 5.455917926155962e-05, Validation Loss: 5.585390535998158e-05\n",
      "Epoch [24/25], Train Loss: 5.1785424147965387e-05, Validation Loss: 5.5988633296995736e-05\n",
      "Epoch [24/25], Train Loss: 4.423250356921926e-05, Validation Loss: 5.6086405190095924e-05\n",
      "Epoch [24/25], Train Loss: 5.0116548663936555e-05, Validation Loss: 5.625002110415759e-05\n",
      "Epoch [24/25], Train Loss: 5.392539969761856e-05, Validation Loss: 5.6468567830355214e-05\n",
      "Epoch [24/25], Train Loss: 4.043336593895219e-05, Validation Loss: 5.679629321093671e-05\n",
      "Epoch [24/25], Train Loss: 5.763192166341469e-05, Validation Loss: 5.721581522569371e-05\n",
      "Epoch [24/25], Train Loss: 5.939361290074885e-05, Validation Loss: 5.7802910305326805e-05\n",
      "Epoch [24/25], Train Loss: 5.817648707306944e-05, Validation Loss: 5.8456534073532866e-05\n",
      "Epoch [24/25], Train Loss: 6.916901475051418e-05, Validation Loss: 5.923482434203227e-05\n",
      "Epoch [24/25], Train Loss: 6.0678019508486614e-05, Validation Loss: 6.008256896166131e-05\n",
      "Epoch [24/25], Train Loss: 6.433386442949995e-05, Validation Loss: 6.114635010211108e-05\n",
      "Epoch [24/25], Train Loss: 5.0080096116289496e-05, Validation Loss: 6.1967138996503e-05\n",
      "Epoch [24/25], Train Loss: 7.039641059236601e-05, Validation Loss: 6.248936479096301e-05\n",
      "Epoch [24/25], Train Loss: 6.404107989510521e-05, Validation Loss: 6.24289282617004e-05\n",
      "Epoch [24/25], Train Loss: 6.969159585423768e-05, Validation Loss: 6.178304295948086e-05\n",
      "Epoch [24/25], Train Loss: 5.9307567426003516e-05, Validation Loss: 6.04728489027669e-05\n",
      "Epoch [24/25], Train Loss: 6.990751717239618e-05, Validation Loss: 5.880911970355858e-05\n",
      "Epoch [24/25], Train Loss: 5.7783119700616226e-05, Validation Loss: 5.709868006912681e-05\n",
      "Epoch [24/25], Train Loss: 5.137752305017784e-05, Validation Loss: 5.587559353443794e-05\n",
      "Epoch [24/25], Train Loss: 5.813747338834219e-05, Validation Loss: 5.532329669222236e-05\n",
      "Epoch [24/25], Train Loss: 6.749463500455022e-05, Validation Loss: 5.547690767950068e-05\n",
      "Epoch [24/25], Train Loss: 5.7994286180473864e-05, Validation Loss: 5.612127085138733e-05\n",
      "Epoch [24/25], Train Loss: 5.953661457169801e-05, Validation Loss: 5.683061632832202e-05\n",
      "Epoch [24/25], Train Loss: 6.216952169779688e-05, Validation Loss: 5.7374902341204384e-05\n",
      "Epoch [25/25], Train Loss: 6.184267112985253e-05, Validation Loss: 5.742634724204739e-05\n",
      "Epoch [25/25], Train Loss: 5.6898072216426954e-05, Validation Loss: 5.707888970694815e-05\n",
      "Epoch [25/25], Train Loss: 5.99996856180951e-05, Validation Loss: 5.63995614356827e-05\n",
      "Epoch [25/25], Train Loss: 5.597910421784036e-05, Validation Loss: 5.591319156034539e-05\n",
      "Epoch [25/25], Train Loss: 5.791845978819765e-05, Validation Loss: 5.5772964454566436e-05\n",
      "Epoch [25/25], Train Loss: 4.5172724639996886e-05, Validation Loss: 5.610037017807675e-05\n",
      "Epoch [25/25], Train Loss: 4.202641866868362e-05, Validation Loss: 5.6667648459551855e-05\n",
      "Epoch [25/25], Train Loss: 4.76717614219524e-05, Validation Loss: 5.7292849669465794e-05\n",
      "Epoch [25/25], Train Loss: 5.945829252596013e-05, Validation Loss: 5.783939195680432e-05\n",
      "Epoch [25/25], Train Loss: 6.503752229036763e-05, Validation Loss: 5.8310505119152366e-05\n",
      "Epoch [25/25], Train Loss: 6.423287413781509e-05, Validation Loss: 5.8771543748055896e-05\n",
      "Epoch [25/25], Train Loss: 5.986408723401837e-05, Validation Loss: 5.942868713949186e-05\n",
      "Epoch [25/25], Train Loss: 4.9814756494015455e-05, Validation Loss: 6.042172826710157e-05\n",
      "Epoch [25/25], Train Loss: 5.3595667850458995e-05, Validation Loss: 6.183302806069453e-05\n",
      "Epoch [25/25], Train Loss: 6.231851148186252e-05, Validation Loss: 6.337272012994315e-05\n",
      "Epoch [25/25], Train Loss: 6.525284698000178e-05, Validation Loss: 6.485643340662743e-05\n",
      "Epoch [25/25], Train Loss: 6.387415487552062e-05, Validation Loss: 6.542081464431249e-05\n",
      "Epoch [25/25], Train Loss: 6.708990258630365e-05, Validation Loss: 6.49235817642572e-05\n",
      "Epoch [25/25], Train Loss: 6.0981346905464306e-05, Validation Loss: 6.318067462416366e-05\n",
      "Epoch [25/25], Train Loss: 5.65486479899846e-05, Validation Loss: 6.051856544218026e-05\n",
      "Epoch [25/25], Train Loss: 4.9470698286313564e-05, Validation Loss: 5.7652854108406853e-05\n",
      "Epoch [25/25], Train Loss: 6.402490544132888e-05, Validation Loss: 5.579742913444837e-05\n",
      "Epoch [25/25], Train Loss: 6.337094237096608e-05, Validation Loss: 5.526224316175406e-05\n",
      "Epoch [25/25], Train Loss: 6.2553197494708e-05, Validation Loss: 5.592893188198407e-05\n",
      "Epoch [25/25], Train Loss: 5.0589413149282336e-05, Validation Loss: 5.708464692967634e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Train Loss: 5.816968405270018e-05, Validation Loss: 5.7775163683497036e-05\n",
      "Epoch [25/25], Train Loss: 6.152681453386322e-05, Validation Loss: 5.758374196981701e-05\n",
      "Epoch [25/25], Train Loss: 5.983585288049653e-05, Validation Loss: 5.6711343980471914e-05\n",
      "Epoch [25/25], Train Loss: 4.991422247258015e-05, Validation Loss: 5.582578936203693e-05\n",
      "Epoch [25/25], Train Loss: 5.54166836082004e-05, Validation Loss: 5.542446572993261e-05\n",
      "Epoch [25/25], Train Loss: 5.3450625273399055e-05, Validation Loss: 5.555111468614389e-05\n",
      "Epoch [25/25], Train Loss: 6.695427146041766e-05, Validation Loss: 5.59318381419871e-05\n",
      "Epoch [25/25], Train Loss: 6.529378879349679e-05, Validation Loss: 5.614628195568609e-05\n",
      "Epoch [25/25], Train Loss: 6.504383782157674e-05, Validation Loss: 5.606142779773412e-05\n",
      "Epoch [25/25], Train Loss: 4.442527279024944e-05, Validation Loss: 5.567064872593619e-05\n",
      "Epoch [25/25], Train Loss: 6.0230919189052656e-05, Validation Loss: 5.5315386028572296e-05\n",
      "Epoch [25/25], Train Loss: 7.230429764604196e-05, Validation Loss: 5.527248722501099e-05\n",
      "Epoch [25/25], Train Loss: 5.7338176702614874e-05, Validation Loss: 5.551783591120814e-05\n",
      "Epoch [25/25], Train Loss: 6.045443660696037e-05, Validation Loss: 5.5797436167874064e-05\n",
      "Epoch [25/25], Train Loss: 6.343048880808055e-05, Validation Loss: 5.586719125858508e-05\n",
      "Epoch [25/25], Train Loss: 5.65654736419674e-05, Validation Loss: 5.568483344783696e-05\n",
      "Epoch [25/25], Train Loss: 5.237021832726896e-05, Validation Loss: 5.530893079897699e-05\n",
      "Epoch [25/25], Train Loss: 5.5080097808968276e-05, Validation Loss: 5.505635902712432e-05\n",
      "Epoch [25/25], Train Loss: 5.7056571677094325e-05, Validation Loss: 5.508083413587883e-05\n",
      "Epoch [25/25], Train Loss: 4.8197027354035527e-05, Validation Loss: 5.530767642388431e-05\n",
      "Epoch [25/25], Train Loss: 4.56354500784073e-05, Validation Loss: 5.548072779978005e-05\n",
      "Epoch [25/25], Train Loss: 5.181102460483089e-05, Validation Loss: 5.546293299024304e-05\n",
      "Epoch [25/25], Train Loss: 5.9380407037679106e-05, Validation Loss: 5.53146705594069e-05\n",
      "Epoch [25/25], Train Loss: 5.1523864385671914e-05, Validation Loss: 5.51447245622209e-05\n",
      "Epoch [25/25], Train Loss: 5.893950947211124e-05, Validation Loss: 5.503137629906026e-05\n",
      "Epoch [25/25], Train Loss: 5.506156958290376e-05, Validation Loss: 5.504672129366857e-05\n",
      "Epoch [25/25], Train Loss: 4.8273323045577854e-05, Validation Loss: 5.510940633636589e-05\n",
      "Epoch [25/25], Train Loss: 6.276721251197159e-05, Validation Loss: 5.5135213915491474e-05\n",
      "Epoch [25/25], Train Loss: 5.541658902075142e-05, Validation Loss: 5.509468198094207e-05\n",
      "Epoch [25/25], Train Loss: 5.7724289945326746e-05, Validation Loss: 5.502756539499387e-05\n",
      "Epoch [25/25], Train Loss: 5.7886507420334965e-05, Validation Loss: 5.4991402672991775e-05\n",
      "Epoch [25/25], Train Loss: 5.1545615860959515e-05, Validation Loss: 5.502401108969934e-05\n",
      "Epoch [25/25], Train Loss: 5.4546540923183784e-05, Validation Loss: 5.512530794173169e-05\n",
      "Epoch [25/25], Train Loss: 5.8370416809339076e-05, Validation Loss: 5.524783312769917e-05\n",
      "Epoch [25/25], Train Loss: 6.197037146193907e-05, Validation Loss: 5.5316970732140663e-05\n",
      "Epoch [25/25], Train Loss: 5.654921551467851e-05, Validation Loss: 5.5340638694663843e-05\n",
      "Epoch [25/25], Train Loss: 6.143062637420371e-05, Validation Loss: 5.529546979232691e-05\n",
      "Epoch [25/25], Train Loss: 6.140027107903734e-05, Validation Loss: 5.52035783281705e-05\n",
      "Epoch [25/25], Train Loss: 5.169455835130066e-05, Validation Loss: 5.5140185334797325e-05\n",
      "Epoch [25/25], Train Loss: 5.986734322505072e-05, Validation Loss: 5.513291010477891e-05\n",
      "Epoch [25/25], Train Loss: 6.479582953033969e-05, Validation Loss: 5.51725817786064e-05\n",
      "Epoch [25/25], Train Loss: 5.8073677791981027e-05, Validation Loss: 5.525790135531376e-05\n",
      "Epoch [25/25], Train Loss: 5.708122262149118e-05, Validation Loss: 5.535036956037705e-05\n",
      "Epoch [25/25], Train Loss: 5.19261957379058e-05, Validation Loss: 5.54081256268546e-05\n",
      "Epoch [25/25], Train Loss: 5.568900451180525e-05, Validation Loss: 5.5427231321421765e-05\n",
      "Epoch [25/25], Train Loss: 4.939430073136464e-05, Validation Loss: 5.5463619598109894e-05\n",
      "Epoch [25/25], Train Loss: 6.789481994928792e-05, Validation Loss: 5.5538981056694564e-05\n",
      "Epoch [25/25], Train Loss: 5.8011621149489656e-05, Validation Loss: 5.568401975324378e-05\n",
      "Epoch [25/25], Train Loss: 6.147276144474745e-05, Validation Loss: 5.589490368341406e-05\n",
      "Epoch [25/25], Train Loss: 6.356392987072468e-05, Validation Loss: 5.620340477131928e-05\n",
      "Epoch [25/25], Train Loss: 5.434537524706684e-05, Validation Loss: 5.664658844276952e-05\n",
      "Epoch [25/25], Train Loss: 5.585127655649558e-05, Validation Loss: 5.7306906819576396e-05\n",
      "Epoch [25/25], Train Loss: 5.0250459025846794e-05, Validation Loss: 5.817872903814229e-05\n",
      "Epoch [25/25], Train Loss: 5.344517558114603e-05, Validation Loss: 5.939178881817497e-05\n",
      "Epoch [25/25], Train Loss: 5.706936281058006e-05, Validation Loss: 6.092234398238361e-05\n",
      "Epoch [25/25], Train Loss: 7.594539783895016e-05, Validation Loss: 6.275884782856641e-05\n",
      "Epoch [25/25], Train Loss: 6.607777322642505e-05, Validation Loss: 6.474012067580285e-05\n",
      "Epoch [25/25], Train Loss: 6.302254041656852e-05, Validation Loss: 6.66702449962031e-05\n",
      "Epoch [25/25], Train Loss: 6.883935566293076e-05, Validation Loss: 6.797289946310532e-05\n",
      "Epoch [25/25], Train Loss: 5.75807825953234e-05, Validation Loss: 6.828232653788291e-05\n",
      "Epoch [25/25], Train Loss: 6.90761225996539e-05, Validation Loss: 6.677527805247034e-05\n",
      "Epoch [25/25], Train Loss: 5.582981975749135e-05, Validation Loss: 6.365696632807764e-05\n",
      "Epoch [25/25], Train Loss: 7.482153887394816e-05, Validation Loss: 5.971462718055894e-05\n",
      "Epoch [25/25], Train Loss: 6.696538912365213e-05, Validation Loss: 5.652728577842936e-05\n",
      "Epoch [25/25], Train Loss: 6.05087770964019e-05, Validation Loss: 5.5247199149259056e-05\n",
      "Epoch [25/25], Train Loss: 5.322581637301482e-05, Validation Loss: 5.606016202364117e-05\n",
      "Epoch [25/25], Train Loss: 6.008552009006962e-05, Validation Loss: 5.793416955081436e-05\n",
      "Epoch [25/25], Train Loss: 5.44952999916859e-05, Validation Loss: 5.93069642491173e-05\n",
      "Epoch [25/25], Train Loss: 5.3707448387285694e-05, Validation Loss: 5.917339998025758e-05\n",
      "Epoch [25/25], Train Loss: 6.503626354970038e-05, Validation Loss: 5.773029843112454e-05\n",
      "Epoch [25/25], Train Loss: 5.8063284086529166e-05, Validation Loss: 5.606937508370417e-05\n",
      "Epoch [25/25], Train Loss: 5.947443059994839e-05, Validation Loss: 5.534146548598073e-05\n",
      "Epoch [25/25], Train Loss: 5.417913052951917e-05, Validation Loss: 5.5778277358816314e-05\n",
      "Epoch [25/25], Train Loss: 6.739905074937269e-05, Validation Loss: 5.759847263107076e-05\n",
      "Epoch [25/25], Train Loss: 6.042388849891722e-05, Validation Loss: 6.285962153924629e-05\n",
      "Epoch [25/25], Train Loss: 7.403948984574527e-05, Validation Loss: 7.421610910872308e-05\n",
      "Epoch [25/25], Train Loss: 7.85972224548459e-05, Validation Loss: 8.509890952457984e-05\n",
      "Epoch [25/25], Train Loss: 9.11028400878422e-05, Validation Loss: 8.996142520724485e-05\n",
      "Epoch [25/25], Train Loss: 9.921772289089859e-05, Validation Loss: 8.31734054372646e-05\n",
      "Epoch [25/25], Train Loss: 7.171247125370428e-05, Validation Loss: 6.949037512337479e-05\n",
      "Epoch [25/25], Train Loss: 6.393918010871857e-05, Validation Loss: 6.0255669329004986e-05\n",
      "Epoch [25/25], Train Loss: 6.836852844571695e-05, Validation Loss: 6.196248383882145e-05\n",
      "Epoch [25/25], Train Loss: 6.176529132062569e-05, Validation Loss: 6.816850752026464e-05\n",
      "Epoch [25/25], Train Loss: 7.880621706135571e-05, Validation Loss: 6.821941545543571e-05\n",
      "Epoch [25/25], Train Loss: 7.835386350052431e-05, Validation Loss: 6.108360927707206e-05\n",
      "Epoch [25/25], Train Loss: 6.077936996007338e-05, Validation Loss: 5.625427850948957e-05\n",
      "Epoch [25/25], Train Loss: 5.579051867243834e-05, Validation Loss: 5.957746664838245e-05\n",
      "Epoch [25/25], Train Loss: 6.463185127358884e-05, Validation Loss: 6.492153988801874e-05\n",
      "Epoch [25/25], Train Loss: 5.283295104163699e-05, Validation Loss: 6.33602144565278e-05\n",
      "Epoch [25/25], Train Loss: 6.302538531599566e-05, Validation Loss: 5.727504491612005e-05\n",
      "Epoch [25/25], Train Loss: 5.0008969992632046e-05, Validation Loss: 5.529547876600797e-05\n",
      "Epoch [25/25], Train Loss: 5.410841913544573e-05, Validation Loss: 5.861912771554974e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Train Loss: 6.203261000337079e-05, Validation Loss: 6.031295730887602e-05\n",
      "Epoch [25/25], Train Loss: 5.153420352144167e-05, Validation Loss: 5.765739285076658e-05\n",
      "Epoch [25/25], Train Loss: 5.460621468955651e-05, Validation Loss: 5.586810463379758e-05\n",
      "Epoch [25/25], Train Loss: 6.070879680919461e-05, Validation Loss: 5.7349351360850655e-05\n",
      "Epoch [25/25], Train Loss: 5.1812708989018574e-05, Validation Loss: 5.8213162992615254e-05\n",
      "Epoch [25/25], Train Loss: 4.8540186980972067e-05, Validation Loss: 5.63667500197577e-05\n",
      "Epoch [25/25], Train Loss: 7.412581180687994e-05, Validation Loss: 5.504330959714328e-05\n",
      "Epoch [25/25], Train Loss: 6.331766780931503e-05, Validation Loss: 5.623600542700539e-05\n",
      "Epoch [25/25], Train Loss: 6.034391844877973e-05, Validation Loss: 5.728368923882954e-05\n",
      "Epoch [25/25], Train Loss: 5.6304019381059334e-05, Validation Loss: 5.610270406274746e-05\n",
      "Epoch [25/25], Train Loss: 5.314371082931757e-05, Validation Loss: 5.49367713877776e-05\n",
      "Epoch [25/25], Train Loss: 5.8387980971019715e-05, Validation Loss: 5.544074447243475e-05\n",
      "Epoch [25/25], Train Loss: 5.709530887543224e-05, Validation Loss: 5.6100414803950115e-05\n",
      "Epoch [25/25], Train Loss: 5.5640339269302785e-05, Validation Loss: 5.559766068472527e-05\n",
      "Epoch [25/25], Train Loss: 5.6804165069479495e-05, Validation Loss: 5.500173235001663e-05\n",
      "Epoch [25/25], Train Loss: 4.865650407737121e-05, Validation Loss: 5.534778101718984e-05\n",
      "Epoch [25/25], Train Loss: 7.309836655622348e-05, Validation Loss: 5.567779420137716e-05\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model_interictal = DDPM(input_channels, num_filters)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for reconstruction\n",
    "optimizer = optim.Adam(model_interictal.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses_interictal = []\n",
    "val_losses_interictal = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model_interictal.train()  # Set model to training mode\n",
    "    for i, (batch_X, _) in enumerate(train_dataloader):\n",
    "        \n",
    "        # Forward pass\n",
    "        reconstructed = model_interictal(batch_X)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(reconstructed, batch_X)\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Append losses to the lists after each epoch\n",
    "        train_losses_interictal.append(loss.item())\n",
    "        \n",
    "        \n",
    "        # Print progress\n",
    "       # print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(dataloader)}], Loss: {loss.item()}\")\n",
    "        \n",
    "        # Validation\n",
    "        model_interictal.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_X_val, _ in val_dataloader:\n",
    "                reconstructed_val = model_interictal(batch_X_val)\n",
    "                val_loss += criterion(reconstructed_val, batch_X_val).item()\n",
    "        val_loss /= len(val_dataloader)\n",
    "        val_losses_interictal.append(val_loss)\n",
    "\n",
    "        # Print training and validation loss\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item()}, Validation Loss: {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train_losses_interictal and val_losses_interictal contain the loss values across epochs\n",
    "# Plotting training and validation loss\n",
    "epochs = range(1, len(train_losses_interictal) + 1)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_losses_interictal, label='Training Loss')\n",
    "plt.plot(epochs, val_losses_interictal, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss for Interictal data generation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('DDPM_interictal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data samples\n",
    "num_samples_to_generate = 2714\n",
    "with torch.no_grad():\n",
    "    generated_samples_interictal = []\n",
    "    for _ in range(num_samples_to_generate):\n",
    "        noise = torch.randn(1, X_int.shape[1], 32)  # Generate noise with 32 channels\n",
    "        generated = model_interictal.decoder(noise.permute(0, 2, 1)).squeeze().numpy()  # Adjust input shape for the decoder\n",
    "        generated_samples_interictal.append(generated)\n",
    "\n",
    "# Convert generated samples to a NumPy array\n",
    "generated_samples_interictal = np.array(generated_samples_interictal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2714, 16, 4000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_samples_interictal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('generated_samples_interictal', generated_samples_interictal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train_samples_interictal', X_int_train)\n",
    "np.save('y_train_samples_interictal', y_int_train)\n",
    "np.save('X_val_samples_interictal', X_int_val)\n",
    "np.save('y_val_samples_interictal', y_int_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
